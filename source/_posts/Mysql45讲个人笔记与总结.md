---
0title: Mysql45讲个人笔记与总结
top: false
cover: false
toc: true
mathjax: true
categories:
  - mysql
tags:
  - mysql
date: 2021-11-13 19:43:52
password:
summary:
---

# Mysql45

# 一、基础架构，SQL语句如何执行

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111131946742.png)

## 1.1 Server层

Server层：查询缓存、分析器、优化器、执行器等 以及所有内置的函数（eg:日期、时间、数学和加密函数等）所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

### 1.1.1 连接器

​			客户端连接到服务端，获取到==权限==等信息，然后在连接的有效时长内(==interactive_timeout==和==wait_timeout==参数控制， 5.7版本会断开可以自动重连)对sql进行处理。

* connect-timeout：连接过程中的等待时间
* wait-timeout：连接完成后，使用过程中的等待时间
* interactive-timeout：交换式……

`show processlist`

```mysql
# 通过命令可以去查看连接状态
show processlist
show variables like 'wait_timeout';
```

**注意：**

> 连接器会到权限表中查询拥有的权限，之后这个连接练得权限判断逻辑，都依赖于读到的权限，并且，连接在建立之后如果修改权限也不影响已经存在的连接，只有连接新建的时候，才会生效

**长链接与短连接**

> **长链接与短连接**是一种“行为”，比如连接完，执行一个查询，就断开，这是短连接；执行一个查询，不断开，下次查询还用这个连接，持续使用，就是长链接
>
> 换句话说，在不用连接池的时候，每次查询都要获取连接，查询完成之后调用close方法，这就是短链接，使用连接池之后，因为连接都被放入容器中，每次用完就放进去，而不是close，这种就是长连接

**mysql_reset_connection** 影响的会话状态相关的信息

> mysql_reset_connection()影响以下与会话状态相关的信息： ·回滚活跃事务并重新设置自动提交模式 ·释放所有的表锁 ·关闭或删除所有的临时表 ·重新初始化会话的系统变量值 ·丢失用户定义的变量设置 ·释放prepared语句 ·关闭handler变量 ·将last_insert_id()的值设置为0 ·释放get_lock()获取的锁 ·清空通过mysql_bind_param()调用定义的当前查询属性 返回值： 0表示成功，非0表示发生了错误。

#### FQA

**如何解决长链接所导致的内存占用过大MySQL异常重启问题（OOM）？**

1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

2. 首先会判断查询缓存是否开启，如果已经开启，会判断sql是select还是update/insert/delete，对于select，尝试去查询缓存，如果命中缓存直接返回数据给客户端， 如果缓存没有命中，或者没有开启缓存， 会进入到下一步分析器。

### 1.1.2 查询缓存

> 查询缓存：mysql拿到一个查询后，先查询缓存，（缓存保存形式KV（K为查询的语句，V为查询的结果））

#### FQA

**为什么建议关闭缓存？**

> 失效频繁，而且对于更新压力大的数据库，命中率非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。==mysql8.0版本取消了查询缓存的整个功能模块。==

```mysql
# 关闭查询缓存
show variables like '%query_cache_type%';
set GLOBAL query_cache_type='OFF';
```

### 1.1.3 分析器

> 分析器进行语法分析(根据词法分析的结果和语法规则，判断是否满足Mysql语法)、词法分析，检查sql的语法顺序等得到==解析树==， 然后预处理器对解析树进一步分析，==验证数据表、字段是否存在==，通关之后sql进入下一步优化器，

### 1.1.4 优化器

> 优化器对sql执行计划分析，决定使用哪个索引；在一个语句有多表关联（join）时，决定各个表的连接顺序，得到最终执行计划，得到优化后的执行计划之后交给执行器。

执行器调用存储引擎api执行sql，得到响应结果， 将结果返回给客户端，如果缓存是开启状态， 会更新缓存。

### 1.1.5 执行器

> 执行器在执行的时候会先判断对于表T有没有查询权限，如果没有返回没有权限的错误(在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。

**precheck验证权限**

> 权限验证不仅仅在执行器这部分会做，在分析器之后，也就是知道了该语句要“干什么”之后，也会先做一次权限验证。叫做precheck。而precheck是无法对运行时涉及到的表进行权限验证的，比如使用了触发器的情况。因此在执行器这里也要做一次执行时的权限验证。

**执行流程**

> 1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
> 2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
> 3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

FAQ

## 1.2 存储引擎层

负责数据的存储和提取，架构模式位==插件式==的支持InnoDB（默认）、MyISAM（不支持事务）、Memory（针对具体表，而非数据库）

InnoDB、MyISAM、Memory比较：：
InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（银行），
要求实现并发控制（售票），选择InnoDB。如果需要频繁更新、删除操作的数据库也选择InnoDB。因为支持
事务的提交和回滚
MyISAM：插入数据块、空间和内存使用比较低。如果表主要用于插入新记录和读出记录，选择MyISAM能实现处理高效率。
如果应用的完整性、并发性要求比较低，也可使用。
Memory：所有数据存在内存中，数据处理速度快，但不安全。如果需要很快的读写速度，对数据的安全性要求低，可选择Memory
它对表的大小有要求，不能建立太大的表。

# 二、日志系统，更新语句如何执行

**关于缓存**

​		对于MySQL8.0之前的版本，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这就是一般不建议使用查询缓存的原因。

## 2.1 redo log 重做日志

> 客户端执行DDL语句（create）/DML语句（insert，update，delete）/DCL语句（grant，revoke），数据库服务端执行的时候会涉及到 redo log（重做日志） 和 binlog（归档日志） 两个日志文件的更新。

**问题引出：**

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 ==IO 成本==、查找成本都很高。

**关于IO成本**

> IO成本就是寻址时间和上下文切换所需要的时间，最主要是用户态和内核态的上下文切换。我们知道用户态是无法直接访问磁盘等硬件上的数据的，只能通过操作系统去调内核态的接口，用内核态的线程去访问。 这里的上下文切换指的是同进程的线程上下文切换，所谓上下文就是线程运行需要的环境信息。 首先，用户态线程需要一些中间计算结果保存CPU寄存器，保存CPU指令的地址到程序计数器（执行顺序保证），还要保存栈的信息等一些线程私有的信息。 然后切换到内核态的线程执行，就需要把线程的私有信息从寄存器，程序计数器里读出来，然后执行读磁盘上的数据。读完后返回，又要把线程的信息写进寄存器和程序计数器。 切换到用户态后，用户态线程又要读之前保存的线程执行的环境信息出来，恢复执行。这个过程主要是消耗时间资源。 --来自《Linux性能优化实战》里的知识 SQL执行前优化器对SQL进行优化，这个过程还需要占用CPU资源

**关于随机IO**

> 随机 IO。 避免每次更新都要通过磁盘随机 IO 定位到记录位置。 将改动以顺序 IO 写到 redo log。可以使用组提交来批量更新。 类比，其实很多组件都是这么做的。 比如 Redis 的 Pipeline。以减少网络 IO。批量请求。

### 2.1.1 WAL技术

> MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。
>
> 详细的说：先写redo log到log buffer，具体内容就是针对哪个表空间的哪些页面做了哪些修改，然后log buffer中的日志内容会在某些时候写到redo日志文件中，比如事务提交时。至于为什么写redo日志会比刷新内存中的数据页到磁盘快，是因为服务器在启动时就已经给redo日志文件分配好了一块物理上连续的磁盘空间，每次写redo日志都是往文件中追加写，并没有寻址的过程。而修改过的数据页要刷新到磁盘的话，可能对应的磁盘空间并不是物理连续的，找起来费劲

​			当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并==更新内存==，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲（根据innodb_flush_log_at_trx_commit来决定）的时候做

**什么是更新内存**

> 更新内存的意思是先要把这一行记录从磁盘加载到内存中(buffer_pool),然后在内存中更新这个值。不会立即把最新值刷新到磁盘。
>
> 当需要更新的数据页在内存中时，就会直接更新内存中的数据页；不在内存中时，在可以使用 change buffer 的情况下，就会将更新操作记录到 change buffer 中，并将这些操作记录到 redo log 中；

---

### 2.1.3 redo log 图

> redo log 是循环写的，空间固定会用完，之后就去写磁盘，有刷页机制；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
>
> redo log实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111210009122.png)

write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

**落盘机制**

innodb_flush_log_at_trx_commit 变量控制日志缓冲区的内容如何写入和刷新到磁盘。innodb_flush_log_at_timeout 变量控制日志刷新频率(1s由log buffer刷盘一次）

> 落盘机制可以通过innodb_flush_log_at_trx_commit参数来控制：
>    当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
>    当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
>    当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。

1. 后台线程定期会刷脏页
2. 清理LRU链表时会顺带刷脏页
3. redoLog写满会强制刷
4. 数据库关闭时会将所有脏页刷回磁盘
5. 脏页数量过多（默认占缓冲池75%）时，会强制刷

### 2.1.3 crash-safe

> redo log 是 InnoDB引擎所特有的，所以我们如果再使用InnoDB引擎创建表时，如果数据库发生异常重启，之前提交的记录都不会丢失。 InnoDB正因为有了 redo log(重做日志)，才有了 crash-safe 的能力（即使mysql服务宕机，也不会丢失数据的能力）。

数据库重启了，内存中的数据页没有同步到磁盘中，可以通过redo log日志恢复

## 2.2 binlog 归档日志

binlog（归档日志）是Server 层自己的日志。

 如何查看 binlog： https://zhuanlan.zhihu.com/p/33504555 

1. 搜索 log 名称：show variables like '%log_bin%'; 
2.  查看 log 内容：show binlog events in 'binlog.000009’ 或 使用命令行工具：mysqlbinlog binlog.000009

**关于binlog**

> binlog日志格式binlog日志有两种格式，分别为STATMENT、ROW，运行模式有三种，分别为STATMENT、ROW和MIXED。 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。 STATMENT 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。 * 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能； * 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。 ROW 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。 * 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题； * 缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨 MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlogredo log

**为什么会有两份日志？**

> 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。
>
> binlog还不能去掉。 一个原因是，redolog只有InnoDB有，别的引擎没有。 另一个原因是，redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。 只有两份日记才有crash-safe功能 为什么binlog不能做到crash-safe？ 假如只有binlog，有可能先提交事务再写binlog，有可能事务提交数据更新之后数据库崩了，还没来得及写binlog。我们都知道binlog一般用来做数据库的主从复制或恢复数据库，这样就导致主从数据库不一致或者无法恢复数据库了。同样即使先写binlog再提交事务更新数据库，还是有可能写binlog成功之后数据库崩掉而导致数据库更新失败，这样也会导致主从数据库不一致或者无法恢复数据库。所以只有binlog做不到crash-safe。为了支持crash-safe，需要redolog，而且为了保证逻辑一致，事务提交需要两个阶段：prepare阶段和commit阶段。写redolog并落入磁盘(prepare状态)-->写binlog-->commit。commit的时候是不会落盘的。

**binlog为什么没有crash_safe的能力呢？**

> 不考虑mysql现有的实现，假如现在重新设计mysql，只用一个binlog是否可以实现cash_safe能力呢？答案是可以的，只不过binlog中也要加入checkpoint，数据库故障重启后，binlog checkpoint之后的sql都重放一遍。但是这样做让binlog耦合的功能太多。
>
> 并且写入方式的问题，binlog是追加写，crash时不能判定binlog中哪些内容是已经写入到磁盘，哪些还没被写入。而redolog是循环写，从check point到write pos间的内容都是未写入到磁盘的。

**binlog 与redolog的不同**

> 1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
> 2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
> 3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
> 4. 两者在更新方面也不一样redo log 分为 redo log buffer 和 redo log file，buffer 到 file 是通过 os buffer 写入，写入机制分别为【延迟写】: 每秒从 redo log buffer 写入到 os buffer 和 redo log file， 【实时写，实时刷】: 即无延时实时写入，【实时写，延迟刷】: 每次写入到 os buffer 后每秒刷到 redo log file， binlog是在事务提交后一次性写入

REDO的写盘时间会直接影响系统吞吐，显而易见，REDO的数据量要尽量少。其次，系统崩溃总是发生在始料未及的时候，当重启重放REDO时，系统并不知道哪些REDO对应的Page已经落盘，因此REDO的重放必须可重入，即REDO操作要保证幂等。最后，为了便于通过并发重放的方式加快重启恢复速度，REDO应该是基于Page的，即一个REDO只涉及一个Page的修改。 熟悉的读者会发现，数据量小是Logical Logging的优点，而幂等以及基于Page正是Physical Logging的优点，因此InnoDB采取了一种称为Physiological Logging的方式，来兼得二者的优势。所谓Physiological Logging，就是以Page为单位，但在Page内以逻辑的方式记录。举个例子，MLOG_REC_UPDATE_IN_PLACE类型的REDO中记录了对Page中一个Record的修改，方法如下： （Page ID，Record Offset，(Filed 1, Value 1) ... (Filed i, Value i) ... ) 其中，PageID指定要操作的Page页，Record Offset记录了Record在Page内的偏移位置，后面的Field数组，记录了需要修改的Field以及修改后的Value。

---

**执行器与InnoDB引擎执行update语句内部流程**

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的==数据页==本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。<!--操作系统层面读取磁盘的最小单位本来就是页，内存页、cache页和磁盘页都是一样大小，一般是4KB，但是Innodb使用B+树存储数据时，一个树节点即一次磁盘IO到内存是16KB，4倍关系。-->
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行==新数据==。<!--写在了内存中，innodb中的内存模型中有一个buffer pool的结构。innodb的存储结构，它分为内存结构和磁盘结构。-->
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。<!--1.binlog只有在commit的时候才会写入； 2.当prepare log 写入成功且binglog写入成功后发生crash，在mysql启动时候，会自动commit这个事物； 3.当prepare log写入成功，binlog写入失败，此时发生crash，mysql启动会自动回滚掉这个事物。即Binlog如果已经写入磁盘，那么redo log是prepare, 且binlog已经完整了，这时候崩溃恢复过程会认可这个事务，提交掉。 达到了“用binlog恢复的库跟原库逻辑相同” 这个要求-->

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111211530363.png)

**数据恢复步骤**

> 恢复的时候的大致步骤可能如下，摘取下来仅供做设计思想的参考：
>
>  **Step1.** 按顺序扫描redolog，如果redolog中的事务既有prepare标识，又有commit标识，就直接提交（先将磁盘页读入内存，再用 redo更新形成 dirty page，然后再刷盘） **Step2** . 如果redolog事务只有prepare标识，没有commit标识，则说明当前事务在commit阶段crash了，binlog中当前事务是否完整未可知，此时拿着redolog中当前事务的XID（redolog和binlog中事务落盘的标识），去查看binlog中是否存在此XID a. 如果binlog中有当前事务的XID，则提交事务（复制redolog disk中的数据页到磁盘数据页） b. 如果binlog中没有当前事务的XID，则回滚事务（使用undolog来删除redolog中的对应事务）

### 2.2.1 两阶段提交

> 将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。

**怎样让数据库恢复到半个月内任意一秒的状态？**

通过定期的整库备份加上binlog的操作回放可以保证数据的安全性。因为binlog记录的是数据的逻辑操作（原始sql语句），而redolog是数据的物理操作日志，并且非innodb的引擎没有redolog。因此回放的时候回使用binlog进行回放

例如：某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

* 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
* 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

**注：**在重放binlog之前，需要将binlog中误删除的那个位置前的操作给删除掉，不然还是会执行误删除操作。等于前面的所有操作都白费了，也可以指定重放的位置，重放到误删除操作之前的position。

---

**为什么要两阶段提交？**

> 因为从 “两阶段提交”的执行流程看，“ binlog 成功，redo log prepare 失败”的场景， redo log 和 binlog 还是不一致的。 真正的“两阶段提交” 是指对 redo log 进行“两阶段提交”：先 prepare，再commit。 数据库 crash-重启后，会对记录对redo log 进行check
>
> 1. 如果 redo log 已经commit，则视为有效。
>
> 2. 如果 redo log prepare 但未commit，则check对应的bin log记录是否记录成功。 
>    1. bin log记录成功则将该prepare状态的redo log视为有效 
>    2. bin log记录不成功则将该prepare状态的redo log视为无效

本质上是因为 redo log 负责事务； binlog负责归档恢复； 各司其职，相互配合，才提供(保证)了现有功能的完整性； 现在 你非要破坏 其中一个log，完了，还妄想保证上述的功能，怎么可能呢？ 除非你从根本上 改写binlog，合并redo log 和 binlog 的 职责和功能！

redolog和binlog具有关联行，在恢复数据时，redolog用于恢复主机故障时的未更新的物理数据，binlog用于备份操作。每个阶段的log操作都是记录在磁盘的，在恢复数据时，redolog 状态为commit则说明binlog也成功，直接恢复数据；如果redolog是prepare，则需要查询对应的binlog事务是否成功，决定是回滚还是执行。

简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### 2.2.2 小结

> redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。<!--innodb_flush_log_at_trx_commit={0|1|2} # 指定何时将事务日志刷到磁盘，默认为1。 0表示每秒将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中。 1表示每事务提交都将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中。 2表示每事务提交都将"log buffer"同步到"os buffer"但每秒才从"os buffer"刷到磁盘日志文件中。-->

> sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

## 2.3 FAQ

**全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？**

一天一备和一周一备： - 好处：最长恢复时间更短。 一天一备——全备+这一天0点到当前时间的binlog (如果每次0点全备) 一周一备——全备+周一到当前时间的binlog (如果每周周一0点全备) - 代价：一天一备，频繁全量备份，需要消耗大量存储空间

在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。

一周一备最坏情况就要应用一周的 binlog 了。

系统的对应指标就是  RTO（恢复目标时间）。

当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间增加磁盘压力，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。

---

**数据库备份策略**

备份就是救命药加后悔药，灾难发生的时候备份能救命，出现错误的时候备份能后悔。事情都有两面性，没有谁比谁好，只有谁比谁合适，完全看业务情况和需求而定。一天一备恢复时间更短，binlog更少，救命时候更快，但是后悔时间更短，而一周一备正好相反。我自己的备份策略是设置一个16小时延迟复制的从库，充当后悔药，恢复时间也较快。再两天一个全备库和binlog，作为救命药,最后时刻用。这样就比较兼顾了。

---

**为什么先写日志后写磁盘还可以查到数据呢？**

因为数据已经在内存中了，不会去查找磁盘了

如果update到内存后，redolog/binlog写入之前，这个时刻【如果】有其他客户端B能读到的话（比如 10 更新为20了），从客户端来的角度来看的话，这个20是已经更新完成的了。然而如果redolog/binlog写入之前崩溃了，恢复时，这个更新肯定是要丢弃的（因为日志还没commit）；这时候之前的读就是有问题的。所以个人认为在commit之前，哪怕是更新到内存了，其他读取理应是看不到这个尚未commit的数据的（和事务隔离级别有关？）

---

**由于脏页导致的普通select超过30s**

所谓刷脏就是由于内存页和磁盘数据不一致导致了该内存页是“脏页”，将内存页数据刷到磁盘的操作称为“刷脏”。刷脏是为了避免产生“脏页”，主要是因为MySQL更新先写redo log再定期批量刷到磁盘的，这就导致内存页的数据和磁盘数据不一致，为了搞清楚为什么“刷脏”会导致慢查，我们先分析下redo log再哪些场景会刷到磁盘。
场景1：redo log写满了，此时MySQL会停止所有更新操作，把脏页刷到磁盘
场景2：系统内存不足，需要将脏页淘汰，此时会把脏页刷到磁盘
场景3：系统空闲时，MySQL定期将脏页刷到磁盘

可以想到，在场景1和2都会导致慢查的产生，根据文章提到的，redo log是可以循环写的，那么即使写满了应该也不会停止所有更新操作吧，其实是会的，文中有句话“粉板写满了，掌柜只能停下手中的活，把粉板的一部分赊账记录更新到账本中，把这些记录从粉板删除，为粉板腾出新的空间”，这就意味着写满后是会阻塞一段时间的。

那么问题来了，innodb存储引擎的刷脏策略是怎么样的呢？通常而言会有两种策略：全量（sharp checkpoint）和部分（fuzzy checkpoint）。全量刷脏发生在关闭数据库时，部分刷脏发生在运行时。部分刷脏又分为定期刷脏、最近最少使用刷脏、异步/同步刷脏、脏页过多刷脏。

---

**关于数据页**

MySQL的记录是以“页”为单位存取的，默认大小16K。也就是说，你要访问磁盘中一个记录，不会只读这个记录，而会把它所在的16K数据一起读入内

---

**如果两种log都写完成了，但是redolog没有写磁盘，物理机挂了，redolog在内存中就丢失了吧，再启动跟磁盘中的binlog就不一致，后期恢复数据的时候会有问题吗**

需要讲trx_commit设置成1

---

**redo log为什么要设计成环形的？环形缓冲区的设计又有什么好？**

可以避免新建、删除文件带来的抖动

# 三、事物隔离

## 3.1 隔离性与隔离级别 

## 3.2 事物的ACID属性

* **Atomicity（原子性）：**

    一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 

* **Consistency（一致性）：**

  在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。

*  **Isolation（隔离性）：**

  数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。 

* **Durability（持久性）：**

  事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

> 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

* **脏读:** 读到其他事务未提交的数据； 

* **不可重复读：**前后读取的记录内容不一致；

* **幻读：**前后读取的记录数量不一致。幻读也成幻行，指的是第一次查询和第二次查询返回的行集不一致。所以删除了一行数据也会导致幻读

## 3.3 事物的隔离级别

1. **读未提交RU：**一个事务还没提交时，它做的变更就能被别的事务看到。会造成“脏读”，“幻读”，“不可重复读取”。 
2. **读提交RC：**一个事务提交之后，它做的变更才会被其他事务看到。避免了“脏读”，“但不能避免""幻读“和”不可重复读取”。(是大多主流数据库默认的事务等级)
3. **可重复读RR：**一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。避免了“脏读“和”不可重复读取“的情况，但不能避免“幻读”。（带来了更多的性能损失）
4. **串行化Seria：**顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。（最严格级别，事务串行执行，资源消耗最大）

**注意：**

> 在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，要记得将 MySQL 的隔离级别设置为“读提交”
>
> 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。
>
> 5.7版本就是@@tx_isolation，8.0以上是transaction_isolation

## 3.4 视图

数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

1. **RC级别:**   MVCC视图会在每一个语句前创建一个，所以在RC级别下，一个事务是可以看到另外一个事务已经提交的内容、因为它在每一次查询之前都会重新给予最新的数据创建一个新的MVCC视图。 

2. **RR级别:** MVCC视图在，视图是在第一个Select语句执行时创建的吧？，这个视图会一直使用，直到该事务结束。 这里要注意不同的隔离级别他们的一致性事务视图创建的时间点是不同的。 

   事务最开始是update语句时，这个时候还没创建视图，当事务询查到第一条查询语句才开始创建视图

3. **RU：**没有视图的概念，直接返回记录上的最新值

4. **串行化：** 直接用加锁的方式来避免并行访问。

## 3.5 事物隔离的实现

> 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。<!--意思就是除了记录变更记录，还会记录一条变更相反的回滚操作记录，前者记录在redo log，后者记录在undo log-->

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111231403770.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小

## 3.7 事务的启动方式

1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。一致性视图是在执行第一个快照读语句时创建的；
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
3.  start transaction with consistent snapshot; 如果你想要马上启动一个事务，可以使用 `start transaction with consistent snapshot `这个命令。  一致性视图是在执行 start transaction with consistent snapshot 时创建的。
4. commit work and chain 将提交和开启事务用一条语句完成可以弥补，减少交互，来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

> 很多语言的第三方库都是使用连接池维持可复用的长连接来保持与mysql的链接，需注意，长连接并不意味着长事务，需要判断是否将autocommit设置成了0.

建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。

如果纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。

## 3.8 长事务查询

information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```mysql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

## FAQ

**回滚日志何时删除?**

> 在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。
>
> 回归日志生命周期 在开始时创建 提交后不一定删除 只有在提交后且没有比当前更早的事务时 回滚日志才会被删除 所以尽量不要使用长事务

**为什么不要使用长事务?**

 长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。

**如何避免长事务**

首先，从应用开发端来看：

1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。

   ```bash
   一、查询日志开启 
   方法一： 　　
   #设置路径
   mysql>set global general_log_file='/tmp/general.lg';  　
   # 开启general log模式 
   mysql>set global general_log=on; 　　
   # 关闭general log模式 命令行设置即可,无需重启 在general log模式开启过程中，所有对数据库的操作都将被记录 general.log 文件 
   mysql>set global general_log=off; 
   方法二： 也可以将日志记录在表中 
   set global log_output='table' 运行后,可以在mysql数据库下查找 general_log表 
   二、查询日志关闭 查看是否是开启状态： 
   mysql> show global variables like '%general%'; 
   #  关闭查询日志
   mysql> set global general_log = off; 
   ```

   

2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。

3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）

其次，从数据库端来看：

1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
2. Percona 的 pt-kill 这个工具不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

# 四、深入浅出索引一

> 索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。

## 4.1 B+树

哈希表能快速找到数据，但是不支持范围查找，有序数组支持范围查找，但是不支持随机插入，B+树俩者都支持。

### 4.1.1 MySQL的存储结构

#### 4.1.1.1 表存储结构

单位：表>段>区>页>行

在数据库中， 不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说存储空间的基本单位是页。

一个页就是一棵树B+树的节点，数据库I/O操作的最小单位是页，与数据库相关的内容都会存储在页的结构里。

#### 4.1.1.2 B+树索引结构

在一棵B+树中，每个节点为都是一个页，每次新建节点的时候，就会申请一个页空间

同一层的节点为之间，通过页的结构构成了一个双向链表

非叶子节点为，包括了多个索引行，每个索引行里存储索引键和指向下一层页面的指针

叶子节点为，存储了关键字和行记录，在节点内部(也就是页结构的内部)记录之间是一个单向的表

#### 4.1.1.3 B+树页节点结构

有以下几个特点

将所有的记录分成几个组， 每组会存储多条记录，

页目录存储的是槽(slot)，槽相当于分组记录的索引，每个槽指针指向了不同组的最后一个记录

我们通过槽定位到组，再查看组中的记录

页的主要作用是存储记录，在页中记录以单链表的形式进行存储。

单链表优点是插入、删除方便，缺点是检索效率不高，最坏的情况要遍历链表所有的节点。因此页目录中提供了二分查找的方式，来提高记录的检索效率。

#### 4.1.1.4 B+树的检索过程

我们再来看下B+树的检索过程

从B+树的根开始，逐层找到叶子节点。

找到叶子节点为对应的数据页，将数据叶加载到内存中，通过页目录的槽采用二分查找的方式先找到一个粗略的记录分组。

在分组中通过链表遍历的方式进行记录的查找。

#### 4.1.1.5 为什么要用B+树索引

数据库访问数据要通过页，一个页就是一个B+树节点，访问一个节点相当于一次I/O操作，所以越快能找到节点，查找性能越好。

B+树的特点就是够矮够胖，能有效地减少访问节点次数从而提高性能。

下面，我们来对比一个二叉树、多叉树、B树和B+树。

### 4.1.2 二叉树

二叉树是一种二分查找树，有很好的查找性能，相当于二分查找。

但是当N比较大的时候，树的深度比较高。数据查询的时间主要依赖于磁盘IO的次数，二叉树深度越大，查找的次数越多，性能越差。

最坏的情况是退化成了链表，如下图

为了让二叉树不至于退化成链表，人们发明了AVL树(平衡二叉搜索树)：任何结点的左子树和右子树高度最多相差1

### 4.1.3 多叉树

多叉树就是节点可以是M个，能有效地减少高度，高度变小后，节点变少I/O自然少，性能比二叉树好了

### 4.1.4 B树

B树简单地说就是多叉树，每个叶子会存储数据，和指向下一个节点的指针。

例如要查找9，步骤如下

我们与根节点的关键字 (17，35)进行比较，9 小于 17 那么得到指针 P1；

按照指针 P1 找到磁盘块 2，关键字为(8，12)，因为 9 在 8 和 12 之间，所以我们得到指针 P2；

按照指针 P2 找到磁盘块 6，关键字为(9，10)，然后我们找到了关键字 9。

### 4.1.5 B+树

B+树是B树的改进，简单地说是：只有叶子节点才存数据，非叶子节点是存储的指针；所有叶子节点构成一个有序链表

例如要查找关键字16，步骤如下

与根节点的关键字 (1，18，35) 进行比较，16 在 1 和 18 之间，得到指针 P1(指向磁盘块 2)

找到磁盘块 2，关键字为(1，8，14)，因为 16 大于 14，所以得到指针 P3(指向磁盘块 7)

找到磁盘块 7，关键字为(14，16，17)，然后我们找到了关键字 16，所以可以找到关键字 16 所对应的数据。

### 4.1.6 B+树与B树的不同：

B+树非叶子节点不存在数据只存索引，B树非叶子节点存储数据

B+树使用双向链表串连所有叶子节点，区间查询效率更高，因为所有数据都在B+树的叶子节点，但是B树则需要通过中序遍历才能完成查询范围的查找。

B+树每次都必须查询到叶子节点才能找到数据，而B树查询的数据可能不在叶子节点，也可能在，这样就会造成查询的效率的不稳定

B+树查询效率更高，因为B+树矮更胖，高度小，查询产生的I/O最少。

这就是MySQL使用B+树的原因，就是这么简单！

## 4.2 InnoDB 的索引模型

在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。

对于Innodb对应的N叉树大小，以InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

MySql默认一个节点的长度为16K，一个整数（bigint）字段索引的长度为 8B,另外每个索引还跟着6B的指向其子树的指针；所以16K/14B ≈ 1170 参见https://blog.csdn.net/weixin_35871519/article/details/113303881

https://github.com/jeremycole/innodb_diagrams/blob/master/images/InnoDB_Structures.pdf

**关于 InnoDB 的表结构：**

1. 在 InnoDB 中，每一张表其实就是多个 B+ 树，即一个主键索引树和多个非主键索引树。

2. 执行查询的效率，使用主键索引 > 使用非主键索引 > 不使用索引。 

3. 如果不使用索引进行查询，则从主索引 B+ 树的叶子节点进行遍历。

**每一个索引在 InnoDB 里面对应一棵 B+ 树。**

**例如：**

```mysql
create table T(
id int primary key, 
k int not null, 
name varchar(16),
index (k))engine=InnoDB;
insert into t(id,k) values(100,1),(200,2),(300,3),(500,5),(600,6);
```

![InnoDB 的索引组织结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111231611454.png)

> 二级索引的叶子节点存的就是主键的值，不是引用！根据这个值进行回表，再在聚簇索引里面直接从叶子节点里面拿到值，不需要进行一次IO去磁盘找。为啥存值不存引用（数据在磁盘的地址指针）？因为一旦发生页分裂或者页合并，就得去维护这个地址指针，更麻烦。

---

**基于主键索引和普通索引的查询有什么区别？**

主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

---

## 4.3 索引维护

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

数据页参见https://www.cnblogs.com/zhuchangwu/p/14041410.html

由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。

显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

**适合业务字段做主键的场景**

1. 只有一个索引；

2. 该索引必须是唯一索引。  

这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。

## FAQ

**重建索引问题**

如果你要重建索引 k，你的两个 SQL 语句可以这么写：

`alter table T drop index k;`

`alter table T add index(k);`

如果你要重建主键索引，也可以这么写：

`alter table T drop primary key;`

`alter table T add primary key(id);`

对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

1. 直接删掉主键索引是不好的，它会使得所有的二级索引都失效，并且会用ROWID来作主键索引；
2. 看到mysql官方文档写了三种措施，第一个是整个数据库迁移，先dump出来再重建表（这个一般只适合离线的业务来做）；第二个是用空的alter操作，比如ALTER TABLE t1 ENGINE = InnoDB;这样子就会原地重建表结构（真的吗？）；第三个是用repaire table，不过这个是由存储引擎决定支不支持的（innodb就不行）。

**注意**

> 记录日志的表最好是分区表，历史数据清理可以直接drop分区	

---

**“N叉树”的N值在MySQL中是可以被人工调整的么？**

1， 通过改变key值来调整
N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。我们通过改变Key的大小，就可以改变N的值
2， 改变页的大小
页越大，一页存放的索引就越多，N就越大。

数据页调整后，如果数据页太小层数会太深，数据页太大，加载到内存的时间和单个数据页查询时间会提高，需要达到平衡才行。

**没有主键的表，有一个普通索引。怎么回表？**

https://dev.mysql.com/doc/refman/5.6/en/innodb-index-types.html
5.6 文档
先找非空唯一索引；
如果没有，再用rowid 

**innodb B+树主键索引的叶子节点存的是什么?**

B+树的叶子节点是page （页），一个页里面可以存多个行

 因为存的不可能是“页” 这一逻辑概念 只能说这个叶结点大小等于innoDB里设置的页大小 或者说这个叶结点其实就是“页” 但存的是什么 那当然是数据 什么数据 当然是表中的行数据

**普通索引，为什么要用回表，直接指向数据行，数据页不行吗？**

第一、主键索引和普通索引，实际指向的都是一个页地址，在每个页中，主键索引页每行的value存的是实际数据，普通索引页每行的value是主键id。
第二、如果普通索引页每行的value是主键索引页地址，那么在发生页分裂、页合并、主键索引重建的时候，需要遍历所有的普通索引，查找涉及到的普通索引key进行更新。
第三、可以理解为：使用id值，相当于对主键索引与普通索引进行了解耦，主键索引页的变更不会影响到其他的普通索引。
第四、关于解耦带来的好处，与查询上带来的性能损失之间的定量分析，希望有其他同学补充
第五、可能还有其他的原因，欢迎其他同学补充

**1、如果插入的数据是在主键树叶子结点的中间，后面的所有页如果都是满的状态，是不是会造成后面的每一页都会去进行页分裂操作，直到最后一个页申请新页移过去最后一个值**

只会分裂它要写入的那个页面。每个页面之间是用指针串的，改指针就好了，不需要“后面的全部挪动

在Page 数据结构中，记录 Page 的头信息的File Header 字段中有 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，通过这两个字段，来确定该页的上一页和下一页，实际上所有页通过两个字段可以形成一条双向链表的

**2、还有之前看到过说是插入数据如果是在某个数据满了页的首尾，为了减少数据移动和页分裂，会先去前后两个页看看是否满了，如果没满会先将数据放到前后两个页上，不知道是不是有这种情况**

对，减为了增加空间利用率

**为什么现在一般自增索引都设置为bigint**

因为现在很多业务插入数据很凶残，容易超过int 上限，实际上是建议设置bigint unsigned



**想问如果主键开始是int，自增不够了，改成bigint，内部该怎么处理，是新建表，还是要分裂**？



---

**索引只能定位到page，page内部怎么去定位行数据**

知识点:Page directory ,内存中利用二分查找

https://www.cnblogs.com/bdsir/p/8745553.html感觉这个很清楚

https://blog.csdn.net/cy973071263/article/details/104512020

---

**非聚集索引上为啥叶子节点的value为什么不是地址，这样可以直接定位到整条数据，而不用再次对整棵树进行查询**

这个叫作“堆组织表”，MyISAM就是这样的，各有利弊。你想一下如果修改了数据的位置的情况，InnoDB这种模式是不是就方便些，对于主键索引页分裂的场景， 就可能会导致主键记录的地址发生变化， 这时候需要更新每一个索引上面对主键记录地址的引用

---

**整张表的数据其实就是存在主键索引中的**

---

**什么情况下创建索引才有意义？有哪些限制？比如字段长度**

 有这个索引带来的查询收益，大于维护索引的代价，就该建😄 对于可能变成大表的表，实际上如果不建索引会导致全表扫描，这个索引就是必须的。

---

**如何查看索引占用多少空间？**

可以估算出来的，根据表的行数和索引的定义。

---

**查看索引数的结构，比如多少个层，多少节点？**

跟上一个一样。 如果要精确的，就要解数据文件，这个工具可以看看https://github.com/jeremycole/innodb_diagrams

---

**如何查看索引的利用率。比如我创建了一个索引，是否可以有记录这个索引被调用了多少次？**

 performance_schema.table_io_waits_summary_by_index_usage能看到一些信息

---

**关于innodb中自增索引的插入问题**

按照传统B+树的插入规则，即使是自增插入，当一个数据页满的时候，也是会引起页分裂的。但是innodb在这一块做了优化，即判断如果是自增插入且当前页已满的情况下，不改变原有页的结构，而是将新的数据放到一个新页中。
在innodb的实现中，为每个索引页面维护了一个上次插入的位置，以及上次的插入是递增/递减的标识。根据这些信息，innodb能够判断出新插入到页面中的记录，是否仍旧满足递增/递减的约束，若满足约束，则采用优化后的分裂策略；若不满足约束，则退回到传统的分裂策略。

---

**在插入数据的时候，主键类型为字符串，ID为uuid的形式，插入时会导致分裂吗？**

会，特别不建议uuid做主键

---

**联合索引在B+树中的存储方式**

https://mengkang.net/1302.html

# 五、深入浅出索引二

在下面这个表 T 中，如果执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？

```mysql

create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;
insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111241743747.png)

1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
2. 再到 ID 索引树查到 ID=300 对应的 R3；
3. 在 k 索引树取下一个值 k=5，取得 ID=500；
4. 再回到 ID 索引树查到 ID=500 对应的 R4；
5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。

在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。

## 5.1.1 覆盖索引

> 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

<!--覆盖索引就是在这次的查询中，所要的数据已经在这棵索引树的叶子结点上了-->

**在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？**

身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。

## 5.1.2 最左前缀原则

B+ 树索引结构，可以利用索引的“最左前缀”，来定位记录。

https://cloud.tencent.com/developer/news/44861

**对（name，age）这个联合索引进行分析**

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111241812273.jpg)

索引项是按照索引定义里面出现的字段顺序排序的。

"where name like ‘张 %’" 走索引

单独的年龄不走索引

> 如果单独的字段不能走联合索引，那么考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引

只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。

**在建立联合索引的时候，如何安排索引内的字段顺序。**

评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

## 5.1.3 索引下推

【索引下推】Index Condition Pushdown，简称 ICP。 是Mysql 5.6版本引入的技术优化。旨在 在“仅能利用最左前缀索的场景”下（而不是能利用全部联合索引），对不在最左前缀索引中的其他联合索引字段加以利用——在遍历索引时，就用这些其他字段进行过滤(where条件里的匹配)。过滤会减少遍历索引查出的主键条数，从而减少回表次数，提示整体性能。 ------------------ 如果查询利用到了索引下推ICP技术，在Explain输出的Extra字段中会有“Using index condition”。即代表本次查询会利用到索引，且会利用到索引下推。 ------------------ 索引下推技术的实现——在遍历索引的那一步，由只传入可以利用到的字段值，改成了多传入下推字段值。

---

不符合最左查询的字段的查询过程

```mysql
 select * from tuser where name like '张%' and age=10 and ismale=1;
```

这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。

在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111241827519.jpg)

**总结：**

 1、覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据 

2、最左前缀：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符 

3、联合索引：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。

 4、索引下推：like 'hello%’and age >10 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度

## FAQ

**关于日志处理**

分区表处理访问日志，drop分区

**优化器执行的顺序**

1.根据搜索条件找出所有可能用到的索引。
2.计算全表扫描的代价
3.计算其他索引扫描的代价
4.选出优化器计算出扫描成本最低的索引
（扫描代价涉及到I/O成本和CPU成本，innodb内部有一套自己的成本计算方法，简单举例比如：读取一个页到内存成本为1.0， 检测一条记录是否符合成本为0.2）

根据上面的逻辑，%j 这种条件使用了辅助索引。就是说，优化器认为“扫描辅助索引的代价比扫描聚集索引的代价要低”。

**为什么二级索引比主键索引小**

因为主键索引有额外的三个隐藏列，row_id，trx_id,roll_pointer,具体参考掘金小孩的mysql

**关于大数据表如何整理**

rename +新建表

**索引数据比数据大怎么处理**

删除数据的时候,当前删除索引被标记为被删除,改索引位置则可以被空间复用,当一页数据都被删除时页可以被复用,空间被复用但是磁盘系统表空间是未改变的,需要通过重建表,重建表的逻辑对数据紧凑排列来保存到临时文件中也就是online的逻辑对server端来说就是inplace逻辑

重建索引不行吗？

当没有开启`innodb_file_per_table`选项,导致所有的表(数据和索引)都存储在了一个文件中.
即使是使用了`optimize table`都无法释放空间.

可以参考这两篇文章:
https://stackoverflow.com/questions/1270944/mysql-innodb-not-releasing-disk-space-after-deleting-data-rows-from-table

https://stackoverflow.com/questions/3927690/howto-clean-a-mysql-innodb-storage-engine/4056261#4056261

**关于联合索引**

关于联合索引我的理解是这样的：比如一个联合索引(a,b,c)，其实质是按a,b,c的顺序拼接成了一个二进制字节数组，索引记录是按该字节数组逐字节比较排序的，所以其是先按a排序，再按b排序，再按c排序的，至于其为什么是按最左前缀匹配的也就显而易见了，没看过源码，不知道理解的对不对，希望老师指正。

给表创建索引时，应该创建哪些索引，每个索引应该包含哪些字段，字段的顺序怎么排列，这个问题没有标准答案，需要根据具体的业务来做权衡。不过有些思路还是可供参考的：
1.既然是一个权衡问题，没有办法保证所有的查询都高效，那就要优先保证高频的查询高效，较低频次的查询也尽可能的使用到尽可能长的最左前缀索引。可以借助pt-query-digest来采样统计业务查询语句的访问频度，可能需要迭代几次才能确定联合索引的最终字段及其排序。
2.业务是在演进的，所以索引也是要随着业务演进的，并不是索引建好了就万事大吉了，业务发生变化时，我们需要重新审视当初建的索引是不是还依然高效，依然能满足业务需求。
3.业内流传的有一些mysql 军规，其实这些并不是真正的军规，只是典型场景下的最佳实践。真正的军规其实就一条：高效的效满足业务需求。比如有个军规规定一个表上的索引数不超过5个，但如果我们现在有一些历史数据表、历史日志表，我们很明确的知道这些表上不会再有数据写入了，但我们的查询需求很多也很多样化，那我们在这些表上的索引数能不能超过5个？当然是没有任何问题的。当然关于这份军规还是要认真看一下的，但看的重点不是去记住它，而是要弄明白每一条军规它为什么这么规定，它这样规定是基于什么考虑，适用的场景和前提是什么，这些都弄明白了，你记不记得住这些军规都无所谓了，因为你已经把它溶化到了你的血液中，具体到自己的具体业务时游刃有余将是必然。

**公司有订单表，有些核心字段，比如订单号.时间(整型，时间戳，范围查找).订单状态（整型，6个值，可能in，可能=）.客户标识（整型，几百个值）.付款方式（整型，5个值），设备号（字符串，有权限需要in）,这6个字段后台都会用到查询筛选，而且不选的情况下条件就不传，按照联合索引最左原则，那么可能要建几十个索引，这是不可能的，这个表做了按月分表，数据量一张表大约1000万,不建立索引的话，后台选的条件没有建索引就会非常慢，强制最多只能查连续两个月的数据（union all），请有什么好的解决方案么？？？ **

得按照查询的模式，选最常见的来创建组合索引。比如如果时间+客户标识用得最多，就创建者两个的联合索引。

对于比较少用的条件，单独给这个字段建索引，然后查id出来跟别的字段的查询结果，在客户端取交集，也是一种思路。

**MySQL在执行一条SQL时，是如何选择使用哪个索引的。 possible keys有很多，根据什么选择用哪一个。**

索引统计信息、临时表成本、排序成本

**在不影响排序结果的情况下，在取出主键后，回表之前，会在对所有获取到的主键排序，请问是否存在这种情况？**

存在，在MySQL 里面叫做“MRR优化”

MRR（Multi Range Read) 是针对辅助索引的范围查询时， 会一次性读取多个主键的值，并进行排序后， 再一次性到主键索引进行回表。 这样可以将多次回表的随机IO转换成顺序IO，提升查询性能。

# 六、全局锁和表锁

MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作DML的时候，加 MDL 读锁；当要对表做结构变更操作DDL的时候，加 MDL 写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。 因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 如果对线上一个频繁DML操作的表做DDL如添加字段等操作，可能会导致死锁，使数据库连接资源被消耗完，导致数据库宕机。安全的解决方式是对表做DDL如添加字段时，设置执行语句的超时时间，写锁超时自动释放，不影响读锁。

MySQL 里面的锁大致可以分成

* 全局锁
* 表级锁
* 行锁

## 6.1 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是` Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。<!--解锁unlock tables 可以给从库加读锁-->

**全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。**

---

**mysqldump 使用参数–single-transaction进行备份可以开启事务为什么需要FTWRL？**

致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。

single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。

**为什么不使用 set global readonly=true 而使用FTWRL？**

set global readonly=true   方式也可以让全库进入只读状态

一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。

二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

三是、在 slave 上 如果用户有超级权限的话 readonly 是失效的

业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，对里面任何一个表做加字段操作，都是会被锁住的。

## 6.2 表级锁

MySQL 里面表级别的锁有两种：一种是表锁（lock tables 表名 read write / unlock tables），一种是元数据锁（meta data lock，MDL)。

> 与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

### 6.2.1 lock tables 

举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。

在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

### 6.2.2 MDL

另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

> 元数据锁是server层的锁，表级锁，主要用于隔离DML（Data Manipulation Language，数据操纵语言，如select）和DDL（Data Definition Language，数据定义语言，如改表头新增一列）操作之间的干扰。每执行一条DML、DDL语句时都会申请MDL锁，DML操作需要MDL读锁，DDL操作需要MDL写锁（MDL加锁过程是系统自动控制，无法直接干预，读读共享，读写互斥，写写互斥）

因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

* 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
* 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

### 6.2.3 为什么给一个小表加个字段，导致整个库挂了

> 给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111251636592.jpg)

我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。

之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。

如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。

如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。

你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

参考

https://blog.csdn.net/q2878948/article/details/96430129

### 6.2.4 如何安全地给小表加字段？

1. 解决长事务，事务不提交，就会一直占着 MDL 锁。要考虑先暂停 DDL，或者 kill 掉这个长事务。

2. 比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。

```mysql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```

## 总结

表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：

1. 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；
2. 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。
3. 

MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。

## FAQ

**备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？**

**当备库用–single-transaction 做逻辑备份的时候，如果从主库的 binlog 传来一个 DDL 语句会怎么样？**

假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：

```mysql
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
/***开启一致性视图，一致性试图不包含表结构**/
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```

在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);

启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；

设置一个保存点，这个很重要（Q3）；

> 两阶段锁，事务回滚或者提交时，才会释放锁。Q6之后还需要备份其他表。备份期间会占用MDL读锁，设置回滚点，读完数据后，回滚释放锁。将锁的占用时间控制到最短。
>
> 备份过程中会有多个mdl锁，一个表一个（假设有tn个表）如果不设置savepoint，第一个表读完后，表1的dml锁还不会释放，会一直等tn的表读完，事务提交才会释放所有表的锁，所以时间会很长

show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5），回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6）。<!--ROLLBACK TO SAVEPOINT：目的是释放锁-->

DDL 从主库传过来的时间按照效果不同，下面有四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成

1. 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。
2. 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；<!--获取表结构和后面的select是强相关的，但是到这时还没有加锁，因此，此时是可以执行dll语句的，当获取表结构后再select的时候发现表结构变更了就会报错，估计是为了备份创建的表结构和当前的结构不匹配导致的-->
3. 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。<!--已经持有了 MDL 的读锁，阻塞 binlog 的 DDL 操作。-->
4. 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。<!--从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。-->

------

**online ddl**

Online DDL的过程是这样的：
1. 拿MDL写锁
2. 降级成MDL读锁
3. 真正做DDL
4. 升级成MDL写锁
5. 释放MDL锁

**全局锁和表锁是Server层实现的**

**如何对大表添加字段**

使用Gh-ost

**关于表字段设计的建议**

建议全小写和下划线



# 七、行锁，如何减少行锁对性能的影响

> MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。

## 7.1 两阶段锁

在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。**

假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：

1. 从顾客 A 账户余额中扣除电影票价；
2. 给影院 B 的账户余额增加这张电影票价；
3. 记录一条交易日志。

根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。

<!--需要进行死锁检测，即使只有100个线程事务，但死锁检测的复杂度是o(n^2)，会需要10000个数量级的检测，所以出现cpu消耗高，并发事务却没多少的情况-->

如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？

## 7.2 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111261024389.jpg)

这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

* 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。

* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数` innodb_deadlock_detect `设置为 on，表示开启这个逻辑。

在 InnoDB 中，`innodb_lock_wait_timeout `的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。

但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。

所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。<!--死锁的处理策略，破坏死锁的几个条件 互斥 占有并等待 不可剥夺 循环等待-->

你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

<!--过程示例：新来的线程F，被锁了后就要检查锁住F的线程（假设为D）是否被锁，如果没有被锁，则没有死锁，如果被锁了，还要查看锁住线程D的是谁，如果是F，那么肯定死锁了，如果不是F（假设为B），那么就要继续判断锁住线程B的是谁，一直走知道发现线程没有被锁（无死锁）或者被F锁住（死锁）才会终止-->

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。

### 7.2.1 如何解决由这种热点行更新导致的性能问题呢？

* **可以将临时思死锁检测关闭** 但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。
* **控制并发度** 比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。

* **对更新同一行的请求进行排队**，对于相同行的更新，在进入引擎前排队，这样在 InnoDB 内部就不会有大量的死锁检测工作了。
* **设计角度，将一行数据变成多行** 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。相当于子账户的概念，原理上就是分段汇总，Java原子类LongAdder也使用了这个原理。这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。

## 结论

如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。

减少死锁的主要方向，就是控制访问相同资源的并发事务量。

## FAQ

**如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：**

* 第一种，直接执行 delete from T limit 10000;
* 第二种，在一个连接中循环执行 20 次 delete from T limit 500 order by id;
* 第三种，在 20 个连接中同时执行 delete from T limit 500。



你会选择哪一种方法呢？为什么呢？

如果一定要在这三个中选，肯定选第二个。 第一个事务太长，执行时间过长， 如果是主备形式的，影响数据同步的时间。 这么多数据如果回滚的话，那该是多痛苦的事情 加锁的时间过长，会造成锁超时的 第三个，很明显有并发问题，如果产生循环等待就是死锁了。 其实可以把id利用起来，20个连接，每个都删500个id，岂不更好。

第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。<!--从库回放relay log的时候也会锁很久（占用MDL锁，导致同步DDL的binlog延迟），导致主库同步过来的binlog阻塞，造成主从延迟-->

第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。

**关于死锁检测innodb_deadlock_detect，每条事务执行前都会进行检测吗？**

如果他要加锁访问的行上有锁，他才要检测。

1. 一致性读不会加锁，就不需要做死锁检测；

2. 并不是每次死锁检测都都要扫所有事务。比如某个时刻，事务等待状态是这样的：

  B在等A，
  D在等C，
  现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个检测不用管B和A

---

**innodb行级锁是通过锁索引记录实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表吗？**

如果列上没有索引，更新就是走主键索引树，逐行扫描满足条件的行，等于将主键索引所有的行上了锁，假如加上limit 1,扫描 主键索引树，直到找到第一条满足条件的行，扫描过的行都会被加上行锁。即为->如果update的列没建索引，即使只update一条记录也会锁定整张表

1. 当加上limit1之后 更新语句的执行流程是先去查询在去更新,也就是查询sql为 select * from t where name = "abc" limit 1 for update,相当于扫描主键索引找到第一个满足name="abc"的条件为止,此时锁的区间为(负无穷,当前行的id],如果在这个id之后的更新和插入时都不会锁住的,在这个id之前的更新和插入会阻塞,之后则不会阻塞

2. 如果不加limit 1的话,因为此时是整个主键索引全表扫描则整个表锁住了

3. 回表的行锁,比如字段name有普通索引,在更新操作时普通索引会锁住的同时,如果更新操作需要回表的话对应的主键索引也会存在锁(主键索引锁临界锁会退化为行锁),普通索引(间隙锁和行锁)

 如果隔离级别是rr的话，那就说明你不能出现不可重复读，所以当你在用没有索引的字段当where条件更新的话，并且没有加limit，那么mysql会扫描主键然后锁住所有的行，因为他就是要保证他在更新的时候，别的事务不能搞事情啊，要别人插入一条，或者更新了一条，恰好又满足我刚才那个where条件 ，那就违反了当前的隔离级别了，当然rc条件下，就无所谓了，反正我的隔离级别下会出现不可重复读，别人要要更新那请便，只要不搞我当前扫描到这行就行了（因为他加了行锁）。加了limit 亦然，rr下，我扫描到的这前多少行你不能给我搞事情，搞了就违反我的隔离级别，所以他锁住了前多少行，后面爱咋搞咋搞。rc也无所谓，也只是行锁，锁住那几行。

---

**不支持行锁的引擎，只能使用表锁，而表锁同一张表在同一时刻只能有一个更新。但是上节课讲的表级锁中的MDL锁，dml语句会产生MDL读锁，而MDL读锁不是互斥的，也就是说一张表可以同时有多个dml语句操作。感觉这两种说法有点矛盾**

不矛盾，MDL锁和表锁是两个不同的结构。

比如：
你要在myisam 表上更新一行，那么会加MDL读锁和表的写锁；
然后同时另外一个线程要更新这个表上另外一行，也要加MDL读锁和表写锁。

第二个线程的*MDL读锁是能成功加上*的，但是被表写锁堵住了。从语句现象上看，就是第二个线程要等第一个线程执行完成。

**update会持有读MDL。读和读不互斥。但是对于行锁来说。两个update同时更新一条数据是互斥的。这个是因为多种锁同时存在时，以粒度最小的锁为准的原因么？**

不是“以粒度最小为准”
而是如果有多种锁，必须得“`全部不互斥`”才能并行，只要有一个互斥，就得等。

**如果开启事务，然后进行死锁检测，如果发现有其它线程因为这个线程的加入，导致其它线程的死锁，这个流程能帮着分析一下么**

理论上说，之前没死锁，现在A加进来，出现了死锁，那么死锁的环里面肯定包含A，
因此只要从A出发去扫就好了

**如何在死锁发生时,就把发生的sql语句抓出来,？**

 show engine innodb status 里面有信息，不过不是很全…

> 一般中间件每次执行事务时，都会重置状态。比方说spring托管的事务会有重置代码，最明显的就是在spring事务切面的代码里，从getConnection()时就有类似的代码。对于发生死锁如何排查，一般是dba去做，其实mysql库表里是有的，开发一般是不给权限查的，这里只贴下自己写的，做抛砖引玉
> SELECT r.trx_id waiting_trx_id,
>    r.trx_mysql_thread_id waiting_thread,
>    r.trx_query waiting_query,
>    b.trx_id blocking_trx_id,
>    b.trx_mysql_thread_id blocking_thread,
>    b.trx_query blocking_query
> FROM information_schema.innodb_lock_waits w
>    INNER JOIN information_schema.innodb_trx b
>        ON b.trx_id = w.blocking_trx_id
>    INNER JOIN information_schema.innodb_trx r
>        ON r.trx_id = w.requesting_trx_id;

**在使用连接池的情况下,连接会复用.比如一个业务使用连接set sql_select_limit=1,释放掉以后.其他业务复用该连接时,这个参数也生效.请问怎么避免这种情况,或者怎么禁止业务set session？**

 5.7的reset_connection接口可以考虑一下

> 在业务里，比如使用mybatis使用数据库的连接池，一个事务获取一个连接时，另一个事务这时是获取不到这个连接的，只有一个事务执行完释放连接到连接池，其它事务才能获取到，而释放后的连接已经被恢复到获取时的状态，包括自动提交等设置

**双11的成交额,是通过redis累加的嘛？**

用redis的话，为了避免超卖需要增加了很多机制来保证。修改都在数据库里执行就方便点。前提是要解决热点问题

**关于使用char类型id索引失效问题**

原因是id 是char 类型，但是没有加单引号，所以没有进入id索引中，然后锁表了，所以导致死锁。

sql：delete from 表A where id =15426169754750004759008 STORAGEDB
(id是主键)

会出现隐式转换函数, ID索引会失效, 走全表扫描



# 八、事务隔离

```mysql
CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2);
```

![事务 A、B、C 的执行流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111261434878.png)

begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。<!--数据库在设计的时候，一定会考虑最大程度的支持事务之间的并发，那它一定会让锁的时间尽可能短-->

第一种启动方式，一致性视图是在执行第一个==快照读语句==（select ）时创建的；

第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。

在 MySQL 里，有两个“视图”的概念：

> 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。
>
> 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。
>
> 它没有物理结构，通过高低水位，数据版本号，undo日记来进行判断数据可见不可见，作用是事务执行期间用来定义“我能看到什么数据”。

## 8.1 “快照”在 MVCC 里是怎么工作的？

在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。<!--基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)
如果在事务内select t表,另外的事务执行了DDL t表,根据发生时间,要嘛锁住要嘛报错(参考第六章)-->

InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。

也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111261456872.png)

要获取旧版本的数据行时，可以通过最新版本的数据和最新版本到目的版本之间的 Undo Logs 计算出来，因为 Undo Logs 记录了每个对应版本对应行数据的值。 Undo Logs 中分为两种类型: 1. INSERT_UNDO（INSERT操作），记录插入的唯一键值； 2. UPDATE_UNDO（包含UPDATE及DELETE操作），记录修改的唯一键值以及old column记录。

事务执行之后，其他事务的更新对它虽然不可见，但是数据版本还是可见的，因为数据库实际上存储的是最新版本的数据。但是对于该事务来说，需要根据版本号以及Undo Logs计算出他需要的版本对应的数据

因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。

如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。

## 8.2 视图

**在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。**

<!--判断事物开启条件的一种是begin 并且执行第一个'操作 'InnoDB 表的语句，所以我第一句只执行非select的dml语句就会生成事务id，但是并不会生成一致性视图，在我要执行select的时候 其它事物可能已经创建。所以对于视图数组就会出现比当前事务id还大并且没有提交的事物，同理也会出现比当前事务还小且没有提交的事物。所以假如当前事务id为88 ，活跃数组就可能有[72,79,88,90,91] 不连续的原因也知道吧，就是因为在生成一致性视图的时候中间短事务早就提交了-->

事务id再当前读才会申请而UPDATE、DELETE、INSERT、SELECT ... LOCK IN SHARE MODE、SELECT ... FOR UPDATE是当前读。

数组里面事务 ID 的最小值记为低水位，==当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位==。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

**为什么数组中要保存当前所有事务ID**

> Innodb 要保证这个规则：事务启动以前所有还没提交的事务，它都不可见。
>
> 但是只存一个已经提交事务的最大值是不够的。 因为存在一个问题，那些比最大值小的事务，之后也可能更新（就是你说的98这个事务）
>
> 所以事务启动的时候还要保存“现在正在执行的所有事物ID列表”，如果一个row trx_id在这列表中，也要不可见。

而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111261518663.png)

<!--这张图应该是在申请事务ID时，事务的状态-->

1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
3. 如果落在黄色部分，那就包括两种情况a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

比如，对于图 2 中的数据来说，如果有一个事务，它的低水位是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 计算出 V3，所以在它看来，这一行的值是 11。

**InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。**

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。



**反向推到为什么不直接判断是否在视图数组中**

> 为什么不直接判断该事务ID是否存在于活跃事务数组中呢？这样还简便得多呀！
>    确实，这样实现起来简单，但效率不行。上述方式，虽然实现和理解起来稍微复杂，但效率很高，实现它的一个前提条件就是事务ID要根据创建时间有序递增，才能快速鉴别出一定可见和一定不可见的情况（情况1、2）。其实我觉得实现的原理思想和布隆过滤器的思想很相似，先快速鉴别出一定可见和不可见的数据（第1、2种），然后对于可能可见和可能不可见的数据（第3种）通过活跃数组进行精确判断。

**当开启事务时，需要保存活跃事务的数组（A），然后获取高水位（B）。在这两个动作之间（A和B之间）会不会产生新的事务？如果产生了新的事务，那么这个新的事务相对于当前事务就是可见的，不管有没有提交?**

> 代码实现上，获取视图数组和高水位是在事务系统的锁保护下做的，可以认为是原子操作，期间不能创建事务。

## 8.3 更新逻辑

**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

**除了 update 语句外，select 语句如果加锁，也是当前读。**

下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。

```mysql

mysql> select k from t where id=1 lock in share mode;
mysql> select k from t where id=1 for update;
```

可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：

1. 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
2. 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

## 8.4 小结

**InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。**

* 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
* 对于读提交，查询只承认在语句启动前就已经提交完成的数据；

而当前读，总是读取已经提交完成的最新版本。

**为什么表结构不支持“可重复读”？**

这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。

**8.0已经把表结构放到InnoDB字典里，表结构支持可重复读。在mysqldump过程中修改表结构并不会导致程序终止了。**

## FAQ

### 减库存场景

当前库存：num=200
假如多线程并发：
AB同时开启事务，A先请求到行锁，

| 事务A                                                   | 事务B                                                   |
| ------------------------------------------------------- | ------------------------------------------------------- |
| start transaction;                                      | start transaction;                                      |
| select num from t where num>0;先查询当前库存值（num>0） |                                                         |
| update t set num=num-200; 库存减量                      | select num from t where num>0;先查询当前库存值（num>0） |
| Commit                                                  | update t set num=num-200; 库存减量                      |
|                                                         | Commit                                                  |


A：查询到num=200,做了库存减量成了0
B：事务启动后，查询到也是200，等 A 释放了行锁，B进行update，直接变成 -200
但是 B 查询时，时有库存的，因此才减库存，结果变成负的。

给 select 加读锁或者写锁吗 ？这种select 加锁，对业务影响大吗？

> 一开始Select 加锁虽然可以，但是会比较严重地影响并发数。
>
> 比较简单的做法是update语句的where 部分加一个条件： where nun >=200 .
> 然后在程序里判断这个update 语句的affected_rows,
> 如果等于1 那就是符合预期；
> 如果等于0，那表示库存不够减了，业务要处理一下去，比如提示“库存不足”

**思考**

如果使用乐观锁的话但在并发条件下更新，完全的cas会导致较多的更新失败。其实这里解决的是num不能被减成负，所以使用num>=200来保证就可以了。既保证业务正确，也提高并发性能，解决并发量适中的场景也只能这样. 如果并发太高, 那就是hot key problem, 后来的写入会timeout. 这就要用(写)缓存或者消息队列来辅助处理了.

# 九、普通索引与唯一索引如何选择

## 9.1 索引

### 9.1.1 概念

索引就好比一本书的目录，它会让你更快的找到内容，显然目录(索引)并不是越多越好，假如这本书1000页，有500也是目录，它当然效率低，目录是要占纸张的,而索引是要占磁盘空间的。

### 9.1.2 Mysql索引结构

Mysql索引主要有两种结构：B+树和hash.

* **hash:**hsah索引在mysql比较少用,他以把数据的索引以hash形式组织起来,因此当查找某一条记录的时候,速度非常快.当时因为是hash结构,每个键只对应一个值,而且是散列的方式分布.所以他并不支持范围查找和排序等功能.

* **B+树:**b+tree是mysql使用最频繁的一个索引数据结构,数据结构以平衡树的形式来组织,因为是树型结构,所以更适合用来处理排序,范围查找等功能.相对hash索引,B+树在查找单条记录的速度虽然比不上hash索引,但是因为更适合排序等操作,所以他更受用户的欢迎.毕竟不可能只对数据库进行单条记录的操作.

### 9.1.3 Mysql常见索引

* **主键索引(PRIMARY KEY()：**  是一种特殊的唯一索引，不允许有空值。

  ```mysql
  ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
  ```

  

* **唯一索引(UNIQUE)：**与"普通索引"类似，不同的就是：索引列的值必须唯一，但允许有空值。

  ```mysql
   ALTER TABLE `table_name` ADD UNIQUE (`column`)
  ```

  

* **普通索引(INDEX)：**最基本的索引，没有任何限制

  ```mysql
    ALTER TABLE `table_name` ADD INDEX index_name ( `column` ) 
  ```

  

* **全文索引(FULLTEXT)：**仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时耗空间。

  ```mysql
   ALTER TABLE `table_name` ADD FULLTEXT ( `column` )
  ```

  

* **组合索引：**为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。

  ```mysql
  ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
  ```

  

## 9.2 性能分析





![InnoDB 的索引组织结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111271940806.png)

### 9.2.1 查询过程

假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。

* 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
* 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

**这种不同对查询的性能微乎其微**

InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。

当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。

但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

### 9.2.2 更新过程

#### 9.2.2.1 change buffer

> insert buffer是对于非唯一辅助索引更新的优化。对于主键索引来说我们可以通过设置increment_id来实现顺序插入，但是对于辅助索引往往难以保证更新的顺序性，这样可能会导致每次对于辅助索引insert都是离散的，需要遍历整张表找到插入位置，从IO角度来说效率低，而且会将无用页读入内存占用空间，所以使用insert buffer来实现对于索引延时更新，当发生insert的时候，如果索引页在内存中，则更新，不再内存中则将更新记录到 insert buffer中，当索引页被读入到内存的时候再执行 merge 操作。 后面的innodb版本，不仅支持insert，同时还支持 update ，delete操作所以称为change buffer！！！

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。<!--这里说的数据页，指的是二级索引树的数据页，并不是聚簇索引即主键树的数据页。 如涉及到索引字段的更新，也是要更新对应的索引数据的，而索引树对应的数据页不在内存中，则changeBuffer会先保存这个数据，之后会和对应的数据页进行merge过程。 redoLog也是会记录这一动作的，所以更新对应索引树的数据不会丢失。-->

需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。<!--change buffer可以看成也是一个数据页，需要被持久化到 系统表空间（ibdata1），以及把这个change buffer页的改动记录在redo log里，事后刷进系统表空间（ibdata1）。-->

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。

**为什么要使用change buffer ？**

首先要明确概念： 

1. mysql数据存储在主键索引树的叶子节点。 

2. 普通索引和唯一索引也都有自己的索引树，树的叶子节点存储的是主键ID。

3. 做更新操作（插入，更新，删除）会同时更新所有的索引树结构。---------insert：主键索引树和唯一建索引树的肯定都要更新，肯定是无法用到change buffer的；但是普通索引树的更新，是可以使用change buffer的。 update：只要涉及到相关字段更新，就要同时更新相应的索引树。道理同上。 【显然，insert操作的影响更大，如果有多个唯一索引，insert对内存命中率会有极大影响】 


1. 减少读磁盘：仅仅是减少的是对二级普通索引页的读磁盘操作，而对于其他类型的页(唯一索引，主键索引)还是要读磁盘的。 
2. 减少内存占用：change buffer虽然还是需要内存占用(记录数据更新动作)，但相比于数据页来说(默认16K)，所占的内存还是小了很多的。



**什么时候使用change buffer，以及为什么唯一索引不使用**

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

唯一索引更新导致性能降低的原因应该是：必须把数据页加载到内存中进行判断涉及到的随机io的读写

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 `innodb_change_buffer_max_size`来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

**如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。**

第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB 的处理流程如下：

* 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
* 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB 的处理流程如下：

* 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
* 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。

将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。<!--注意这里是insert操作。insert操作必然要更新所有的索引树，当然就包括了唯一索引树，那么在更新这棵树的时候就用不上change buffer，就需要频繁访问磁盘，降低内存命中率。而update操作，只要不涉及到唯一索引字段的更新，就不会去更新唯一索引树，所以update操作的消耗是比较低的。所以涉及到有大量insert的业务场景，发生内存命中率低的问题，就需要考虑是不是索引的问题了。-->

## 9.3 change buffer 的使用场景

> change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么.

**现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？**

因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

## 9.4 索引选择和实践

这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。

如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。

特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。<!--也就是读少写多的场景-->

## 9.5 什么是buffer pool

> 硬盘在读写速度上相比内存有着数量级差距，如果每次读写都要从磁盘加载相应数据页，DB的效率就上不来，因而为了化解这个困局，几乎所有的DB都会把缓存池当做标配（在内存中开辟的一整块空间，由引擎利用一些命中算法和淘汰算法负责维护和管理），change buffer则更进一步，把在内存中更新就能可以立即返回执行结果并且满足一致性约束（显式或隐式定义的约束条件）的记录也暂时放在缓存池中，这样大大减少了磁盘IO操作的几率

## 9.6 change buffer 和 redo log

理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。

> redo log 与 change buffer(含磁盘持久化) 这2个机制，不同之处在于优化了整个变更流程的不同阶段。 先不考虑redo log、change buffer机制，简化抽象一个变更(insert、update、delete)流程： 
>
> 1、从磁盘读取待变更的行所在的数据页，读取至内存页中。
>
>  2、对内存页中的行，执行变更操作 
>
> 3、将变更后的数据页，写入至磁盘中。
>
>  步骤1，涉及 随机 读磁盘IO； 步骤3，涉及 随机 写磁盘IO；
>
>  --change buffer机制，优化了步骤1,避免了随机读磁盘IO; 
>
> --redo log机制， 优化了步骤3,避免了随机写磁盘IO，将随机写磁盘，优化为了顺序写磁盘(写redo log，确保crash-safe) ；
>
>  --在我们mysql innodb中， change buffer机制不是一直会被应用到，仅当待操作的数据页当前不在内存中，需要先读磁盘加载数据页时，change buffer才有用武之地。 redo log机制，为了保证crash-safe，一直都会用到。

**对于以下语句分析执行流程**

```mysql
insert into t(id,k) values(id1,k1),(id2,k2);
```

这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。

![change buffer 的更新过程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111281556442.png)

* 内存、
* redo log（ib_log_fileX）、
*  数据表空间（t.ibd）、数据表空间：就是一个个的表数据文件，对应的磁盘文件就是“表名.ibd”；
* 系统表空间（ibdata1）。系统表空间：用来放系统信息，如数据字典等，对应的磁盘文件是“ibdata1”

这条更新语句做了如下的操作（按照图中的数字顺序）：

1. Page 1 在内存中，直接更新内存；

2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”

3. 这个信息将上述两个动作记入 redo log 中（图中 3 和 4）。

做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。

**那么在这之后新来了一个select请求如何处理**

比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。

如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111281600997.png)

从图中可以看到：

1. 读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。
2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。<!--merge的时机应该是读取数据页到内存中的时候，这时会先在内存的change buffer找有没有修改，没找到继续到磁盘的change buffer找，如果都没有找到证明这个数据页没有修改。
   change buffer内容会通过redo log刷到磁盘页吗？不会，是通过内存/磁盘中的change buffer刷的。-->

所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**

## 小结

redo日志有分几十种类型的。redo做的事情，简单讲就是记录页的变化（WAL将页变化的乱序写转换成了顺序写）。页是分多种的，比如 B+树索引页（主键 / 二级索引）、undo页（数据的多版本MVCC）、以及现在的change buffer页等等，这些页被redo记录后，就可以不着急刷盘了。change buffer记录索引页的变化；但是change buffer本身也是要持久化的，而它持久化的工作和其他页一样，交给了redo日志来帮忙完成；redo日志记录的是change buffer页的变化。 change buffer持久化文件是 ibdata1，索引页持久化文件是 t.ibd

唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。

1. changebuffer跟普通数据页一样也是存在磁盘里，区别在于changebuffer是在共享表空间ibdata1里
2. redolog有两种，一种记录普通数据页的改动，一种记录changebuffer的改动
3. 只要内存里脏页（innodb buffer pool）里的数据发生了变化，就一定会记录2中前一种redolog
   （对数据的修改记录在changebuffer里的时候，内存里是没有这个物理页的，不存在脏页）
4. 真正对磁盘数据页的修改是通过将内存里脏页的数据刷回磁盘来完成的，而不是根据redolog



change Buffer和数据页一样，也是物理页的一个组成部分，数据结构也是一颗B+树，这棵B+树放在共享表空间中，默认ibdata1中。change buffer 写入系统表空间机制应该和普通表的脏页刷新到磁盘是相同的机制--Checkpoint机制；之所以change buffer要写入系统表空间，是为了保证数据的一致性，change buffer做修改时需要写redo log，在做恢复时需要根据redo log来恢复change buffer，若是不进行change buffer写入系统表空间，也就是不进行持久化，那么在change buffer写入内存后掉电（也就是篇尾提出的问题），则无法进行数据恢复。这样也会导致索引中的数据和相应表的相应列中的数据不一致。change buffer 写入到了系统表空间，merge 的时候会先查询change buffer里对应的记录，然后进行purge，因为change buffer B+树的key是表空间ID，所以查询根据表空间ID 查询change buffer会很快。



**注意**

> redo日志有分几十种类型的。redo做的事情，简单讲就是记录页的变化（WAL将页变化的乱序写转换成了顺序写）。页是分多种的，比如 B+树索引页（主键 / 二级索引）、undo页（数据的多版本MVCC）、以及现在的change buffer页等等，这些页被redo记录后，就可以不着急刷盘了。change buffer记录索引页的变化；但是change buffer本身也是要持久化的，而它持久化的工作和其他页一样，交给了redo日志来帮忙完成；redo日志记录的是change buffer页的变化。
> change buffer持久化文件是 ibdata1，索引页持久化文件是 t.ibd。

首先明确一个观点，redo log最大的作用，就是用于数据库异常宕机的恢复工作。
如果数据库永远不会宕机，那么不需要 redo log。redo log 和 change buffer其实关注的是两个事情，不能混为一谈。

其次，数据库缓冲池中有如下内容：数据页，索引页，插入缓冲，等等其他页（其他页目前不需要了解），数据页可以理解为叶子节点，索引页可以理解为非叶子节点，插入缓冲就是老师这节课讲的 change buffer。

当做insert update delete操作时，会涉及到两方面的更新，一类是主键索引B+树，另一类的非主键索引B+树。针对，主键索引B+树和 非主键索引中的唯一索引B+树，如果在内存中，直接更新内存；如果不在内存，直接从数据库中读取页到内存中来，更新内存即可。针对非主键索引的普通索引B+树，如果树在内存中，直接更新内存；如果不在内存中，更新change buffer，等到后面需要使用这个树的时候，会从磁盘中读取，然后做merge操作。

有同学问，到底是依据change buffer磁盘还是依据redo log更新磁盘，我的回答是，他们都不会直接更新磁盘，刷新磁盘的工作是innodb存储引擎中的线程去做的。redo log负责的是 异常宕机的恢复；change buffer用于 提高普通索引更新的性能。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111282128560.png)

## FAQ

**你可以看到，change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？**



---

**如果是针对非唯一索引和唯一索引的更新和delete而且条件是where 索引值=这种情况,是否二级索引和唯一索引就没有区别呢**

这时候要“先读后写”，读的时候数据会读入内存，更新的时候直接改内存，就不需要change buffer了

change buffer就是为了延迟更新数据的时候对二级索引的更新，而where 索引值=，就是用的二级索引来更新的，更新之前得先把二级索引的树读出来，既然已经读出来了，就可以直接更新了，没必要用change buffer了

**如何判断内存命中率**

Hit rate

**change buffer相当于推迟了更新操作，那对并发控制相关的是否有影响，比如加锁？我一直以为加锁需要把具体的数据页读到内存中来，才能加锁，然而并不是？**

锁是一个单独的数据结构，如果数据页上有锁，change buffer 在判断“是否能用”的时候，就会认为否

change Buffer 针对的对象是索引页，锁是加在数据页上的吧。如果更新的时候发现数据页已经有锁了，change Buffer自然会失效 

**Merge 行为之后还会产生redo log吗？**

第一步，merge其实是从磁盘读数据页到内存，然后应用，这一步都是更新的内存，同时写redolog

现在内存变成脏页了，跟磁盘数据不一样。之后就走刷脏页的流程。刷脏页也不用写。

个人理解会产生的因为第一次redo log 记录的是change buffer对应的页，而merge过程记录的是内存页

**为什么change buffer已经使用了redo log 还需要持久化**

猜想大概是因为change buffer 需要快速的检束出数据以便于进行merge操作，所以必须要保持B+树这种高效的结构，再者就是redo log 的空间有限，不能存很多数据

当数据库崩溃时可以通过redo log将change buffer内容回放出来。” 是的，所以change buffer其实也是用了WAL机制。

**change buffer中存的内容是“在某个数据页更新什么”，但是在update/insert时，确定这条记录更新/插入在哪个数据页，不也是有一个查找的过程么？（肯定有一个一层层查找的过程，会路过很多数据页啊）为了确定在哪个数据页操作而遍历过的数据页也会读进内存作缓存吗？**

是的，查找过程避不开，但是二级索引树的非叶子节点没多少，主要在磁盘上的还是叶子节点。

准确来说在二级索引的叶子节点的上一层节点中就可以确定要插入到哪一页中，因为在二级索引的叶子节点时索引列+主键值，他的非叶子节点中每页存储的是叶子节点中每一页中最小的那个索引列+主键的一条记录+页号，当我们插入的时候就可以从最后一层的非叶子节点中找到应该插入的页

查非叶子节点，都是在内存中进行的。查叶子节点，并且将这页载入到内存， 这个比较耗时，特别是在写多读少的场景下，性能差很多

**如果说因为内存不足需要回收change buffer这部分内存，那也应当将数据merge后刷入磁盘吧。**

“内存不足需要回收change buffer这部分内存“，只需要让change buffer本身持久化可以，不需要执行merge操作。merge操作是在读数据页的时候做的

**update操作不是先读后写吗？如果是先读的话，不是应该把数据已经读到内存了吗？那这样的话直接更新内存不就好了，为什么还要写change buffer**

 如果一个表上有字段 a, b, 且有普通索引c， update语句为 update xxx set a = 'xxx' where c = 'xxx'， 执行这个语句的时候， 因为要判断c = 'xxx' 的记录是否存在， 存在的话才会更新， 此时必定要将c 索引的内存页载入到内存中（执行计划会走索引c) ， 修改内存页，写redo log; 同时主键索引页也要载入内存进行修改（主键索引永远都需要先读后写，这个免不了）。这个就用不到Change Buffer。
但是如果是另外一种场景： update xxx set a = 'xxx' where b = 'xxx' ， 这个时候因为查询条件不走索引c，故不需要将c的数据页载入内存， 针对索引c上的修改就写入到Change Buffer， 但是针对主键索引，还是要先载入内存再修改。 此时的优化就是针对索引c的页的随机io的优化。

**关于change buffer 主要节省的则是随机读磁盘的 IO消耗这个点，我的理解是如果没有change buffer机制，那么在执行更新后（写入redolog），读取数据的时候需要从次磁盘随机读取redolog合并到数据中，主要减少的是这部分消耗？**

不是，如果没有change buffer, 执行更新的“当时那一刻”，就要求从磁盘把数据页读出来（这个操作是随机读）。

**数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。后面又说change是占用pool内存的，那到底占不占用buffer pool的内存**

1. change buffer本身是占用内存的；
2. 但是chage buffer本身只是记录了“更新过程”，远远比数据页（一个16k）小。相比于把数据页读入内存，这个方式还是省了内存的。

**change buffer的持久化是不是考虑到随着事务的运行，内存中已经存放不下change buffer了，所以才考虑要持久化到系统表空间中去的？**

change buffer的写盘策略跟数据一样，内存放不下会触发落盘，还有checkpoint推进的时候也是可能会出发



**对于二级普通索引，update t where k=？这种语句，执行的时候，是先读后写吗，也就是先按k索引树将相应索引页都加载到内存，然后再按主键索引将数据页面加载到内存？还是按照文中提到的先记录到change buffer？**

如果是where k= N 是要先读的（确保数据存在）

读的是主键b+树，带数据，但是不用读普通索引的B+树，意思就是change buffer只缓存了普通索引的B+树的操作，只有要使用这个索引的时候，这些操作才能真正生效，

**changeBuffer 更新过程**

changeBuffer详细一点来说是对普通索引页的优化。
普通索引（name） （age）主键（id）
（4，张三）
语句一:update name=李四 where id = 4
语句二:update age where name='李四'
可知主键为聚簇索引，存着整行数据。普通索引存着当前索引段的数据和主键值。
语句一:
1.主键数据（页）读到内存，修改主键上的数据行。
2.修改普通索引name上的name字段数据。
第一步是必须读盘到内存中的，然后修改对应数据,得到修改数据行。第二步是要去修改name索引的数据，这时就可以将此操作放到changeBuffer里，等待下次用到name索引时（用到就会读到内存中），再将其修改，所以就省了第二步的读盘操作。所以普通索引的name暂时是张三。
语句二（紧接着语句一）:
1.name索引数据读到内存，根据hash发现changBuffer上有本次读取页的数据没有改，就顺便改一下。
2.索引到name=李四的id,然后去修改主键中的age数据，修改完主键的后，这时就该去修改age索引的数据了，但age是普通索引，所以会将操作放到changeBuffer里，等待时机去更新。

**在不读磁盘的情况下，delete/update影响行数如何获取？**

不可能完全不读盘的，只是说可能某些二级索引可以不用读盘，不管做的是insert, update还是delete操作，都涉及到主键索引上数据的更新，主键索引的相关页都是需要载入内存的，通过主键索引的变化就可以获取影响行数

# 十、MySQL为什么有时候会选错索引

首先创建一个表

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```

然后，我们在表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。

```mysql
create procedure idata()
begin
declare i int;
set i=1;
start TRANSACTION;
while(i<=100000)do
insert into t(a, b) values(i, i);
set i=i+1;
end while;
commit;
end;


```

接下来，我们分析一条 SQL 语句：

```mysql
select * from t where a between 10000 and 20000;
```

![image-20211207111653178](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112071116283.png)

使用以下的方法进行测试

![session A 和 session B 的执行流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112071117791.png)

随后，session B 把数据都删除后，又调用了 idata 这个存储过程，插入了 10 万行数据。这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。

为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 `force index(a) `来让优化器强制使用索引 a

下面的三条 SQL 语句，就是这个实验过程。

```mysql
set long_query_time=0;
select * from t where a between 10000 and 20000; /*Q1*/
select * from t force index(a) where a between 10000 and 20000;/*Q2*/
```

* 第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；
* 第二句，Q1 是 session B 原来的查询；
*  第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。

下面是慢查询日志

```mysql
# Time: 2021-12-07T02:51:36.018162Z
# User@Host: root[root] @  [172.18.0.1]  Id:  1545
# Query_time: 0.034452  Lock_time: 0.000118 Rows_sent: 10001  Rows_examined: 100000
SET timestamp=1638845495;
/* ApplicationName=DataGrip 2021.3.1 */ select * from t where a between 10000 and 20000;
```

```mysql
# Time: 2021-12-07T02:52:35.324978Z
# User@Host: root[root] @  [172.18.0.1]  Id:  1545
# Query_time: 0.009915  Lock_time: 0.000091 Rows_sent: 10001  Rows_examined: 10001
SET timestamp=1638845555;
/* ApplicationName=DataGrip 2021.3.1 */ select * from t force index(a) where a between 10000 and 20000;
```

可以看到，Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引，导致了更长的执行时间。

这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。

## 10.1 优化器的逻辑

选择索引是优化器的工作

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。

扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

## **10.2 扫描行数如何判断**

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。

这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。

举个例子，有两个字段，一个是布尔型值有0,1两种情况，一个是枚举型有10个枚举值。分别在两个字段上建索引，布尔型字段索引会把数据分成两部分，枚举型会把数据分成十份，根据索引查找的时候，布尔型选择了一个排除了一半，枚举型选一个会排除9/10，所以枚举型区分度更好

我们可以使用 show index 方法，看到一个索引的基数。如图 4 所示，就是表 t 的 show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112071445860.png)

**MySQL 是怎样得到索引的基数的呢？**

为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”

采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：

* 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
* 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。

你可以从图 中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。

其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112071451182.png)

rows 这个字段表示的是预计扫描行数。

其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116，偏差就大了。而图 1 中我们用 explain 命令看到的 rows 是只有 10001 行，是这个偏差误导了优化器的判断。

如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。

而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。

优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。



使用普通索引需要把回表的代价算进去，在图 1 执行 explain 的时候，也考虑了这个策略的代价 ，但图 1 的选择是对的。也就是说，这个策略并没有问题。

所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。

既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072059815.png)

> 8.0没有测试出和这个问题，在seesion1 提交之后就正常了

在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理

```mysql
select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```

从条件上看，这个查询没有符合条件的记录，因此会返回空集合。

在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？

为了便于分析，我们先来看一下 a、b 这两个索引的结构图。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072101780.png)

如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。

如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。

如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。

```mysql

mysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
```

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072104712.png)

可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。

1. 扫描行数的估计值依然不准确；
2. 这个例子里 MySQL 又选错了索引。



## 10.3 索引选择异常和处理

其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多

> 使用错了索引。
>
> 1. 可以使用force index(key)进行校正。
> 2. 通过修改sql语句诱导优化器选择正确的索引，因为优化器选择索引会考虑三个因素，扫描行数、临时表和排序。
> 3. 重新建立一个更合适的索引。

一种方法是，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。

刚开始分析时，我们认为选择索引 a 会更好。现在，我们就来看看执行效果：

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072113194.png)

可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。

也就是说，优化器没有选择正确的索引，force index 起到了“矫正”的作用

不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。

但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。

所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？

既然优化器放弃了使用索引 a，说明 a 还不够合适，所以**第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引**。比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。

 

我们来看看改之后的效果

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072204120.png)

之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。

现在 order by b,a 这种写法，要求按照 b,a 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。

当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。

```mysql
mysql> select * from (select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 100)alias limit 1;
```

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112072206028.png)

在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。<!--因为b不用排序，又有limit 1，从5w里只要找到一条就可以返回了，如果选择a，因为要排序，就要扫完1000条，然后才能排序，这成本明显太大，所以选择了b。但如果是limit 100，选择b，虽然不用排序，但找到第一条记录后，还要向后查询，看后面有没有满足条件的100个记录，从5w中找100个的成本就大于从1000找100个的成本了，所以选择a。其实limit 20就会选择a了-->

**第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。**

不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。

如果我说还有一个方法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。

## FAQ

**为什么经过这个操作序列，explain 的结果就不对了？**

delete 语句删掉了所有的数据，然后再通过 call idata() 插入了 10 万行数据，看上去是覆盖了原来的 10 万行。

但是，session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。

这样，索引 a 上的数据其实就有两份。

# 十一、怎么给字符串字段加索引

现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。

> **1.为什么需要优化字符串上的索引 如果字符串较长，**
>
> 索引字段占用内存空间大，B+树高度较高，这样查询IO次数较多，耗时长。 个人认为未出现性能瓶颈，不需要过度优化，全字段索引也ok。 
>
> **2.优化方法及优缺点**
>
> 方法一：前缀索引概念：在建立索引的时候指定索引长度，且该长度的字段区分度高 
>
> * 优点： a. 相比全字段索引，每页存储的索引更多，查询索引IO次数少，效率高。即既节省了内存空间，又提高了查询效率。
>
> *  缺点： a. 指定索引长度的区分度低的话，扫描主键索引次数就会多，效率低； b. 不会使用覆盖索引，即使索引长度定义为全字段，也会去主键索引查询 适用场景：前缀索引区分度高 
>
> 方法二：倒序存储 概念：
>
> 字段保存的时候反序存储
>
> *  优点：同前缀索引 
> * 缺点： a.只适用于等值查询，不适用于范围、模糊查询。 b.每次保存、查询时需调用reverse()函数； c.若后缀索引区分度低，扫描行数会增多。 适用场景：索引字段后缀区分度高，前缀区分度低。 
>
> 方法三：添加hash字段，作为索引 概念：在表中添加一个hash字段并加索引，用于存储索引字段的哈希值如使用crc32()哈希函数，每次查询时先计算出字段的hash值，再利用hash字段查询。可能存在hash冲突，所以where需要加索引字段的等值条件。 
>
> 优点：哈希函数冲突概率低的话，平均扫描行数接近1。
>
>  缺点：只适用于等值查询，不适用于范围、模糊查询。 适用场景：只适用于等值查询，不适用范围查询或模糊查询。

假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：

```mysql

create table SUser(
ID bigint unsigned primary key,
email varchar(64), 
... 
)engine=innodb; 
```

由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：

```mysql
 select f1, f2 from SUser where email='xxx';
```

我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。

同时，MySQL 是支持`前缀索引`的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。

比如，这两个在 email 字段上创建索引的语句：

```mysql
alter table SUser add index index1(email);
# 前缀索引，抛开唯一性获得索引空间上的优化，但是也会导致回表次数增多
alter table SUser add index index2(email(6))
```

第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。

那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图 2 和 3 所示，就是这两个索引的示意图。

![email 索引结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112121629239.jpg)

![email(6) 索引结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202112121629520.jpg)

从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。

但，这同时带来的损失是，**可能会增加额外的记录扫描次数。**<!--前缀索引还不能使用覆盖索引-->

接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。

```mysql
select id,name,email from SUser where email='zhangssxyz@xxx.com';
```

如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：

1. 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值；
2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；
3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com’的条件了，循环结束。

这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。

如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：

1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；
2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；
3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；
4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。

过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。

在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。

**通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。**

但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。

**也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**

于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？

实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：

```mysql
 select count(distinct email) as L from SUser;
```

然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：

```mysql
select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。

## 11.1 前缀索引对覆盖索引的影响

前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。

```mysql
select id,email from SUser where email='zhangssxyz@xxx.com';
```

与前面例子中的 SQL 语句

```mysql
select id,name,email from SUser where email='zhangssxyz@xxx.com';
```

相比，这个语句只要求返回 id 和 email 字段。

所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。

即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。

也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。<!--前缀索引的目的并不是在二级索引树上保存更多数据，也做不到减少回表的次数，应该是前缀索引能够减少索引字段长度，节省空间，当和主键联合的时候，无法做到覆盖索引，需要去回表查询，从而导致覆盖索引的优化无法使用，必须要回表，然后确定前缀索引字段的正确性-->

前缀索引肯定不能减少回表次数啊 反而是会 >= 非前缀索引的回表次数。 前缀索引只是减少的数据大小，一个数据页16k可以存储更多的信息，降低树高，减少io次数。

## 11.2 其他方式

对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？

比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。

假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。

按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。

但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。<!--相同的数据页放下的索引值越少，索引树层级会变高，索引搜索效率也会降低-->

那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。

**第一种方式是使用倒序存储。**如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：

```mysql
 select field_list from t where id_card = reverse('input_id_card_string');
```

由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。

**第二种方式是使用 hash 字段。**你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。

```mysql
alter table t add id_card_crc int unsigned, add index(id_card_crc);
```

然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。

```mysql
select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
```

<!--CRC32的基本特征： #1.CRC32函数返回值的范围是0-4294967296（2的32次方减1) #2.相比MD5，CRC32函数很容易碰撞 CRC32的使用场景： 由上述两个基本特性可知，MySQL CRC32 生成整型结果使用用bigint存储，而MD5需要varchar来存储。但是CRC32很容易碰撞-->

<!--在数据库版本满足要求的情况下，最好是使用crc64()，可以降低碰撞几率。-->

这样，索引的长度变成了 4 个字节，比原来小了很多。

**接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。**

首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。<!--倒序和hash都将数据打散，数据没有按照原有字符串的顺序排列。在进行范围查询时，需要进行顺序扫描，此时的扫描范围就会是全表。-->

它们的区别，主要体现在以下三个方面：

1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。
2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

11.3 小结

1. 直接创建完整索引，这样可能比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

## FAQ

如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。

系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？



由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。

# 十二、为什么我的MySQL会抖一下

> 平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。

## 12.1 SQL语句为什么会变慢

InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。

做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。

掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。在这个 flush 操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。**<!--每个表都是一个ibd文件, 每个文件都是分成n个16kb的page. page是IO的基本单位, 也就是从硬盘到内存每次都载入一个page. 所以用到的page既在内存也在硬盘ibd文件里. 在内存page上写写改改后, 这个page没写回ibd文件, 就成了脏页-->

不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。

接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账 10 文，这次又要赊 9 文。

![](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202280954270.jpeg)

回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。

## 12.2 出发flush的场景

1. **redo log满**

第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。这个场景，对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202280958868.jpg)

checkpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。

2. **需要加载新页仅磁盘的时候，内存页不够用，要淘汰的页是脏页，此时需要刷盘** 

第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。

这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。

你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：

* 一种是内存里存在，内存里就肯定是正确的结果，直接返回；
* 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。

3. **mysql认为自己空闲时。**

第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。

这种场景，对应的就是 MySQL 认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。<!--innodb技术内幕里面讲的更详细，master thread 在判断过去1s 的io次数来判断数据库是否忙碌，然后再决定是否刷新脏页-->

4. **正常关闭数据库时** 

第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。这种场景，对应的就是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

## 12.3 四种场景下flush出发对性能的影响。

其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。

第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。

也就是说，更新数据就一套程序，没有备用方案； 更新redo log是必须的一个节点，redo log满了只能排队等待redo log刷出空闲的位置； 我想什么时候redo log才会被写满呢？ 生产的速度远大于消费的速度； 数据库出问题了，cpu和io资源被别的地方大量占用

第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，

* mysql的一个核心理念就是有内存就会用内存，包括读写数据、log（redo）等等的执行动作，因此buffer pool实际是作为一个内存管理器的理念存在的。

----

**缓冲池中的内存页有三种状态：**

第一种是，还没有使用的；

第二种是，使用了并且是干净页；

第三种是，使用了并且是脏页。

在innodb的内存buffer pool中，用 free list 来维护未使用页，用flush list维护脏页，用lru list来维护使用页

InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。<!-- 读入的数据页不在内存中，就会从磁盘读取，如果内存中的FLUSH LIST不空闲，则flush 脏页，如果FLUSH LIST 空闲，则在LRU LIST 上采用LRU算法淘汰“冷数据”-->

而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。

**所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：**

1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。

## 12.4 InnoDB 刷脏页的控制策略

首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。

这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：

```
show global variables like 'innodb_io_capacity'
# 测试随机读写命令
fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest
```

**案例：刷脏参数不合理，导致系统卡顿**

其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就曾有其他公司的开发负责人找我看一个库的性能问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。

他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。

<!--innodb_io_capacity的默认值为200，所以如果主机磁盘用的是SSD，大家建议改为20000.-->

虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看 InnoDB 怎么控制引擎按照“全力”的百分比来刷脏页。

**如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？**

1. 脏页比例 

2. 脏页刷盘速度 

3. 刷新相邻页面策略 （bufferpool脏页比例 或 redolog 都可能成为读写sql的瓶颈） 
   1. 脏页比例默认75%，一定不要让其接近75% innodb_max_dirty_pages_pct =Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 
   2. 刷脏页速度 innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度
   3. innodb_flush_neighbors=0（不开启脏页相邻淘汰） （对于机械硬盘顺序读写会有提升，ssd无提升。iops普通机械硬盘只有几百，ssd有上千，可以不开启） 
   4. 避免大量刷脏页，脏页flush可能会产生内存抖动

这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。

所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。

InnoDB 会根据这两个因素先单独算出两个数字。

参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：

```c
F1(M){ if M>=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct;}
```

InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。<!--直接刷脏页是不会动redolog的，等后续应用redolog的时候，会根据LSN 的大小来判断这个页有没有应用到这条log Logging Sequence Number-->

然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。<!--直接刷脏页是不会动redolog的，等后续应用redolog的时候，会根据LSN 的大小来判断这个页有没有应用到这条log-->

<!--两个值，一个描述的是迫近设置的最大脏页比率的程度；另一个描述的远离checkpoint的程度，取较大者来进行计算，作为百分比与io capacity 值乘，获取当前的脏页刷取速度。 也就是说 脏页比越高（其实是越靠近max值） 或离chdckpoint越远，刷取速度就可能越快-->

上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。图中的 F1、F2 就是上面我们通过脏页比例和 redo log 写入速度算出来的两个值。

![图 3 InnoDB 刷脏页速度策略](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281102684.png)

现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。

<!--其实说到底影响性能的就是IO，和内存使用情况。设计者千方百计的减少IO次数，合理利用内存。采用redo log来顺序的把更新纪录写到磁盘，让操作尽可能的在内存中发生。但最终的IO和内存占满对性能的影响还是要面临的，就算是错峰操作也避免不了一些极端的情况，既然避免不了，那就尽可能的选择更好的时机更顺利的操作去完成这件事。-->

要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且**平时要多关注脏页比例，不要让它经常接近 75%。**

**脏页比例获取**

```mysql
# 其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：

mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

接下来，我们再看一个有趣的策略。

一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。

在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。

找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。<!--找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。-->

而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。

在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。

## 12.5 小结

今天这篇文章，延续第 2 篇中介绍的 WAL 的概念，解释了这个机制后续需要的刷脏页操作和执行时机。利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。

<!--写redo log是直接写进redo log就OK,所以是顺序写；如果要直接更新到数据页，就要找到具体位置，所以是随机写；感谢楼主和楼上-->

但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。

## 12.6 思考题

**一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？**



每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。

这时候系统不得不停止所有更新，去推进 checkpoint。

这时，你看到的现象就是**磁盘压力很小，但是数据库出现间歇性的性能下跌。**

在这种情况下，连 change buffer 的优化也失效了。因为 checkpoint 一直要往前推，这个操作就会触发 merge 操作，然后又进一步地触发刷脏页操作；

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281735631.jpg)

1. 把相对应的数据页中的脏页持久化到磁盘,checkpoint往前推

2. 由于redo log还记录了undo的变化,undo log buffer也要持久化进undo log

3. 当innodb_flush_log_at_trx_commit设置为非1,还要把内存里的redo log持久化到磁盘上

4. redo log还记录了change buffer的改变,那么还要把change buffer purge到idb

   以及merge change buffer.merge生成的数据页也是脏页,也要持久化到磁盘
   上述4种操作,都是占用系统I/O,影响DML,如果操作频繁,会导致'抖'得向现在我们过冬一样。
   但是对于select操作来说,查询时间相对会更快。因为系统脏页变少了,不用去淘汰脏页,直接复用
   干净页即可。还有就是对于宕机恢复,速度也更快,因为checkpoint很接近LSN,恢复的数据页相对较少
   所以要控制刷脏的频率,频率快了,影响DML I/O,频率慢了,会导致读操作耗时长。

##  FAQ

**当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？（合并间隙，移动位置？）**
**另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？**

其实由于淘汰的时候，刷脏页过程不用动redo log文件的。

这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。

**buffer pool里维护着一个脏页列表，假设现在redo log 的 checkpoint 记录的 LSN 为 10，现在内存中的一干净页有修改，修改后该页的LSN为12，大于 checkpoint 的LSN，则在写redo log的同时该页也会被标记为脏页记录到脏页列表中，现在内存不足，该页需要被淘汰掉，该页会被刷到磁盘，磁盘中该页的LSN为12，该页也从脏页列表中移除，现在redo log 需要往前推进checkpoint，到LSN为12的这条log时，发现内存中的脏页列表里没有该页，且磁盘上该页的LSN也已经为12，则该页已刷脏，已为干净页，跳过。**

---

**什么是lsn**

https://www.modb.pro/db/62466#:~:text=LSN%E5%85%A8%E7%A7%B0%E6%98%AF%EF%BC%9Alog%20sequence,checkponit%E9%83%BD%E6%9C%89LSN%E6%A0%87%E8%AE%B0%E3%80%82

----

**innodb是如何知道一个页是不是脏页的，是有标记位还是通过redolog的ckeckpoint来确定的？**

每个数据页头部有LSN，8字节，每次修改都会变大。

对比这个LSN跟checkpoint 的LSN，比checkpoint小的一定是干净页

**flush、purge、merge****对应的是什么**

* flush 一般是说刷脏页，
* purge一般是指清undo log,
* merge一般是指应用change buffer

**访问某条记录时，存储引擎是如何判断这条记录所在的数据页是否在内存当中，这个查内存机制是如何实现的？**

每个页面有编号的。拿着编号去内存看，没有，就去磁盘

**如果直接将内存中的数据页刷入磁盘，那redo log中的数据怎么办，会去删除吗？如果是那redo log岂不就不连续了。如果不是的话当刷redo log时又该怎么判断此时硬盘中的数据已经是最新的数据了呢。**

 Redo log不用动，checkpoint 推进的时候再“丢弃”就可以了。丢弃的意思是，判断到数据页已经刷过，就不用再重放

**那在重放 redo log 时是如何跳过那些由于内存不足而刷脏的页面的呢？刷脏的时候会将 LSN 重置为0之类的？**

判断一下发现是干净页就跳过。
不是重置为0，是把磁盘上数据页的LSN也一起改掉了

# 十三、为什么表数据删掉一半，表文件大小不变

**问题：**

把最大的表删掉了一半的数据，怎么表文件的大小还是没变？

一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。<!--系统表空间，对应 ibdata1 这个文件。-->

## 13.1 参数 innodb_file_per_table

```mysql
show variables like 'innodb_file_per_table';
```

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：

1. 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。

从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。

建议不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

所以，**将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。**

我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。

我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。

## 13.2 数据删除流程

我们先再来看一下 InnoDB 中一个索引的示意图。在前面第 4和第 5篇文章中，我和你介绍索引时曾经提到过，InnoDB 里的数据都是用 B+ 树的结构组织的。

![树索引示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281630220.png)

假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。

现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？

答案是，整个数据页就可以被复用了。

但是，**数据页的复用跟记录的复用是不同的。**

记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。<!--为了维护 B+ 树叶子数据的有序性-->

而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。

如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。<!--这里的相邻应该是指B+树上的逻辑相邻，而不是表空间文件的物理相邻，合并数据页的过程应该正好对应B+树删除叶子结点中某条记录导致其利用率很低，然后和邻居节点合并的过程。-->

进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。

你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。

实际上，**不止是删除数据会造成空洞，插入数据也会。**

如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。

假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281646473.png)

可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）

另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。<!--为什么说更新可能会导致位置改变？说再详细些应该是这样，其实更新操作，主键索引树的位置是不会变的，可能会变的是哪些二级索引树。-->

<!--索引k的值从1变成3，1的索引数据会标记为删除，然后重新建立3的索引数据，一删一增的过程就产生了空洞-->

也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。

**空洞的原因：** 

①删除表记录，被删除的记录只是被标记删除，索引值所在的空间能被复用，但是没有真正的删除。

 ②新增表记录，如果索引的值是随机分散的，那么会造成数据页的分裂，也会造成空洞 

③更新索引上的值，实际上是把旧值标记为删除，然后新增一个新值，旧值虽然能被复用，但是还是造成了空洞

delete不能回收磁盘空间，因为是逻辑删除，只能重建表。

## 13.3 重建表

**试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？**

你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。

由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。

这里，你可以使用 `alter table A engine=InnoDB` 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作

![图 3 改锁表 DDL](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281702645.png)

显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。

而在 **MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。**

描述一下引入了 Online DDL 之后，重建表的流程：

<!--redis的AOF重写也是 fork一个子进程去重写, 同时主进程的命令写入重写缓冲区, 等子进程通知重写完毕后, 主进程将重写文件和缓冲区编成新的文件, 再替换原来的AOF文件. 这种增量复制的思想其实很多地方都有用到, 包括前面提到的redis主从复制, 也是开辟一个有限大的缓冲区解决某个子节点短暂断链的问题-->

1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。

![Online DDL](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202202281705063.png)

可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。

我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？

确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。

为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。

那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。

<!--一开始获取写锁，目的是保证在一些准备动作（如row log的创建）还未完成之前，主表不允许做任何修改或读取，之后降级是允许其他线程 DML，因为这时 log 文件已经就绪，他们的 DML 都会进入 log 文件中。开始复制数据的时候退化成读锁，不解锁的原因是防止有其他线程获取DML写锁。最后把row log的数据复制到临时表的时候还会获取一次MDL写锁，防止其他DML操作。为了保证将日志应用到临时表后，临时表与原表数据一致，就在应用日志前获取MDL写锁，阻止所有DDL、DML操作。-->

而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。

需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。

## 13.4 Online 和 inplace

说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。

你可能注意到了，在图 3 中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。<!--server 层的tmp table vs innoDB 中的tmp file tmp file对于server层来说，就像原地 inplace 一样-->

在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。<!--在存储引擎中实现，对于server端来说，无感知，这种方式叫做inplace,需要临时表，只不过对server层来说，他看不到具体的过程，只看到最后的结果，感觉就像是原地替换一样-->

所以，我现在问你，如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？

<!--这里的原地，是指相对于server层，没有做一个拷贝到临时表的操作-->

答案是不能。因为，tmp_file 也是要占用临时空间的。

我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：

```mysql
alter table t engine=innodb,ALGORITHM=inplace;
```

跟 inplace 对应的就是拷贝表的方式了，用法是：

```mysql
alter table t engine=innodb,ALGORITHM=copy;
```

当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程就是图 3 的操作过程。

但我这样说你可能会觉得，inplace 跟 Online 是不是就是一个意思？

<!--DDL 的方式就两种，一种是COPY，一种是INPLACE。mysql 5.6之前是 COPY 方式，mysql5.6引入 online，整个过程在引擎内部完成，对于 server 层没有创建临时表，就是 Inplace 方式。所以，如果DDL过程是 online 的，那么一定是 Inplace 方式。反之不一定，比如添加全文索引-->

其实不是的，只是在重建表这个逻辑中刚好是这样而已。

比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：

```mysql

alter table t add FULLTEXT(field_name);
```

这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。

如果说这两个逻辑之间的关系是什么的话，可以概括为：

1. DDL 过程如果是 Online 的，就一定是 inplace 的；
2. 反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。

**optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。**

* 从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面图 4 的流程了；
* analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
* optimize table t 等于 recreate+analyze。

## 13.5 小结

现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过 alter table 命令重建表，才能达到表文件变小的目的。我跟你介绍了重建表的两种实现方式，Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。

## 13.6 思考题

1. 一个表 t 文件大小为 1TB；
2. 对这个表执行 alter table t engine=InnoDB；
3. 发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。

你觉得可能是什么原因呢 ？

这个表，本身就已经没有空洞的了，比如说刚刚做过一次重建表操作。在 DDL 期间，如果刚好有外部的 DML 在执行，这期间可能会引入一些新的空洞。

在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。

<!--为什么预留1/16的空洞呢，主要是为了给update操作使用， 防止过于频繁的页分裂-->

假如是这么一个过程：

1. 将表 t 重建一次；
2. 插入一部分数据，但是插入的这些数据，用掉了一部分的预留空间；<!--在达到预留空间上限的时候，插入操作是不会占用预留空间的，而是会新申请一个数据块，只有在更新操作才会占用预留空间。所以确切的说应该是：做了更新操作占用了一部分预留空间后，然后再做重建表，结果反而表占用的空间变大了-->
3. 这种情况下，再重建一次表 t，就可能会出现问题中的现象。

## FAQ

**分布式ID（雪花算法生成的ID）生成的索引会比自增长的ID性能低吗？**

雪花算法生成的ID是越来越大的，但不是逐渐递增，长度用的的bitint，

性能一样的，没有一定要“连续”，只要是递增

---

**Truncate 会释放表空间吗**

Truncate 可以理解为drop+create

---



**重建表的时候如果没有数据更新，有没有可能产生页分裂和空洞**

Online 可以认为没有

---



**不影响增删改，就是 Online；相对 Server层没有新建临时表，就是 inplace，这里怎么判断是不是相对 Server 层没有新建临时表**

怎么判断是不是相对 Server 层没有新建临时表。一个最直观的判断方法是看命令执行后影响的行数，没有新建临时表的话新建的行数是0。

```mysql
MariaDB [test]> alter table t engine=InnoDB;
Query OK, 0 rows affected (0.800 sec)
Records: 0 Duplicates: 0 Warnings: 0

MariaDB [test]> alter table t engine=innodb,ALGORITHM=copy;
Query OK, 100000 rows affected (1.381 sec)
Records: 100000 Duplicates: 0 Warnings: 0

```



---

**apply row log 的时候，是不是已经将S-MDL 提升为 X-MDL了？(**

but it also extends the period of time at the end of the DDL operation when the table is locked to apply logged DML.
看来apply logged DML 是会锁表的
https://dev.mysql.com/doc/refman/5.7/en/innodb-online-ddl-space-requirements.html

---

\1. 是不是 5.6 之后 所有的 alter 操作(增删字段、增删索引等)都是支持 online ddl

\2. 如果 alter 都是 online ddl 那么是不是如果 alter操作 获取到mdl写锁 时， 后面的 查询需要mdl读锁会暂时阻塞， 但是mdl会马上降为读锁 ，后面的操作会继续进行不会堵塞 。等再升到写锁 ，后面操作又会暂时阻塞。

\3. 当 alter 降到mdl 读锁时 ， 这时候可以新增数据么 ， mdl表级读锁 不会影响到 insert 或者 update的行锁么

\4. 如果将 alter 操作显式的放到事务里 ，事务不提交 ， 另一个事务查询的时候会查询到alter 操作后的表结构 ， 比如新增了一个字段。这个是什么原因 ，是否打破了 mvcc 的定义呢

 \1. 不是哦，我文章里说的加全文索引就不online

\2. 对，这两个暂时，都是时间很短的

\3. 是，DML语句加的是MDL读锁，读读不冲突

\4.  不过alter table 语句会默认提交前面的事务，然后自己独立执行

---

**大表来说该怎么alter table呢**

1. 用其他方式,比如说备库里面的表alter完了,再接上主库,更新完binlog后,同步了,再主从切换.
2. 要是磁盘空间不够， 就不配做ddl。 不然怎么也不行
3. 大表是不适合做alter table操作的,做也是在晚上处理并且要对时间进行预估;因为做alter table操作的时候online的第一步要获取MDL的写锁此时不能DML语句和DDL语句的执行

---

**更新有空洞，有点费解，我个人理解是更新是结合删除和插入的一个合并操作。删除后产生的空洞，在插入时不是应该就马上被复用了吗，毕竟主键是一致的。所以为什么更新会产生空洞呢？？**

 可以这么想下，如果1，2，3，4，5
然后update把2 改成6， 如果原地修改，这个索引就不是“有序”的了

---

**数据页A满了，随机插入一条数据，不得不申请一个新的数据页，这时候数据页A会留下空洞，我的问题是，既然满了，为什么还有空洞呢？**

申请新页B，把一部分数据从A挪到B，A就空出一些

---

**creat table xx select * from xxx这种还会有空洞的存在吗？**

作者回复: 这种一般select里面用的是主键id排序的
所以XX表的主键索引是紧凑的了

不过其他索引还是有哦

---

**inplace的rebuild和no-rebuild**
**rebuild 需要重建表（重新组织记录），比如optimize table、添加索引、添加/删除列、修改列NULL/NOT NULL属性等**
**no-rebuild 需要修改表的元数据，比如删除索引、修改列名不改变数据类型、修改列默认值、修改列自增值**
**问题一 这二者什么差别，我感觉都差不多，**
**问题二 文章中说的这个表消除空洞较少空间属于哪个**
**问题三 如果没有任何新数据插入，只是压缩原有的表，请问属于哪个**

 \1. Rebuild 是整个表重建，就是我们文中图4的过程。 no-rebuild是指主键索引不用重建，比如加索引

\2. Rebuild

\3. Rebuild

---

**重建表的时候如果没有数据更新，有没有可能产生页分裂和空洞**

如果考虑同时有并发的插入数据，就可能了。“online可以认为没有”是假设没有并发更新

页分裂发生在插入数据的时候，空洞产生在删除数据的时候，不论online 还是非 online 没有数据更新的话它不会产生页分裂和空洞；而 online 由于在重建表的过程中会将更新记录在 row log 里，如果这些语句里面有非自增的插入和删除数据，在执行 rowlog 的时候可能会发生空洞；

---

**网上找到一个Inplace和Online的区别，写的挺好的，贴出来方便大家理解：**
**MySQL各版本，对于add Index的处理方式是不同的，主要有三种：**

（1）Copy Table方式
这是InnoDB最早支持的创建索引的方式。顾名思义，创建索引是通过临时表拷贝的方式实现的。

新建一个带有新索引的临时表，将原表数据全部拷贝到临时表，然后Rename，完成创建索引的操作。

这个方式创建索引，创建过程中，原表是可读的。但是会消耗一倍的存储空间。

（2）Inplace方式
这是原生MySQL 5.5，以及innodb_plugin中提供的创建索引的方式。所谓Inplace，也就是索引创建在原表上直接进行，不会拷贝临时表。相对于Copy Table方式，这是一个进步。

Inplace方式创建索引，创建过程中，原表同样可读的，但是不可写。

（3）Online方式
这是MySQL 5.6.7中提供的创建索引的方式。无论是Copy Table方式，还是Inplace方式，创建索引的过程中，原表只能允许读取，不可写。对应用有较大的限制，因此MySQL最新版本中，InnoDB支持了所谓的Online方式创建索引。

InnoDB的Online Add Index，首先是Inplace方式创建索引，无需使用临时表。在遍历聚簇索引，收集记录并插入到新索引的过程中，原表记录可修改。而修改的记录保存在Row Log中。当聚簇索引遍历完毕，并全部插入到新索引之后，重放Row Log中的记录修改，使得新索引与聚簇索引记录达到一致状态。

与Copy Table方式相比，Online Add Index采用的是Inplace方式，无需Copy Table，减少了空间开销；与此同时，Online Add Index只有在重放Row Log最后一个Block时锁表，减少了锁表的时间。

与Inplace方式相比，Online Add Index吸收了Inplace方式的优势，却减少了锁表的时间。

# 十四、count(*)这么慢，我该怎么办？

在开发系统的时候，你可能经常需要计算一个表的行数，比如一个交易系统的所有变更记录总数。这时候你可能会想，一条 select count(*) from t 语句不就解决了吗？

但是，你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL 怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。

## 14.1 count(*) 的实现方式

在不同的 MySQL 引擎中，count(*) 有不同的实现方式。

* MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；
* 而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。

在前面的文章中，我们一起分析了为什么要使用 InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB 都优于 MyISAM。我猜你的表也一定是用了 InnoDB 引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。

## 14.2 那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？

这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。

假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。

* 会话 A 先启动事务并查询一次表的总行数；
* 会话 B 启动事务，插入一行后记录后，查询表的总行数；
* 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。

我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。

![图 1 会话 A、B、C 的执行流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011000002.png)

你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。

这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。

> 备注：如果你对 MVCC 记忆模糊了，可以再回顾下第 3 篇文章《事务隔离：为什么你改了我还看不见？》和第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容。

当然，现在这个看上去笨笨的 MySQL，在执行 count(*) 操作的时候还是做了优化的。

InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。**

> 备注： B+树只有叶子结点上有数据，全部遍历其实就是对叶子结点的链表进行遍历。此时如果遍历主键索引树，由于其叶子结点上存放的是完整的行信息，对于一个数据页而言其行密度会比较小，最终导致要扫描的数据页较多，进而IO开销也比较大。如果遍历第二索引树，其叶子结点只存放主键信息，其数据页的行密度比较大，最终扫描的数据页较少，节省了IO开销。<!--MYSQL 加载数据到内存的最小单位是页，扫描小的索引树IO次数更少。-->
>
> 如果扫描二级索引，如何避免幻读？
>
> 因为不锁的话，可能你在读二级索引的时候，主键索引其实正在被修改，因为二级索引和主键索引的修改是分开的。为了避免你提前读了，所以会锁上

如果你用过 `show table status` 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？

你可能还记得在第 10 篇文章《 MySQL 为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。**所以，show table status 命令显示的行数也不能直接使用。**

**小结一下：**

* MyISAM 表虽然 count(*) 很快，但是不支持事务；
* show table status 命令虽然返回很快，但是不准确；
* nnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。

**回到文章开头的问题，如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？**

接下来，我们讨论一下，看看自己计数有哪些方法，以及每种方法的优缺点有哪些。

这里，我先和你说一下这些方法的基本思路：你需要自己找一个地方，把操作记录表的行数存起来。

## 14.3 用缓存系统保存计数

对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持

你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？

没错，缓存系统可能会丢失更新。

Redis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。

当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。

但实际上，**将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。**

> 这里主要原因是因为“MySQL插入一行数据”跟“Redis计数加1”这两个操作是分开的，不是原子性的，这就很可能在中间过程因为某些并发出现问题。 更抽象一点：MySQL和Redis是两个不同的载体，将关联数据记录到不同的载体，而不同载体要实现原子性很难，由于不是原子性很容易引起并发问题。如果能将数据统一在同个载体即MySQL，并由其保证操作的原子性，即将插入一行数据和计数加1作为一个完整的事务，通过事务的隔离此时外界看到的就是要么全部执行完毕要么全部都没执行，进而保持逻辑一致。

你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的 100 条记录。那么，这个页面的逻辑就需要先到 Redis 里面取出计数，再到数据表里面取数据记录。

我们是这么定义不精确的：

1. 一种是，查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；
2. 另一种是，查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。

这两种情况，都是逻辑不一致的。

我们一起来看看这个时序图。

![图 2 会话 A、B 执行时序图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011019437.png)

图 2 中，会话 A 是一个插入交易记录的逻辑，往数据表里插入一行 R，然后 Redis 计数加 1；会话 B 就是查询页面显示时需要的数据。

在图 2 的这个时序里，在 T3 时刻会话 B 来查询的时候，会显示出新插入的 R 这个记录，但是 Redis 的计数还没加 1。这时候，就会出现我们说的数据不一致。

你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改 Redis 计数。而读的时候是先读 Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话 A 的更新顺序换一下，再看看执行结果。

![图 3 调整顺序后，会话 A、B 的执行时序图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011022595.png)

你会发现，这时候反过来了，会话 B 在 T3 时刻查询的时候，Redis 计数加了 1 了，但还查不到新插入的 R 这一行，也是数据不一致的情况。

在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。

## 14.4在数据库保存计数

根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，**如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？**

首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。

> 备注：关于 InnoDB 的崩溃恢复，你可以再回顾一下第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中的相关内容。

然后，我们再看看能不能解决计数不精确的问题。

你会说，这不一样吗？无非就是把图 3 中对 Redis 的操作，改成了对计数表 C 的操作。只要出现图 3 的这种执行序列，这个问题还是无解的吧？

这个问题还真不是无解的。

我们这篇文章要解决的问题，都是由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。

所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。

![图 4 会话 A、B 的执行时序图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011041307.png)

我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。

我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。

因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。

## 14.5 不同的 count 用法

在前面文章的评论区，有同学留言问到：在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。今天谈到了 count(*) 的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。

需要注意的是，下面的讨论还是基于 InnoDB 引擎的。

这里，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。

> count的执行过程分为两步： 1. InnoDB存储引擎查询数据结果集 2. Server层根据结果集进行遍历统计

所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。

至于分析性能差别的时候，你可以记住这么几个原则：

1. server 层要什么就给什么；
2. InnoDB 只给必要的值；
3. 现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。

这是什么意思呢？接下来，我们就一个个地来看看。

**对于 count(主键 id) 来说**，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。

**对于 count(1) 来说，**InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。

**对于 count(字段) 来说**

1. 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
2. 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。<!--可以理解为先判断是否为not null，如果是则加1，如果不是，则遍历count字段，判断里面的记录是否为null，如果不是null，而是字段记录，则加1，反之如果为null则忽略！-->

也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。

**但是 count(*) 是例外，**并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。

看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 count(*) 来处理，多么简单的优化啊。

当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 count(*) 了，你直接使用这种用法就可以了。

所以结论是：按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(\*)，所以我建议你，尽量使用 count(\*)。

## 14.6 小结

今天，我和你聊了聊 MySQL 中获得表行数的两种方法。我们提到了在不同引擎中 count(*) 的实现方式是不一样的，也分析了用缓存系统来存储计数值存在的问题。

其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。

## 14.7 思考题

在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？

从并发系统性能的角度考虑，应该先插入操作记录，再更新计数表。

知识点在《行锁功过：怎么减少行锁对性能的影响？》
因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。

## FAQ

**库里总共 30w 数据 。 第一次用 count(*) 是 120多ms , 第二次就是 60多 ms 。 第三次用了 count(1) ，也是60多ms 。 请问 count(*) 这两次的前后时间差是什么原因，也会走缓存 ？**

进了Buffer pool 的原因吧

**RC与RR隔离级别**

oracle,sqlserver,postgresql的默认隔离级别是RC。RC级别，一个事务中的两个相同的读取操作，其结果可能不同。也就是，会读取到其他事务commit的数据。mysql的默认隔离级别是RR，这样会样mysql比其他数据库更高级吗？不会的。RR级别的并发能力比RC要弱一个等级。RC够用才是其他数据库选择为默认隔离级别的原因。

**count（id）和count（这段）都是要把每一行的该字段值取出来，然后判断是否为空，那为什么count（id）的效率要高？**

 count(id)可能会选择最小的索引来遍历
而count(字段)的话，如果字段上没有索引，就只能选主键索引

**对于 count(主键 id) ，server层拿到ID，判断ID是不可能为空的按行累加。这个地方，是不是又点问题，既然是主键ID，是一定不会为空的，这个server层还需要判断不为空吗**

代码就是这么写的 我也觉得可以优化一下… 不过现在就这样

**后台有很多表格形式的报表，分页是需要展示总页数的，当数据很多，但查询条件过滤掉的数据比较少时，查询速度就很慢(10几秒)，这个怎么解**

分页一般可以加上上次页数的offset 也可以是指id，下一次查询带上这个id 速度会快很多。还有如果你们那读写分离，建议count计算与分页查询并行查询，速度会快很多，当然缺点就是 count判断不需要下一页的时候，多一次分页查询。这些都可以在业务上规避

**对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。innodb不取值的话，返回给执行器的数据是啥？**

可以理解为，返回了一行，但是0个字段

就是返回一个空行，但是高度server层“不是空值，可以计数”

过程上，其实是server层调用引擎接口，一行一行取

# 十五、日志索引相关问题

## 15.1 日志相关问题

我在第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中，和你讲到 binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。

在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？

![图 1 两阶段提交示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011331199.jpg)

这里，我要先和你解释一个误会式的问题。有同学在评论区问到，这个图不是一个 update 语句的执行流程吗，怎么还会调用 commit 语句？

他产生这个疑问的原因，是把两个“commit”的概念混淆了：

* 他说的“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟 begin/start transaction 配对使用。
* 而我们图中用到的这个“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。
* “commit 语句”执行的时候，会包含“commit 步骤”。

而我们这个例子里面，没有显式地开启事务，因此这个 update 语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit 步骤“。

接下来，我们就一起分析一下**在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。**

如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。<!--redo log 分为两个部分，一个是redo buffer 一个redo file，有参数控制redo buffer 持久化到file。默认是1 产生一个事务就刷。-->

大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？

我们先来看一下崩溃恢复时的判断规则。

1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
   1. 如果是，则提交事务；
   2. 否则，回滚事务。

这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。

## 15.2 MySQL 怎么知道 binlog 是完整的?

一个事务的 binlog 是有完整格式的：

* statement 格式的 binlog，最后会有 COMMIT；
* row 格式的 binlog，最后会有一个 XID event。

另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。

## 15.3 redo log 和 binlog 是怎么关联起来的?

它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log

* 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；

* 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

## 15.4 处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?

其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。

所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性



## 15.5 如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？

其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。

<!--其实把Mysql的两阶段提交也可以看成两个分布式服务处理两个不同事情，redo log在Innodb引擎内操作的，binlog是在server层操作的，我们就可以把引擎层和server层看成两个分布式服务，那他们要分别进行两个相关联的操作，就意味着要实现分布式事务，而两阶段提交，就是其中的一种解决方案-->

如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。

对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。

两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。

## 15.6 不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？

只保留 binlog，然后可以把提交流程改成这样：… -> “数据更新到内存” -> “写 binlog” -> “提交事务”，是不是也可以提供崩溃恢复的能力？

答案是不可以。

如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。

InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。

InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。

而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。

![图 2 只用 binlog 支持崩溃恢复](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011519464.jpg)

这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。

如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。

重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。

但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。

也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。

你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。

所以，至少现在的 binlog 能力，还不能支持崩溃恢复。

<!--为什么binlog代替不了redolog，在当初Innodb设计之初，数据写入的时候，写到内存和redolog、binlog就算写完了。内存的数据有没有落盘主要看redolog有没有日志数据，只要redolog日志数据没有被checkpoint擦完，就代表还有数据在内存里，所以只要崩溃恢复了，就会去把redolog的数据先恢复到内存的数据页中。如果你只有binlog，你怎么知道这些日志不是已经在磁盘还是在内存中，起码现在的binlog不具备这个能力。--- 总之一句话，没有落盘的数据都在redolog里面记录着，所以它能崩溃恢复，这样好理解吧-->

## 15.7 ：那能不能反过来，只用 redo log，不要 binlog？

如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。

但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。

一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。

一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。<!--主从，主主，主备，数据转储到数仓等等-->

还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。

总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。

## 15.8 redo log 一般设置多大？

redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。

所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。

## 15.9 正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？

这里涉及到了，“redo log 里面到底是什么”的问题。

实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。

1. 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。
2. 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。

## 15.10 redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？

在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：

```mysql
begin;
insert into t1 ...
insert into t2 ...
commit;
```

这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。

所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。

但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。

（这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在后面第 22 篇文章《MySQL 有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。

单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。

## 15.11 业务设计问题

> 业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：

> 以 A 关注 B 为例：第一步，先查询对方有没有关注自己（B 有没有关注 A）select * from like where user_id = B and liker_id = A;

> 如果有，则成为好友insert into friend;

> 没有，则只是单向关注关系insert into like;

> 但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？

```mysql

CREATE TABLE `like` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) NOT NULL,
  `liker_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)
) ENGINE=InnoDB;

CREATE TABLE `friend` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `friend_1_id` int(11) NOT NULL,
  `friend_2_id` int(11) NOT NULL,
  UNIQUE KEY `uk_friend` (`friend_1_id`,`friend_2_id`),
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
```

在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。

![图 3 并发“喜欢”逻辑操作顺序](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203011642896.png)

由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。

因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。

这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。

如提问里面说的，“第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。

首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。

然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：

应用代码里面，比较 A 和 B 的大小，如果 A

```mysql

mysql> begin; /*启动事务*/
insert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;
select relation_ship from `like` where user_id=A and liker_id=B;
/*代码中判断返回的 relation_ship，
  如果是1，事务结束，执行 commit
  如果是3，则执行下面这两个语句：
  */
insert ignore into friend(friend_1_id, friend_2_id) values(A,B);
commit;
```

如果 A>B，则执行下面的逻辑

```mysql

mysql> begin; /*启动事务*/
insert into `like`(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;
# 这里的按位或还是很妙的。 首先需要知道： 1|2等于3，这样就很容易把单向的关注，最终变成相互关注 同时也就是老师提到的 幂等性，执行多次单项关注，效果不变。
select relation_ship from `like` where user_id=B and liker_id=A;
/*代码中判断返回的 relation_ship，
  如果是2，事务结束，执行 commit
  如果是3，则执行下面这两个语句：
*/
insert ignore into friend(friend_1_id, friend_2_id) values(B,A);
# mysql插入数据有3中方式： 1. insert into 如果主键重复会报错 2. replace into 如果主键或者唯一索引重复的话，会替换掉原数据 3. insert ignore 如果主键或则唯一索引重复，则会跳过该数据
commit;
```

<!--这里主要思想是：无论A关注B还是B关注A在like表中都是同一行数据，这样就可以利用行锁-->

这个设计里，让“like”表里的数据保证 user_id < liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。

然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。

操作符 “|” 是按位或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。

这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。

不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。

而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧

## 15.12 思考题

我们创建了一个简单的表 t，并插入一行，然后对这一行做修改。

```mysql

mysql> CREATE TABLE `t` (
`id` int(11) NOT NULL primary key auto_increment,
`a` int(11) DEFAULT NULL
) ENGINE=InnoDB;
insert into t values(1,2);
```

这时候，表 t 里有唯一的一行数据 (1,2)。假设，我现在要执行：

```mysql
 update t set a=2 where id=1;
```

你会看到这样的结果：

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021042507.png)

结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。

仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：

1. 更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；
2. MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；
3. InnoDB 认真执行了“把这个值修改成 (1,2)"这个操作，该加锁的加锁，该更新的更新。

你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步地，可以思考一下，MySQL 为什么要选择这种策略呢？



第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。

假设，当前表 t 里的值是 (1,2)。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021345245.png)

session B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。

第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。

假设当前表里的值是 (1,2)。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021345582.png)

session A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。

现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。（如果你对这个逻辑有疑惑的话，可以回顾下第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）

所以，答案应该是选项 3，即：InnoDB 认真执行了“把这个值修改成 (1,2)"这个操作，该加锁的加锁，该更新的更新。

然后你会说，MySQL 怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？

其实 MySQL 是确认了的。只是在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改”的。

作为验证，你可以看一下下面这个例子。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021347608.png)

<!--只有 id=1 不能确认 “不需要修改”，加上 a=3 条件后就可以确认 “不需要修改”了，所以 session A 的 update 实际未执行-->

**补充说明：**

上面验证结果都是在 binlog_format=statement 格式下进行的。

如果是 binlog_format=row 并且 binlog_row_image=FULL 的时候，由于 MySQL 需要在 binlog 里面记录所有的字段，所以在读数据的时候就会把所有数据都读出来了。

根据上面说的规则，“既然读了数据，就会判断”， 因此在这时候，select * from t where id=1，结果就是“返回 (1,2)”。

同理，如果是 binlog_row_image=NOBLOB, 会读出除 blob 外的所有字段，在我们这个例子里，结果还是“返回 (1,2)”。

对应的代码如图 15 所示。这是 MySQL 5.6 版本引入的，

![binlog_row_image=FULL 读字段逻辑](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021406850.png)

类似的,timestamp 字段的问题。结论是：如果表中有 timestamp 字段而且设置了自动更新的话，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，就会发现不需要修改。

## FAQ

**深入学习了MySQL如何应用**

知道每个语句执行的结果，以及这些代码会消耗什么资源、如果慢了会慢在哪里、每个语句执行会占用哪些锁等等。

# 十六、“order by”是怎么工作的？

在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。

```mysql

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `city` varchar(16) NOT NULL,
  `name` varchar(16) NOT NULL,
  `age` int(11) NOT NULL,
  `addr` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `city` (`city`)
) ENGINE=InnoDB;
```

这时，你的 SQL 语句可以这么写：

```mysql
select city,name,age from t where city='杭州' order by name limit 1000 ;
```

这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为

## 16.1 全字段排序

前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。

![图 1 使用 explain 命令查看语句的执行情况](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021123551.png)

Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。

<!--MySQL 会为每个线程分配固定大小的 sort buffer 用作排序。 sort buffer 是具有逻辑概念的内存区域，大小由 sort_buffer_size 参数控制，默认为 256 kb。 通过 EXPLAIN 命令来查看，如果在分析结果中的 Extra 字段里包含 Using filesort 字眼，说明执行了外部排序操作。 Filesort: Yes Filesort_on_disk: No 表示没有使用了内存排序。 read_rnd_buffer_size:是MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大-->

为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。

![图 2 city 字段的索引示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021125518.png)

从图中可以看到，满足 city='杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些记录。

通常情况下，这个语句执行流程如下所示 ：

1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
7. 按照排序结果取前 1000 行返回给客户端。

我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。

![图 3 全字段排序](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021137717.jpg)

图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。

<!--如果sort buffer的大小足够，那么排序就在内存中完成，采用全字段排序；否则就需要使用磁盘临时文件进行排序，在sort buffer中排好序然后把结果存入临时文件，最后合并成一个大的临时文件，采用归并排序。-->

sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。

```mysql

/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 */
select @b-@a;
```

https://www.cnblogs.com/itmuch/p/13370442.html

这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。

![图 4 全排序的 OPTIMIZER_TRACE 部分结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021312352.png)

number_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件

<!--之所以要用外部排序，一般是待排序数据量很大，在内存中放不下，不能使用内存排序算法。 外部排序，常见为多路归并排序算法 ---- 1、分隔： (分治思想)分隔为多个外部子文件，单个子文件大小小于排序可用的内存大小，即子文件可以加载入内存。 2、内存排序： 对每个子文件进行内存排序。 3、归并： （多路）归并已有序的子文件，最终形成一个完整的有序文件。 （归并的过程占用的内存只是2个元素的大小。如归并有序子文件X和有序子文件Y为文件Z的过程----从X读取最小元素x1入内存，从Y读取最小元素y1至内存。比较x1和y1，将两者中较小的写入文件Z。依次重复此过程，直至X、Y文件中元素都进入Z中。）-->

如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。

否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。

接下来，我再和你解释一下图 4 中其他两个值的意思

我们的示例表中有 4000 条满足 city='杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。

sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。

同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。

这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。

这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1

## 16.2 rowid 排序

在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。

所以如果单行很大，这个方法效率不够好。

那么，**如果 MySQL 认为排序的单行长度太大会怎么做呢？**

接下来，我来修改一个参数，让 MySQL 采用另外一种算法。

```mysql

SET max_length_for_sort_data = 16;
```

max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

city、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。

<!--varchar(16) * 2 + int(11) 16 * 2 + 4 这里是按照英文字符计算，1个英文字符占一字节。-->

新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。

但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：

1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 进行排序；
7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

![图 5 rowid 排序](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021324671.jpg)

对比图 3 的全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。

需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。

<!--rowid 方式和全字段方式一样，需要先把查询到的结果全部放在内存或硬盘中，再使用相关算法进行排序。而排序后由于没有保存所需的字段，需要按顺序使用主键再从索引树上查询，查到一个就返回一个，而不用把所有内容查完放到内存上再一并返回。-->

根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？

现在，我们就来看看结果有什么不同。

首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。

因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。

![rowid 排序的 OPTIMIZER_TRACE 部分输出](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021325168.png)

从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。

1. sort_mode 变成了 ，表示参与排序的只有 name 和 id 这两个字段。
2. number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。

## 16.3 全字段排序 VS rowid 排序

我们来分析一下，从这两个执行流程里，还能得出什么结论。

如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。

如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。

这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。

对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。

这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。

看到这里，你就了解了，MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。

其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。

你可以设想下，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？

所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：

```mysql

alter table t add index city_user(city, name);
```

作为与 city 索引的对比，我们来看看这个索引的示意图。

![图 7 city 和 name 联合索引示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021336915.png)

在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city='杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。

这样整个查询过程的流程就变成了：

1. 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
2. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
3. 从索引 (city,name) 取下一个记录主键 id；
4. 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

![图 8 引入 (city,name) 联合索引后，查询语句的执行计划](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021337429.jpg)

可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。

![图 9 引入 (city,name) 联合索引后，查询语句的执行计划](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021337321.png)

从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。

既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。

这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。

按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。

针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：alter table t add index city_user_age(city, name, age);

```mysql

alter table t add index city_user_age(city, name, age);
```

这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：

1. 从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；
2. 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；
3. 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

![图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021339331.jpg)

然后，我们再来看看 explain 的结果。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021340219.png)

图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划

可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。

<!--。当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。小结今天这篇文章，我和你介绍了 MySQL 里面 order by 语句的几种算法流程。在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。最后，我给你留下一个思考题吧。假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：mysql> select * from t where city in ('杭州',"苏州") order by name limit 100;那么，这个语句执行的时候会有排序过程吗，为什么？如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？你可以把你的思考和观点写在留言区里，我会在下一篇文章的末尾和你讨论这个问题。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。上期问题时间上期的问题是，当 MySQL 去更新一行，但是要修改的值跟原来的值是相同的，这时候 MySQL 会真的去执行一次修改吗？还是看到值相同就直接返回呢？这是第一次我们课后问题的三个选项都有同学选的，所以我要和你需要详细说明一下。第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。假设，当前表 t 里的值是 (1,2)。图 12 锁验证方式session B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。假设当前表里的值是 (1,2)。图 13 可见性验证方式session A 的第二个 sel-->

当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。

## 16.4 小结

在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。

## 16.5 思考题

假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：

```mysql

mysql> select * from t where city in ('杭州',"苏州") order by name limit 100;
```

那么，这个语句执行的时候会有排序过程吗，为什么？

如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？

进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？

## FAQ

**rowid排序的过程，**

1. 执行器查看表定义，发现name、city、age字段的长度之和超过max_length_for_sort_data，所以初始化sort_buffer的时候只放入id和name字段。
2. 执行器调用存储引擎的读数据接口，依次获取满足条件的数据的id和name，存入sort_buffer。
3. 排序。
4. 执行器根据limit条件筛选出id，再次调用引擎读数据的接口获取相应的数据，返回客户端。
   整个过程实际上是被执行器拆成了两次查询，共调用两次存储层的读数据接口，所以总的扫描行数需要相加。（@b-@a=5000）

但是对于using index condition的场景，执行器只调用了一次查询接口，回表是由存储层来完成的，所以扫描行数只算一次，即只算走索引搜索的过程中扫描的行数。（@b-@a只会是4000）

1. rows_examined就是“server层调用引擎取一行的时候”加1；
2. 引擎内部自己调用，读取行，不加1；

加索引的时候，也要扫描全表，但如果是inplace DDL（@第13篇），你会看到扫描行数是0，也是因为这些扫描动作都是引擎内部自己调用的。

**有个 order by 使用场景 ， 有个页面，需要按数据插入时间倒序来查看一张记录表的信息 ，因为除了分页的参数 ， 没有其他 where 的条件 ，所以除了主键外没有其他索引 。这时候 DBA 让我给 create_time 创建索引， 说是按照顺序排列 ，查询会增快为什么**

1. 无条件查询如果只有order by create_time,即便create_time上有索引,也不会使用到。
   因为优化器认为走二级索引再去回表成本比全表扫描排序更高。
   所以选择走全表扫描,然后根据老师讲的两种方式选择一种来排序
2. 无条件查询但是是order by create_time limit m.如果m值较小,是可以走索引的.
   因为优化器认为根据索引有序性去回表查数据,然后得到m条数据,就可以终止循环,那么成本比全表扫描小,则选择走二级索引。
   即便没有二级索引,mysql针对order by limit也做了优化,采用堆排序。这部分老师明天会讲

 **mysql在做没有排序的查询语句的时候 每次扫描返回的结果集顺序一样吗？还是每次扫描的结果集顺序是变化的？**

要看使用的索引有没有变化，是按照索引顺序的

**分页limit过大时会导致大量排序，可以记录上一页最后的ID，下一页查询条件带上 where ID>上一页最后ID limit 100**

# 十七、如何正确的显示随机消息

英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开

现在，如果让你来设计这个 SQL 语句，你会怎么写呢？

为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：

```mysql

mysql> CREATE TABLE `words` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `word` varchar(64) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=0;
  while i<10000 do
    insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));
    set i=i+1;
  end while;
end;;
delimiter ;

call idata();
```

为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，我们就一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。

## 17.1 内存临时表

首先，你会想到用 order by rand() 来实现这个逻辑。

```mysql

mysql> select word from words order by rand() limit 3;
```

这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。

我们先用 explain 命令来看看这个语句的执行情况。

![图 1 使用 explain 命令查看语句的执行情况](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021648298.png)

Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。

这里的`order by rand()`需要用到临时表

https://dev.mysql.com/doc/refman/8.0/en/internal-temporary-tables.html

<!--什么情况下需要使用到临时表呢？ 临时表有内存和硬盘之分， tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。 磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。-->

因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序

这里，你可以先回顾一下上一篇文章中全字段排序和 rowid 排序的内容。我把上一篇文章的两个流程图贴过来，方便你复习。

![全字段排序](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021651476.jpg)

![图 3 rowid 排序](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021652999.jpg)

然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？回顾一下上一篇文章的一个结论：对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。<!--全字段排序认为可以减少回表，少访问磁盘，在innodb引擎被优先使用-->

我强调了“InnoDB 表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。

理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。

这条语句的执行流程是这样的：

1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。

> Q：为什么这里的临时表使用的引擎是memory？ A：tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表；磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。而内存临时表使用的是memory引擎

2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。
3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。
4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。
5. 从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。
6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。<!--rowid排序，存放的是排序的字段R和主键值，但是内存表没有主键，存放的就是位置信息-->
7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。

```mysql

# Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003
SET timestamp=1541402277;
select word from words order by rand() limit 3;
```

其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。

![图 4 随机排序完整流程图 1](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021742441.png)

图中的 pos 就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对 InnoDB 表排序的时候，明明用的还是 ID 字段。

这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。

在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？

其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。<!--innodb用rowid来唯一标识数据行： 对于有主键的innodb，rowid就是主键。 对于没有主键的innodb，rowid由系统生成。 对于Memory引擎，rowid就是数组下标。-->

这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。

* 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；
* 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；
* MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。

到这里，我来稍微小结一下：order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。

## 17.2 磁盘临时表

那么，是不是所有的临时表都是内存表呢？

其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。

磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。

<!--mysql 8.0 版本应该是这个参数：default_tmp_storage_engine-->

当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。

为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。

```mysql

set tmp_table_size=1024;
set sort_buffer_size=32768;
set max_length_for_sort_data=16;
/* 打开 optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* 执行语句 */
select word from words order by rand() limit 3;

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
```

![图 5 OPTIMIZER_TRACE 部分结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021748774.png)

因为将 max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。

这时候你可能心算了一下，发现不对。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（至于为什么是 6 字节，就留给你课后思考吧），数据总行数是 10000，这样算出来就有 140000 字节，超过了 sort_buffer_size 定义的 32768 字节了。但是，number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？

> Q: rowId为什么是6个字节 A: 6个字节能表示2的48次方个数
>
> 64位Linux操作系统下内存虚拟地址寻址空间并不是 2^64，而是 2^48 

这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。

其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。

也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量

而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：

1. 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组
2. 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；
3. 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。

这里我简单画了一个优先队列排序过程的示意图。

![图 6 优先队列排序算法示例](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203021754502.png)

图 6 是模拟 6 个 (R,rowid) 行，通过优先队列排序找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。

图 5 的 OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。

这个流程结束后，我们构造的堆里面，就是这个 10000 行里面 R 值最小的三行。然后，依次把它们的 rowid 取出来，去临时表里面拿到 word 字段，这个过程就跟上一篇文章的 rowid 排序的过程一样了。

我们再看一下上面一篇文章的 SQL 查询语句：

```mysql

select city,name,age from t where city='杭州' order by name limit 1000  ;
```

你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。

总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。

再回到我们文章开头的问题，怎么正确地随机排序呢？

## 17.3 随机排序方法

我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：

1. 取得这个表的主键 id 的最大值 M 和最小值 N;
2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;
3. 取不小于 X 的第一个 ID 的行。

我们把这个算法，暂时称作随机算法 1。这里，我直接给你贴一下执行语句的序列:

```mysql

mysql> select max(id),min(id) into @M,@N from t ;
set @X= floor((@M-@N+1)*rand() + @N);
select * from t where id >= @X limit 1;
```

这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。<!--随机值落到空洞区间，会取到同一个值。空洞区间越大，空洞越多，越容易得到同一个值,举例，索引id数组{1、2、5}，随机算法是(5-1)/rand() + 1，则最大值是4，最小值接近1，在索引树中，5的命中概率更高，因为2到5的区间空洞更大-->

比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。

如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。

所以，为了得到严格随机的结果，你可以用下面这个流程:

1. 取得整个表的行数，并记为 C。
2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分
3. 再用 limit Y,1 取得一行。

我们把这个算法，称为随机算法 2。下面这段代码，就是上面流程的执行语句的序列。

```mysql

mysql> select count(*) into @C from t;
set @Y = floor(@C * rand());
set @sql = concat("select * from t limit ", @Y, ",1");
prepare stmt from @sql;
execute stmt;
DEALLOCATE prepare stmt;
```

由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。

这个随机算法 2，解决了算法 1 里面明显的概率不均匀问题。

MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。

当然，随机算法 2 跟直接 order by rand() 比起来，执行代价还是小很多的。

你可能问了，如果按照这个表有 10000 行来计算的话，C=10000，要是随机到比较大的 Y 值，那扫描行数也跟 20000 差不多了，接近 order by rand() 的扫描行数，为什么说随机算法 2 的代价要小很多呢？我就把这个问题留给你去课后思考吧。

<!--why? 为什么随机算法2比order by rand()的代价小很多？ 因为随机算法2进行limit获取数据的时候是根据主键排序获取的，主键天然索引排序。获取到第9999条的数据也远比order by rand()方法的组成临时表R字段排序再获取rowid代价小的多-->

现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：

1. 取得整个表的行数，记为 C；
2. 根据相同的随机方法得到 Y1、Y2、Y3；
3. 再执行三个 limit Y, 1 语句得到三行数据。

我们把这个算法，称作随机算法 3。下面这段代码，就是上面流程的执行语句的序列。

```mysql

mysql> select count(*) into @C from t;
set @Y1 = floor(@C * rand());
set @Y2 = floor(@C * rand());
set @Y3 = floor(@C * rand());
select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
select * from t limit @Y2，1；
select * from t limit @Y3，1；
```

## 17.4 小结

今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。

如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要尽量避开这种写法。

<!--使用order by rand()需要使用临时表，以及sort buffer，临时表中存rand算出的临时小数以及word字段（10000次扫描）。后面再创建sort buffer将临时表的排序字段以及生成的位置信息拷贝过去（10000次扫描），进行排序，再根据排好序的前三条的位置信息回临时表取出值，此时共有20003次扫描。使用优化算法1在id范围内取随机整数会出现空洞问题，使用算法2利用随机生成现有条目数的排序号到数据库取值，开销比算法1大，需要获取表条目数并扫描前n个数据，但是解决了空洞问题，比最初的方法好，因为没有排序的过程，不用sort buffer，也不用创建临时表，因为没有创建临时属性，优化算法的计算取id和序号过程应该尽量在业务代码中生成-->

今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。

## 17.5 思考题

上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。

我的问题是，如果你是这个需求的开发人员，你会怎么做，来减少扫描行数呢？说说你的方案，并说明你的方案需要的扫描行数。

取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：

```mysql

mysql> select * from t limit N, M-N+1;
```

再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。

当然也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句也是可以的。。

## FAQ

对应单词这种总量不是很多的数据，第一感觉应该装jdk缓存或者redis缓存。由于需要随机访问，数组比较好。假如一个单词平均10个字节，10*10000，不到1M就装下了。
如果一定要用数据库来做，方案1比较好，空洞的问题，如果单词库不变，可以在上线前整理数据，把空洞处理调。比如：原来单词存在A表，新建B表 ，执行 insert into B(word) select word from A. B的id是自增的，就会生成连续的主键。当然如果A表写比较频繁，且数据量较大，业务上禁用 这种写法，RR的隔离级别会锁A表

---

**limit n order by 非索引字段 进行分页查询。数据库符合条件的count=147000条，分页查询count也正确，但是分页查询出的147000条数据中存在重复数据。**

https://juejin.cn/post/6943089541200740360

limit n, a; 显示a条记录；然后 limit n+a, a显示第二组a条件记录；
这两组a个记录出现了重复数据对吧，是的，是因为limit 有可能出现两种算法，比如直接排序和优先队列排序，就是不同的结果。而limit 后面的参数，是会影响算法的

可以得到结论是，**分页重复数据是否出现与排序字段数据唯一性有关，与排序字段是否有序无关**，换句话说，只要排序字段的数据能够保证唯一性（如主键、唯一索引、不重复的普通字段），那么分页就不会存在重复数据，否则会有可能出现重复数据在不同分页中。

**使用或结合数据唯一的字段进行排序**

---

**行器只是调引擎接口获取结果，但是我认为order by的排序过程应该是在执行器执行的吧？内存临时表使用的memory引擎，应该也是在server端，而磁盘临时表应该是innodb内部是这样吗？**

mysql的执行过程都是由执行器来调度的，不论创建memory临时表还是innodb临时表，都是执行器调用引擎的创建表接口实现的，写数据和读数据也是排序这个操作，是在server层做的

---

**什么情况下会产生临时表Using temporary？**

 查询需要临时表，比如我们这个例子里，需要临时表来放rand()结果

---

**你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。**

**上面的limit 1000 不是才14000么？14000小于32768的还是优先队列排序算法把？这里是不是10000少写了个0呢？**

最小堆的维护代价比数组大，不只是14*1000哦

---

**全字段排序、rowid排序 与 临时文件算法（归并排序算法）、优先队列排序算法的 作用点分别在哪里？**

当sql中有order by要求排序，而此时没有合适的索引可以避免排序的话，则只能选择一种排序方式（要么全字段排序，要么rowid排序），另外排序时需要空间来搞的（要么使用内存临时表，要么使用文件临时表）。当sql中除了有order by X还有limit Y时，说明排序后的结果取前Y就够了，那么在选择排序算法（要么是归并排序，要么是优先队列）上会选择优先队列算法

**游标跟limit在大数据量分页的时候 性能怎么样？**

执行 limit a,b 的时候，会把a+b这么多数据全部读出来，然后丢掉前面a条，返回后面的b条，因此a很大的时候，性能会很差

# 十八、为什么这些SQL语句逻辑相同，性能却差异巨大

在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。

3个走不了索引的情况：

1. 函数操作了列；
2. 隐式转换字段类型；
3. 字符集不同。

## 18.1 案例一：条件字段函数操作

假设你现在维护了一个交易系统，其中交易记录表 tradelog 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下

```mysql

mysql> CREATE TABLE `tradelog` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `operator` int(11) DEFAULT NULL,
  `t_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`),
  KEY `t_modified` (`t_modified`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：

```mysql

mysql> select count(*) from tradelog where month(t_modified)=7;
```

由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。

如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。

现在你已经学过了 InnoDB 的索引结构了，可以再追问一句为什么？为什么条件是 where t_modified='2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？

下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值。

![图 1 t_modified 索引示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031417949.png)

如果你的 SQL 语句条件用的是 where t_modified='2018-7-1’的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified='2018-7-1’需要的结果。

实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。

但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。

也就是说，**对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。**<!--虽然优化器权衡后依然选择了走索引，但是这个索引没有办法通过树搜索功能快速定位，只能全索引扫描(遍历索引树)。-->

需要注意的是，优化器并不是要放弃使用这个索引。

在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。

接下来，我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031511255.png)

key="t_modified"表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引。

也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。

```mysql

mysql> select count(*) from tradelog where
    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or
    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or 
    -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
```

当然，如果你的系统上线时间更早，或者后面又插入了之后年份的数据的话，你就需要再把其他年份补齐。

到这里我给你说明了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。

不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以

## 18.2 案例二：隐式类型转换

接下来我再跟你说一说，另一个经常让程序员掉坑里的例子。我们一起看一下这条 SQL 语句：

```mysql

mysql> select * from tradelog where tradeid=110717;
```

交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。

那么，现在这里就有两个问题：

1. 数据类型转换的规则是什么？
2. 为什么有数据类型转换，就需要走全索引扫描？

先来看第一个问题，你可能会说，数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？

这里有一个简单的方法，看 select “10” > 9 的结果：

1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；
2. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。

![MySQL 中字符串和数字转换的效果示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031522445.png)

从图中可知，select “10” > 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。

这时，你再看这个全表扫描的语句：

```mysql

mysql> select * from tradelog where tradeid=110717;
```

就知道对于优化器来说，这个语句相当于：

```mysql

mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。

现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？

```mysql

select * from tradelog where id="83126";
```

接下来，我们再来看一个稍微复杂点的例子。

## 18.3 案例三：隐式字符编码转换

假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。

```mysql

mysql> CREATE TABLE `trade_detail` (
  `id` int(11) NOT NULL,
  `tradeid` varchar(32) DEFAULT NULL,
  `trade_step` int(11) DEFAULT NULL, /*操作步骤*/
  `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/
  PRIMARY KEY (`id`),
  KEY `tradeid` (`tradeid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

insert into tradelog values(1, 'aaaaaaaa', 1000, now());
insert into tradelog values(2, 'aaaaaaab', 1000, now());
insert into tradelog values(3, 'aaaaaaac', 1000, now());

insert into trade_detail values(1, 'aaaaaaaa', 1, 'add');
insert into trade_detail values(2, 'aaaaaaaa', 2, 'update');
insert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');
insert into trade_detail values(4, 'aaaaaaab', 1, 'add');
insert into trade_detail values(5, 'aaaaaaab', 2, 'update');
insert into trade_detail values(6, 'aaaaaaab', 3, 'update again');
insert into trade_detail values(7, 'aaaaaaab', 4, 'commit');
insert into trade_detail values(8, 'aaaaaaac', 1, 'add');
insert into trade_detail values(9, 'aaaaaaac', 2, 'update');
insert into trade_detail values(10, 'aaaaaaac', 3, 'update again');
insert into trade_detail values(11, 'aaaaaaac', 4, 'commit');
```

这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：

```mysql

mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
```

![image-20220303153023677](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031530758.png)

我们一起来看下这个结果：

1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；
2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。

在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 称为关联字段。

接下来，我们看下这个 explain 结果表示的执行流程：

![图 5 语句 Q1 的执行过程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031532145.png)

1. 第 1 步，是根据 id 在 tradelog 表里找到 L2 这一行；
2. 第 2 步，是从 L2 中取出 tradeid 字段的值；
3. 第 3 步，是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配。

进行到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过使用 tradeid 索引能够快速定位到等值的行。但，这里并没有。

果你去问 DBA 同学，他们可能会告诉你，因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。

但是你应该再追问一下，为什么字符集不同就用不上索引呢？

我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：

```mysql

mysql> select * from trade_detail where tradeid=$L2.tradeid.value; 
```

其中，$L2.tradeid.value 的字符集是 utf8mb4。

参照前面的两个例子，你肯定就想到了，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。<!--超集是指：若集合s1中包含集合s2中所有的元素，且s1中存在s2中没有的元素，那么就称s1是s2的超集，s2是s1的子集-->

> 这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。

因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。

也就是说，实际上这个语句等同于下面这个写法：

```mysql

select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 
```

CONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。

这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。

到这里，你终于明确了，字符集不同只是条件之一，**连接过程中要求在被驱动表的索引字段上加函数操作**，是直接导致对被驱动表做全表扫描的原因。

作为对比验证，我给你提另外一个需求，“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。

```mysql
mysql>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;
```

![图 6 explain 结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031536154.png)

这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1。

这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？我们来分析一下。

假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接的时候（图 5 的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：

```mysql

select operator from tradelog  where traideid =$R4.tradeid.value; 
```

这时候 $R4.tradeid.value 的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：

```mysql

select operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); 
```

你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。

理解了原理以后，就可以用来指导操作了。如果要优化语句

```mysql

select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;
```

的执行过程，有两种做法

* 比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。

```mysql

alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;
```

* 如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。

````mysql

mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 
````

![图 7 SQL 语句优化后的 explain 结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031552741.png)

这里，我主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。	

## 18.4 小结

今天举了三个例子，其实是在说同一件事儿，即：**对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。**

第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。

MySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。

因此，业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。

## 18.5 思考题

```mysql

mysql> CREATE TABLE `table_a` (
  `id` int(11) NOT NULL,
  `b` varchar(10) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```

假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:

```mysql

mysql> select * from table_a where b='1234567890abcd';
```

这时候，MySQL 会怎么执行呢？

最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。

那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。

但实际上，MySQL 也不是这么做的。

这条 SQL 语句的执行很慢，流程是这样的：

1. 在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；
2. 这样满足条件的数据有 10 万行；
3. 因为是 select *， 所以要做 10 万次回表；
4. 但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;
5. 返回结果是空。
6. 这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。

## FAQ

**历史表数据如何查询超时如何处理**

先缩小范围，全部查完再整合

---

**a表有100条记录，b表有10000条记录，两张表做关联查询时，是将a表放前面效率高，还是b表放前面效率高？**

(这题目改成100万禾10000万比较好)
如果是考察语句写法，这两个表谁放前面都一样，优化器会调整顺序选择合适的驱动表；

如果是考察优化器怎么实现的，你可以这么想，每次在树搜索里面做一次查找都是log(n), 所以对比的是100*log(10000)和 10000*log(100)哪个小，显然是前者，所以结论应该是让小表驱动大表。

---

**字符集和排序集上有什么最佳实践么**

作者回复: 字符串都选Utf8mb4 好了

---

# 十九、为什么我只查一行的数据，也执行这么慢

一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话题，看看什么情况下，会出现这个现象。

需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。

为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。

```mysql

mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000) do
    insert into t values(i,i);
    set i=i+1;
  end while;
end;;
delimiter ;

call idata();
```

接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看能不能一眼看穿，来检验一下吧。

## 19.1 第一类：查询长时间不返回

如图 1 所示，在表 t 执行下面的 SQL 语句：

```mysql

mysql> select * from t where id=1;
```

查询结果长时间不返回。

![图 1 查询长时间不返回](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031719817.png)

一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。

然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。

### 19.1.1 等 MDL 锁

如图 2 所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。

![图 2 Waiting for table metadata lock 状态示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031721802.png)

出现这个状态表示的是**，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。**

在第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现方法。但需要说明的是，那个复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。

不过，在 MySQL 5.7 版本下复现这个场景，也很容易。如图 3 所示，我给出了简单的复现步骤。

![图 3 MySQL 5.7 中 Waiting for table metadata lock 的复现步骤](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031723223.png)

session A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。

这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。

是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)

https://dev.mysql.com/doc/refman/5.7/en/performance-schema-metadata-locks-table.html

通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。

<!--执行一下select * from performance_schema.setup_instruments where name='wait/lock/metadata/sql/mdl'，看一下ENABLED和TIMED是不是都是YES，只有两个都是YES的时候才能执行文章中说的操作。 具体可以参考官方文档： https://dev.mysql.com/doc/refman/5.7/en/sys-schema-table-lock-waits.html https://dev.mysql.com/doc/refman/5.7/en/metadata-locks-table.html UPDATE performance_schema.setup_instruments SET ENABLED = 'YES', TIMED = 'YES' where name='wait/lock/metadata/sql/mdl';-->

![查获加表锁的线程 id](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031727652.png)

```mysql
SHOW PROCESSLIST
select * from performance_schema.setup_instruments where name='wait/lock/metadata/sql/mdl'
select  blocking_pid from sys.schema_table_lock_waits
kill 3768
```

### 19.1.2 等 flush

接下来，我给你举另外一种查询被堵住的情况。

我在表 t 上，执行下面的 SQL 语句：

```mysql

mysql> select * from information_schema.processlist where id=1;
```



你可以看一下图 5。我查出来这个线程的状态是 Waiting for table flush，你可以设想一下这是什么原因。

![图 5 Waiting for table flush 状态示意图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031731188.png)

这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个

```mysql
flush tables t with read lock;
flush tables with read lock;
```

这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。

<!--关闭所有已打开的表对象，同时将查询缓存中的结果清空。就是说Flush tables的一个效果就是会等待所有正在运行的SQL请求结束。 因为，SQL语句在执行前，都会打开相应的表对象，如select * from t1语句，会找到t1表的frm文件，并打开表内存对象。为了控制表对象使用的内存空间和其他资源，MySQL会隐式（后台表对象管理线程）或显式（flush tables等）来关闭已打开但并没有使用的表对象。 然而，正在使用的表对象是不能关闭的（如SQL请求仍在运行），因此，Flush Tables操作会被正在运行的SQL请求阻塞。-->

但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。

所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。<!--flush tables会等待正在运行的所有语句执行结束，即使运行的是查询请求。 如果flush tables被阻塞，关于tables里面任意表的请求也会阻塞-->

现在，我们一起来复现一下这种情况，复现步骤如图 6 所示：

![图 6 Waiting for table flush 的复现步骤](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031735209.png)

在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。

图 7 是这个复现步骤的 show processlist 结果。这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031736620.png)

### 19.1.3 等 行锁

现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。

```mysql

mysql> select * from t where id=1 lock in share mode; 
```

上面这条语句的用法你也很熟悉了，我们在第 8 篇《事务到底是隔离的还是不隔离的？》文章介绍当前读时提到过。<!--复习： mysql> select k from t where id=1 lock in share mode; mysql> select k from t where id=1 for update; select 语句如果加锁，是当前读；分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。-->

由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。

复现步骤和现场如下：

![图 8 行锁复现](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031740699.png)

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031740652.png)

然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。

这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。

查询方法是：

```mysql

mysql> select * from sys.innodb_lock_waits where locked_table='`test`.`t`'\G
```

![通过 sys.innodb_lock_waits 查行锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031741657.png)

可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。

不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。

实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。

## 19.2 第二类：查询慢

经过了重重封“锁”，我们再来看看一些查询慢的例子。

先来看一条你一定知道原因的 SQL 语句：

```mysql

mysql> select * from t where c=50000 limit 1;
```

作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。

![图 11 全表扫描 5 万行的 slow log](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031749740.png)

Rows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：**坏查询不一定是慢查询。**我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了

扫描行数多，所以执行慢，这个很好理解。

但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。

如图 12 所示，是这个例子的 slow log。可以看到，执行的语句是

```mysql

mysql> select * from t where id=1；
```

虽然扫描行数是 1，但执行时间却长达 800 毫秒。

![图 12 扫描一行却执行得很慢](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031750993.png)

是不是有点奇怪呢，这些时间都花在哪里了？

如果我把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒

![图 13 加上 lock in share mode 的 slow log](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031750579.png)

看上去是不是更奇怪了？按理说 lock in share mode 还要加锁，时间应该更长才对啊。

可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图 14 是这两个语句的执行输出结果。

![图 14 两个语句的输出结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031751852.png)

第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。

![图 15 复现步骤](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031751118.png)

你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。

session B 执行完 100 万次 update 语句后，id=1 这一行处于什么状态呢？你可以从图 16 中找到答案。

![图 16 id=1 的数据状态](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203031751326.png)

session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。

带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。

注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便你看图。

## 19.3 小结

执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。

http://mysql.taobao.org/monthly/2015/04/01/

在实际使用中，碰到的场景会更复杂。但大同小异，学会文章中介绍的定位方法，来定位并解决问题。

## 19.4 思考题

我们在举例加锁读的时候，用的是这个语句，select * from t where id=1 lock in share mode。由于 id 上有索引，所以可以直接定位到 id=1 这一行，因此读锁也是只加在了这一行上。

但如果是下面的 SQL 语句，

```mysql

begin;
select * from t where c=5 for update;
commit;
```

这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？

下篇文章解答

读提交隔离级别下，在语句执行完成后，是只有行锁的。而且语句执行完成后，InnoDB 就会把不满足条件的行行锁去掉。当然了，c=5 这一行的行锁，还是会等到 commit 的时候才释放的。

## FAQ

# 二十、幻读是什么，幻读有什么问题

在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。

为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：

```mysql

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。

上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？

```mysql

begin;
select * from t where d=5 for update;
commit;
```

比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。

由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？

<!--RR级别：扫描到的数据都会加行锁和间隙锁 RC级别：扫描到的数据都会加行锁，但是不满足条件的数据，没有到commit阶段，就会释放，违反了两阶段加锁原则 全表扫描一直指的是扫描主键索引-->

我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。

## 20.1 幻读是什么？

现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。

下面先来看一下这个场景（注意：这是我假设的一个场景）：

![图 1 假设只在 id=5 这一行加行锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041050291.png)

可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。

1. Q1 只返回 id=5 这一行；
2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；
3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。

其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

这里，我需要对“幻读”做一个说明：

<!--在同一个事务中，两次读取到的数据不一致的情况称为幻读和不可重复读。幻读是针对insert导致的数据不一致，不可重复读是针对 delete、update导致的数据不一致。-->

1. 可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
2. 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。

如果只从第 8 篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。

因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。

<!--因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。-->

但是，这是不是真的没问题呢？

不，这里还真就有问题。

## 20.2 幻读有什么问题？

**首先是语义上的。**session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。

如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041059159.png)

session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。

由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。

session C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。

**其次，是数据一致性的问题。**

我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。

为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：update t set d=100 where d=5。

![图 3 假设只在 id=5 这一行加行锁 -- 数据一致性问题](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041102132.png)

update 的加锁语义和 select …for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100

<!--SELECT ... LOCK IN SHARE MODE走的是IS锁(意向共享锁)，即在符合条件的rows上都加了共享锁，这样的话，其他session可以读取这些记录，也可以继续添加IS锁，但是无法修改这些记录直到你这个加锁的session执行完成(否则直接锁等待超时)。 SELECT ... FOR UPDATE 走的是IX锁(意向排它锁)，即在符合条件的rows上都加了排它锁，其他session也就无法在这些记录上添加任何的S锁或X锁。如果不存在一致性非锁定读的话，那么其他session是无法读取和修改这些记录的，但是innodb有非锁定读(快照读并不需要加锁)，for update之后并不会阻塞其他session的快照读取操作，除了select ...lock in share mode和select ... for update这种显示加锁的查询操作。 通过对比，发现for update的加锁方式无非是比lock in share mode的方式多阻塞了select...lock in share mode的查询方式，并不会阻塞快照读。-->

现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。

1. 现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。
2. 经过 T2 时刻，id=0 这一行变成 (0,5,5);
3. 经过 T4 时刻，表里面多了一行 (1,5,5);
4. 其他行跟这个执行序列无关，保持不变。



这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。

1. T2 时刻，session B 事务提交，写入了两条语句；
2. T4 时刻，session C 事务提交，写入了两条语句；
3. T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。

我统一放到一起的话，就是这样的：

```mysql

update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/

insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/
```

好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。

也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。

到这里，我们再回顾一下，**这个数据不一致到底是怎么引入的？**

我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。

所以我们认为，上面的设定不合理，要改。

那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。

<!--这里的假设没有间隙锁，只是表锁，所以c的insert的是可以执行的，但实际是被间隙锁阻塞的。-->

![假设扫描到的行都被加上了行锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041110264.png)

由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。

这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：

```mysql

insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/

update t set d=100 where d=5;/*所有d=5的行，d改成100*/

update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/
```

可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。

同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？

原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。<!--幻读产生的原因：即使给所有行加上了锁，也避免不了幻读，这是因为给行加锁的时候，这条记录还不存在，没法加锁-->

也**就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录**，这也是为什么“幻读”会被单独拿出来解决的原因。

到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。<!--幻读产生的原因：即使给所有行加上了锁，也避免不了幻读，这是因为给行加锁的时候，这条记录还不存在，没法加锁-->

接下来，我们再看看 InnoDB 怎么解决幻读的问题。

## 20.3 如何解决幻读？

现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。

顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041119069.png)

这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。

也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。<!--这样可以避免瞬间加上整个表的写锁，提高并发度； 被扫到了的部分才加上间隙锁，其他事务要等自己想要插入的间隙的间隙锁被释放了，才能顺利插入-->

1. 对主键或唯一索引，如果当前读时，where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加行记录锁。 　
2. 没有索引的列，当前读操作时，会加全表gap锁，生产环境要注意
3. 非唯一索引列，如果where条件部分命中(>、<、like等)或者全未命中，则会加附近Gap间隙锁。例如，某表数据如下，非唯一索引2,6,9,9,11,15。如下语句要操作非唯一索引列9的数据，gap锁将会锁定的列是(6,11]，该区间内无法插入数据。

现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。

比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。

![图 6 两种行锁间的冲突关系](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041122904.png)

也就是说，跟行锁有冲突关系的是“另外一个行锁”。

但是间隙锁不一样，**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作**。间隙锁之间都不存在冲突关系。<!--update/delete都会添加gap锁，因为触发了当前读，insert如果没有where条件只是加了行锁-->

这句话不太好理解，我给你举个例子：

![图 7 间隙锁之间不互锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041124280.png)

这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

> 备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。

你可能会问说，这个 supremum 从哪儿来的呢？

这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”

**间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。**

在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：

```mysql

begin;
select * from t where id=N for update;

/*如果行不存在*/
insert into t values(N,N,N);
/*如果行存在*/
update t set d=N set id=N;

commit;
```

可能你会说，这个不是 insert … on duplicate key update 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。

现在，我们就只讨论这个逻辑。

这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？

这里，我用两个 session 来模拟并发，并假设 N=9。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041128082.png)

你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：

1. session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);
2. session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；
3. session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；
4. session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。

<!--自己加的间隙锁只能允许自己进行插入操作，而不允许其他人进行插入操作，从而在当前读下读不到其他人新插入的记录，解决了幻读。-->

至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。

<!--MySQL InnoDB引擎死锁检测： 查询锁情况列表 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS 查询锁等待信息，其中blocking_lock_id是当前事务在等待的事务 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS 死锁解决： MySQL数据库通过死锁检测（innodb_deadlock_detect）和死锁超时时间（innodb_lock_wait_timeout）这两个参数来进行死锁解决。 死锁检测（innodb_deadlock_detect)：在MySQL 8.0中，增加了一个新的动态变量innodb_deadlock_detect，用来控制InnoDB是否执行死锁检测。 该参数的默认值为ON，即打开死锁检测。开启后InnoDB在加锁的时候会检测加锁后是否会造成死锁，如果会加锁，就回滚代价最小的那一个事务。 死锁超时时间（innodb_lock_wait_timeout）：这个参数可以用来处理检测不出来的死锁，或是避免长时间等待较长的事务的情况。 对于高并发的系统，当大量线程等待同一个锁时，死锁检测可能会导致性能的下降。 此时，如果禁用死锁检测，而改为依靠参数innodb_lock_wait_timeout来释放长时间占用锁资源的事务可能会更加高效。 也就是说，在确认死锁检测功能影响了系统的性能并且禁用死锁检测不会带来负面影响时，可以尝试关闭innodb_deadlock_detect选项。 另外，如果禁用了InnoDB死锁检测，需要及时调整参数innodb_lock_wait_timeout的值，以满足实际的需求。-->

你现在知道了，**间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的**。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例子。

<!--间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。 但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。-->

你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。

我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。

<!--举例： 删除 statement记录的是这个删除的语句，例如： delete from t where age>10 and modified_time<='2020-03-04' limit 1 而row格式记录的是实际受影响的数据是真实删除行的主键id，例如： delete from t where id=3 and age=12 and modified_time='2020-03-05'-->

前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加 binlog_format=row 的组合。他曾问他们公司的 DBA 说，你为什么要这么配置。DBA 直接答复说，因为大家都这么用呀。

所以，这个同学在评论区就问说，这个配置到底合不合理。

关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。<!--什么时候需要可重复读呢，金融的业务，财务需要统计过去一段时间内某些数据，需要反复根据某些条件查找，此时如果有新数据行插入，会导致统计时发生数据不一致的情况，此时需要使用可重复读的隔离级别-->

但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。

但是，如果 DBA 认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出问题。

<!--只有在可重复读的隔离级别下，才会有间隙锁。读提交的隔离级别下不会有间隙锁-->

<!--为什么在读提交级别下，binlog_format需要设置为row？？ 原因是在可重复读级别下，有行锁 + 间隙锁 = next-key锁 来保证不出现幻读以及binlog不出现错误； 但在读提交级别下，是不会加间隙锁的，所以需要修改binlog_format；-->

比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》的内容）

<!--官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数--single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。-->

然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？

<!--没有问题，不管是提交读还是可重复读，都是MVCC支持，唯一的不同，就是生成快照的时间点不同，也就是能够看到的数据版本不同，即使是提交读情况下，多个不同的事物时间不也是这种情况吗，所以相互并不影响。-->

进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？

如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。

## 20.4 小结

今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。

我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务 SQL 语句的时候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由于间隙锁导致的死锁现象。

行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循。下一篇文章，我就会为你讲解 InnoDB 的加锁规则，帮你理顺这其中的“章法”。

## 20.5 思考题

![图 9 事务进入锁等待状态](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041139167.png)

如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。

你可以试着分析一下，出现这种情况的原因是什么？

这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预习的，其中 session C 被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会在下一篇文章和你详细说明。

你也可以说说，你的线上 MySQL 配置的是什么隔离级别，为什么会这么配置？你有没有碰到什么场景，是必须使用可重复读隔离级别的呢？



# 二十一、为什么我只改一行数据，锁这么多

在上一篇文章中，我和你介绍了间隙锁和 next-key lock 的概念，但是并没有说明加锁规则。间隙锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问题上犯错。

所以今天，我们就先从这个加锁规则开始吧。

首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，**这个规则有以下两条前提说明**

1. MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。
2. 如果大家在验证中有发现 bad case 的话，请提出来，

因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。

**我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。**

1. 原则 1：加锁的基本单位是 next-key lock。，next-key lock 是前开后闭区间。<!--加锁的基本单位是next-key-lock ，扫描过程中扫到了当前这个值比如10 ，加锁就就是加的(5，10]-->
2. 原则 2：查找过程中访问到的对象才会加锁。
3. 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
4. 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。

```mysql

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。

## 21.1 案例一：等值查询间隙锁

第一个例子是关于等值条件操作间隙：

![图 1 等值查询的间隙锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041555858.png)

由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：

1. 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2. 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。

<!--图 1 等值查询的间隙锁由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。案例二：非唯一索引等值锁第二个例子是关于覆盖索引上的锁：图 2 只加在非唯一索引上的锁看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。这里 session A 要给索引 c 上 c=5 的这一行加上读锁。根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock-->

所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。

## 21.2 案例二：非唯一索引等值锁

第二个例子是关于覆盖索引上的锁：

![图 2 只加在非唯一索引上的锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041604706.png)

看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。

这里 session A 要给索引 c 上 c=5 的这一行加上读锁。

1. 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。
2. 要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。
3. 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。
4. 根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。

但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。

需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。

这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。你可以自己验证一下效果。<!--数据行加读锁，如果查询字段使用了覆盖索引，访问到的对象只有普通索引，并没有访问到主键索引，则不会锁主键索引。如果没有使用覆盖索引，且当前查询是for update ,update 和 delete 都是当前读，则会回表查询，访问到主键索引，这样主键索引也会加锁。-->

## 21.3 案例三：主键索引范围锁

举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？

```mysql

mysql> select * from t where id=10 for update;
mysql> select * from t where id>=10 and id<11 for update;
```

你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。

在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。

![图 3 主键索引上范围查询的锁](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041630638.png)

现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？

1. 开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
2. 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。<!--实际上这是一个BUG, 我在8.0.20版本里面就只有(10,15)了-->

所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。

这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。

## 21.4 案例四：非唯一索引范围锁

接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。

需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。

![图 4 非唯一索引范围锁](https://static001.geekbang.org/resource/image/73/7a/7381475e9e951628c9fc907f5a57697a.png)

这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。

所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。

## 21.5 案例五：唯一索引范围锁 bug

前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。

![图 5 唯一索引范围锁的 bug](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041705782.png)

session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。

但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。

所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。

照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。

## 21.6 案例六：非唯一索引上存在"等值"的例子

接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。

```mysql

mysql> insert into t values(30,10,30);
```

新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。

![图 6 非唯一索引等值的例子](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041719839.png)

可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。

图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。

现在，我们来看一下案例六。

这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”

![图 7 delete 示例](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041720538.png)

这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。

然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。

也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041725202.png)

这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。<!--如果session b插入(4,5,50)，不会被锁，如果插入（6,5,50） 会被锁住，因为6,5,50根据主键来排的话 是在5,5,10后面的 因为二级索引叶子节点存储的是主键值，而二级索引的叶子节点是有序的，这样(6,5,5)插入的时候就会排序到(5,5,5)之后，进入了间隙锁范围内。-->

## 21.6 案例七：limit 语句加锁

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041727892.png)

这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。

这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。

这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。

因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：

![图 10 带 limit 2 的加锁效果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041729646.png)

可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。

这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。

## 21.7 案例八：一个死锁的例子

前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。

你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：

![图 11 案例八的操作序列](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203041732626.png)

> session B的操作语句update t set d = d + 1 where c =10; 由于c是非唯一键索引，锁（5，10」可以理解
> ，为什么不锁(10,15} 呢，不是应该继续向后扫描直到第一个不满足条件的值为止吗
>
> 会锁的，只是因为在(5,10]就被锁住了，所以后面的锁加不上去了

现在，我们按时间顺序来分析一下为什么是这样的结果。

1. session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；
2. session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；<!--先加(5, 10)的间隙锁，然后加10的行锁，锁住，还没有来得及加（10，15]的next-key lock呢，就被10的行锁给锁住了，所以这个时候session A 如果插入（12,12,12）是不会被session B的间隙锁给锁住。-->
3. 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。

你可能会问，session B 的 next-key lock 不是还没申请成功吗？

其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。

<!--就算分成了两步，为什么session B加(5,10)就能成功呢？session A不是加了(5, 10]的锁吗？ 好吧，自问自答一下，前面应该也是提到过的，间隙锁和间隙锁之间并不冲突，间隙锁和insert到这个间隙的语句才会冲突，因此session B加间隙锁(5, 10)是可以成功的，但是如果往(5, 10)里面插入的话会被阻塞。 但是如果直接加next-key lock(5, 10]，那么肯定是会被阻塞的，因此这个例子确实说明，加锁的步骤是分两步的，先是间隙锁，后是行锁。而且只要理解了间隙锁和行锁之间冲突的原则是不一样的，也就很容易理解这两个锁并不是一起加的了。-->

也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。

## 21.8 小结

1. 查询过程中访问到的对象才会加锁，而加锁的基本单位是next-key lock（前开后闭）；
2. 等值查询上MySQL的优化：索引上的等值查询，如果是唯一索引，next-key lock会退化为行锁，如果不是唯一索引，需要访问到第一个不满足条件的值，此时next-key lock会退化为间隙锁；
3. 范围查询：无论是否是唯一索引，范围查询都需要访问到不满足条件的第一个值为止；

这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。

1. gap lock 只发生于可重复读隔离级别下
2. 可重复读隔离级别下遵守两阶段提交，事务结束才释放锁 
3. read-commited 没有gap lock 
4. read-commited 语句执行完就释放“不满足条件的行”的行锁，而不是在事务结束的时候才释放

后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。

<!--next-key，那么就是next gap+next record，所以叫next-key-lock，所以是左开右闭；而gap-lock呢，是说间隙，那么是开区间-->

其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。

另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。

也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。

不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。

在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。

## 21.9 课后问题

下面这个图的执行序列中，为什么 session B 的 insert 语句会被堵住。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203052247852.png)

我们用加锁规则来分析一下，看看 session A 的 select 语句加了哪些锁：

1. 由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。<!--本来要加(20，25]的，但是25不满足条件，所以优化为(20，25)了-->
2. 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。
3. 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。

<!--加锁是加在索引上的，而c和id是不同的索引。 索引c上，20,15,10这3行都被访问了，应该都加了行锁。 然后由于是 select * 所以需要回表，id 上的对应行也会被加锁。 但是c=10这行并不满足条件，只是在索引c上被访问了，加了锁，不满足条件就丢弃了，不会回表，所以id上没有被访问，也不会加锁。 即c上有20,15,10加锁，id上只有20,15加锁。-->

因此，session A 的 select 语句锁的范围就是：

1. 索引 c 上 (5, 25)；
2. 主键索引上 id=15、20 两个行锁。<!--where条件是c>=15&&c<=20,回表不就id=15和id=20嘛，id=10 应该只是在c索引上被访问的，没有回表-->

每次加锁都会说明是加在“哪个索引上”的。因为，锁就是加在索引上的，这是 InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。

## FAQ

**如 案例五：唯一索引范围锁 bug**
**begin;**
**select * from t where id>10 and id<=15 for update;**
**1、执行如上语句加锁范围(10,15]和(15,20]；**
**2、因为10未加锁，所以我单独再开一个连接，执行delete from t where id=10;不会锁等待，能正常删除；**
**3、但是我再执行insert into t values(10,10,10); 语句会等待，无法正常执行；**
**4、经过分析我发现第一个连接执行的语句的加锁范围已经变成(5,15]和(15,20]，代表锁蔓延了；这是什么原因呢？**

Gap是一个动态的概念


**版本：mysql 5.6.39**
**CREATE TABLE `t` (**
 **`a` int(11) NOT NULL,**
 **`b` int(11) DEFAULT NULL**
**) ENGINE=InnoDB DEFAULT CHARSET=utf8;**
**insert into t values(1,1),(2,2),(3,3),(4,4),(5,5);**
**采用READ-COMMITTED隔离级别**
**案例1、**
**session A：**
**begin;**
**update t set a=6 where b=1;**
**session B：**
**begin;**
**update t set a=7 where b=2;**
**A和B均能执行成功**
**问题1：官档上说对于RC且全表扫描的update，先逐行添加行锁然后释放掉不符合where条件的，那么session A成功对(1,1)加锁，理论上session B在扫描(1,1)并尝试加锁时会被阻塞，为何还能执行成功？官档链接：https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html**

**案例2：**
**session A：**
**begin;**
**update t set a=6 where b=1;**
**session B：**
**begin;**
**delete from t where b=2; -- 被阻塞**
**问题2：为何案例1 中的session B不会被阻塞，而案例2的却被session A的行数阻塞，update和delete都是全部扫描，难道加锁机制不一样？**

在read-commited隔离级别下，update语句
有一个“semi-consistent” read优化，

意思是，如果update语句碰到一个已经被锁了的行，会读入最新的版本，然后判断一下是不是满足查询条件，
a)如果不满足，就直接跳过；
b) 如果满足，才进入锁等待

你的第二个问题：这个策略，只对update有效，delete无效

# 二十二、MySQL有哪些“饮鸩止渴”提高性能的方法？

不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。

我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。

但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。

## 22.1 短连接风暴

正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。

我在第 1 篇文章《基础架构：一条 SQL 查询语句是如何执行的？》中说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。

在数据库压力比较小的时候，这些额外的成本并不明显。

但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。

在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。

碰到这种情况时，一个比较自然的想法，就是调高 max_connections 的值。但这样做是有风险的。因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。<!--这个和创建线程数量是一个道理。线程并不是创建的越多越好，因为CPU资源就那么点，线程越多，每个线程分到的时间片越少，CPU花费最多的时间反而是在线程切换以及上下文保存、读取上，而不是在执行线程上。-->

那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。

### 22.1.1 第一种方法：先处理掉那些占着连接但是不工作的线程。

max_connections 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 kill connection 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。show variables like 'wait_timeout';

但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。

![图 1 sleep 线程的两种状态](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203052213618.png)

在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。

但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。

![图 2 sleep 线程的两种状态，show processlist 结果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203052217147.png)

图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。

![图 3 从 information_schema.innodb_trx 查询事务状态](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203052218667.png)

这个结果里，trx_mysql_thread_id=4，表示 id=4 的线程还处在事务中。

因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。

从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。

从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。

你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。

所以，如果你是一个支持业务的 DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。

### 22.1.2 第二种方法：减少连接过程的消耗。

有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。

跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。

但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。

在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 --skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。

## 22.2 慢查询性能问题

在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：

1. 索引没有设计好；
2. SQL 语句没写好；
3. MySQL 选错了索引。

接下来，我们就具体分析一下这三种可能，以及对应的解决方案。

### 22.2.1 导致慢查询的第一种可能是，索引没有设计好。

种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。

比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：

1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；
2. 执行主备切换；
3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。

这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。

### 22.2.2 导致慢查询的第二种可能是，语句没写好。

比如，我们犯了在第 18 篇文章《为什么这些 SQL 语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。

这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。

比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。

```mysql

mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

call query_rewrite.flush_rewrite_rules();
```

这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。你可以用图 4 中的方法来确认改写规则是否生效

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203052234048.png)

1 是 MySQL的一个插件，安装插件后将自动创建 query_rewrite 库 rewrite_rules 表。 

2 作用：把输入的一种语句改写成另一种模式 

3 优势：当业务无法及时调整时可通过MySQL将接收到的语句改写，如强制使用索引等

导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章《MySQL 为什么有时候会选错索引？》中提到的情况，MySQL 选错了索引。

这时候，应急方案就是给这个语句加上 force index。

同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。

上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。

1.  上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；
2. 在测试表里插入模拟线上的数据，做一遍回归测试；
3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。

不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。

如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。

## 22.3 QPS 突增问题

有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。

我之前碰到过一类情况，是由一个新功能的 bug 导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。

而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。

1. 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。
2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。
3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成"select 1"返回。

当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：

1. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；
2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。

所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。

同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。

## 22.4 小结

今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。

这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。

在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。

DBA 虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好 SQL 审计可以减少需要这类操作的机会。

其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server 层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。

最后，又到了我们的思考题时间了。

今天，课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？

## FAQ

**问题1 “如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。**

这个问题是因为重启之后，业务请求还会再发。而且由于是重启，buffer pool 被清空，可能会导致语句执行得更慢。

**问题2 多个单字段索引与联合索引**

有时候一个表上会出现多个单字段索引（而且往往这是因为运维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方法，是一个很好的应对方案。

**问题场景**

客户端程序的连接器，连接完成后会做一些诸如 show columns 的操作，在短连接模式下这个影响就非常大了。这个提醒我们，在 review 项目的时候，不止要 review 我们自己业务的代码，也要 review 连接器的行为。一般做法就是在测试环境，把 general_log 打开，用业务行为触发连接，然后通过 general log 分析连接器的行为。

如果你的数据库请求模式直接对应于客户请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推广，压力暴增，这样很容易把数据库打挂。在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业务，是一个好的设计方向。



# 二十三、MySQL是怎么保证数据不丢的？

今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL 是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。

在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下第 2 篇、第 9 篇、第 12 篇和第 15 篇文章中的相关内容），得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。

评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log 真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程。

## 23.1 binlog 的写入机制

其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

​	一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。<!--也就是说binlog cache是由内存和临时文件两个部分构成的，因为内存总是有限的，而在事务完成前，又不能写入最终的日志文件，那就只能写入到临时文件-->

事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。

<!--即使在redo coomit 阶段，binlog cache的内容正在写入到binlog过程中，异常重启；这个时候binlog 肯定没有发送到其他下游服务；而且这个时候redo log 还处于prepare 阶段； 那重启后，就是直接回滚数据；虽然丢掉上一次操作的数据，但是最终还是能保证数据一致性；-->

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071113180.png)

可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。

* 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。

<!--Page Cache是OS关于磁盘IO的缓存，位于内核中，不适用于大文件传输，因为大文件传输page cache的命中率比较低，这个时候page cache不仅没有起到作用还增加了一次数据从磁盘buffer到内核page cache的开销-->

<!--高版本的Linux系统中已经把Buffer跟虚拟文件系统的page cache合并在一起了，因此也就没有从磁盘buffer拷贝到内核page cache的开销-->

<!--因为 pagecache 是系统机制 只要主机不挂 进程重启是不会丢失数据的-->

* 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的：

1. sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

<!--从这里可以看出，其实 sync_binlog 参数可以理解为控制 fsync 的触发时机，因为无论其值是0/1/2，write 这一步是一定会发生的。 而对于 fsync 来说，当参数值为 0 时，由 OS 去决定 fsync 的时机；当参数值为 1 时，每次提交事务都会触发 fsync；当参数值为 N（N > 1）时，累计提交 N 个事务时才会触发 fsync。-->

因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。

但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

## 23.2 redo log 的写入机制

接下来，我们再说说 redo log 的写入机制。

在专栏的第 15 篇答疑文章中，我给你介绍了 redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。

然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？

如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。

那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？

答案是，确实会有

这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。

![图 2 MySQL redo log 存储状态](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071323801.png)

这三种状态分别是：

1. 存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；

2. 写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；

   <!--fsync函数同步内存中所有已修改的文件数据到储存设备 一般情况下，对硬盘（或者其他持久存储设备）文件的write操作，更新的只是内存中的页缓存（page cache），而脏页面不会立即更新到硬盘中，而是由操作系统统一调度，如由专门的flusher内核线程在满足一定条件时（如一定时间间隔、内存中的脏页达到一定比例）内将脏页面同步到硬盘上（放入设备的IO请求队列）。 因为write调用不会等到硬盘IO完成之后才返回，因此如果OS在write调用之后、硬盘同步之前崩溃，则数据可能丢失-->

3. 持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。

日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。

为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：

1. 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
2. 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；

<!--这个值的设置和前面学到的redo log的流程并不是按照顺序对应的，需要注意下。不过还是可以知道，这三个取值对应着写到redo log buffer，page cache和hard disk这三种情况。 设置为0，只写内存，不管是主机掉电还是MySQL异常重启，都有丢数据的风险，风险高，但是写入快 设置为1，直接写到磁盘，没有丢数据的风险，风险低，但是写入慢 设置为2，写入文件系统的page cache，主机掉电后会丢数据，但是MySQL异常重启不会丢数据，风险较低，写入比较快。 一般而言配置成1、2比较常见-->

1. 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

<!--与binlog不同，binlog是每个线程都有一个binlog cache，而redo log是多个线程共用一个redo log buffer。-->

注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。

实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。

1. **一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。**注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。

2. **另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘**。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。

这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。

> 1、redolog在prepare阶段持久化到磁盘（可能失败）
>
>  2、紧接着binlog持久化（可能失败） 
>
> 3、最后redolog commit（可能失败） 
>
> 情况一：在1处mysql异常重启，redo log没有fsync，内存丢失，直接回滚，不影响数据一致性；
>
>  情况二：redolog fsync成功，但是binlog写入错误，此时mysql异常重启，现在有redolog的磁盘数据没有binlog的数据，此时检测redolog处于prepare阶段，但是没有binlog，回滚（虽然刚刚redolog fsync了但是不影响数据一致性，因为redolog的操作并没有写入mysql，也永远不会写入mysql）； 
>
> 情况三：binlog完整但未commit，此时检测redolog处于prepare阶段，且binlog完整但未提交，默认添加commit标记，进而提交，写入mysql，满足数据一致性； 情况四：binlog完整且提交，写入mysql，满足一致性；

如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下第 15 篇文章中的相关内容）。

<!--也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？我们先来看一下崩溃恢复时的判断规则。 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。-->

每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。

<!--redolog 在prepare阶段就已经落盘了，此时commit阶段即时写入失败，只是丢失redolog的commit标识，数据不会丢。commit标识可以通过binlog日志的完整性来判断。-->

通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？

解释这个问题，就要用到组提交（group commit）机制了。

这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。

LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。

如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071348818.png)

1. trx1 是第一个到达的，会被选为这组的 leader；
2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；

<!--这里的写盘指的是真的写磁盘！ 这三个事务都处于 redo log prepare阶段，都打算开始刷写redo log到磁盘，由于事务1最早，所以事务1是老大，他不光刷写自己的redo log，还把小弟们的redo log也刷写了。-->

3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；

4. 这时候 trx2 和 trx3 就可以直接返回了。

所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。

在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。

<!--虽然innodb_flush_log_at_trx_commit 设置成 1，事物每次prepare （注意不是commit)都要刷盘，但这个过程的执行是需要消耗时间的，在这个时间段内，其它事物也在执行，所以可以把它们组成一个组，一起刷盘-->

为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。

![图 4 两阶段提交](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071353436.png)

图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：

1. 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；
2. 调用 fsync 持久化。

MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：

![图 5 两阶段提交细化](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071358720.png)

这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。

不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。

<!--老师说的快，只是单纯的指redo log的fsync快，因为是顺序写。因此导致第二步和第四步之间的间隔比较短。想想看，如果第三步很慢的话，第二部和第四部之间的间隔就会很久，然后第四部binlog fsync的数据就会很多，可以很好的利用组提交。但其实不是这样的，所以可以根据需要配置参数-->

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

<!--在这里 sync_binlog 设置为大于1的值 ,代表的是会进行write 但是会等待N个事务才会进行fsync,如果在N个事务之间系统断电,由于还没有进行持久化,导致事务是丢失的,但是注意此时前面成功的事务会告诉客户端已经commit成功了! 相当于是write后就通知客户端commit成功. binlog_group_commit_sync_no_dely_count 如果是N,在N个事务成功的时候进行持久化,此时会告诉客户端commit成功,事务已经进行了持久化,不会丢失事务数据 此外 会先以sync_binlog为准,满足这个条件之后 ,会继续满足组提交的条件,如果设置的延迟时间比较长,会满足no_dely_count参数-->

这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。

所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。

之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？

现在你就能理解了，WAL 机制主要得益于两个方面：

1. redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；
2. 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

分析到这里，我们再来回答这个问题：**如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？**

针对这个问题，可以考虑以下三种方法：

1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。

## 23.3 小结

在专栏的第 2 篇和第 15 篇文章中，我和你分析了，如果 redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe 的。今天这篇文章，我着重和你介绍的是 MySQL 是“怎么保证 redo log 和 binlog 是完整的”。

**问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？**

回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。

**问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？**

回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。

而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。

**问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？**

回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。

**问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？**

你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。

实际上数据库的 crash-safe 保证的是：

1. 如果客户端收到事务成功的消息，事务就一定持久化了；
2. 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；
3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。

## 23.4 思考题

你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？

另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？



1. 业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。
2. 备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。
3. 用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。
4. 批量导入数据的时候。

一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。

## FAQ

**问题：  当设置sync_binlog=0时，每次commit都只时write到page cache，并不会fsync。但是做实验时binlog文件中还是会有记录，这是什么原因呢？是不是后台线程每秒一次的轮询也会将binlog cache持久化到磁盘？还是有其他的参数控制呢？**

你看到的“binlog的记录”，也是从page cache读的哦。
Page cache是操作系统文件系统上的😄

**问题 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？**

binlog存储是以statement或者row格式存储的，而redo log是以page页格式存储的。page格式，天生就是共有的，而row格式，只跟当前事务相关

**问题 事务A是当前事务，这时候事务B提交了。事务B的redolog持久化时候，会顺道把A产生的redolog也持久化，这时候A的redolog状态是prepare状态么？**

不是。

说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段，也就是说，在事务A提交的时候，我们才会走到事务A的redo log prepare这个阶段。

事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A还没有进入提交阶段，是无所谓“redo log prepare”的。

问题 **sync_binlog和binlog_group_commit_sync_no_delay_count这两个参数区别**

**如果**
       **sync_binlog = N**
       **binlog_group_commit_sync_no_delay_count = M**
       **binlog_group_commit_sync_delay = 很大值**
**这种情况fsync什么时候发生呀，min(N,M)吗？**
**感觉sync_binlog搭配binlog_group_commit_sync_delay也可以实现组提交？**

**如果**
        **sync_binlog = 0**
         **binlog_group_commit_sync_no_delay_count = 10**
**这种情况下是累计10个事务fsync一次？**

达到N次以后，可以刷盘了，然后再进入(sync_delay和no_delay_count)这个逻辑；

Sync_delay如果很大，就达到no_delay_count才刷；

只要sync_binlog=0,也会有前面的等待逻辑，但是等完后还是不调fsync

**为什么binlog 是不能“被打断的”的呢？主要出于什么考虑？**

我觉得一个比较重要的原因是，一个线程只能同时有一个事务在执行。

由于这个设定，所以每当执行一个begin/start transaction的时候，就会默认提交上一个事务；
这样如果一个事务的binlog被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。

binlog的基于事务维度来记录的，，就是说一个完整的binlog就是一个完整的事务，如果binlog拆开了，那这个事务的记录就不完整了、不原子了，所以一个事务的binlog不能拆开。而redo log的记录是基于数据页的，一个事务可以有很多数据页的记录，只要保证redo log的数据页维度记录是完整的就可以，所以redo log是可以拆开的。

redo log的每一个page都是独立的单元，每个page header都会记录事务id信息。所以打散了没关系，还能串起来。binlog一个事务只会记录一次事务id，如果打散了就串不起来了。

**对于binlog写入问题**

认为binlog写到file里面就是写到disk了，就不理解为什么还要fsync，后来仔细回读了文章，发现binlog写到file是指写到pagecache，并不是disk。
建议老师在描述binlog写盘的那两个步骤时，把写到file直接描述为写到pagecache，避免歧义

**因为binlog不能被打断,那么binlog做fsync是单线程吧?**
**如果是的话,那么binlog的write到fsync的时间,就应该是redo log fsync+上一个事务的binlog fsync时间。**

Write的时候只要写进去了，fsync其实很快的。连续性是write的时候做的（写的时候保证了连续）

**文章说innodb的 redo log 在commit的时候不进行fsync，只会write 到page cache中。当sync_binlog>1,如果redo log 完成了prepare持久化落盘，binlog只是write page cache，此时commit标识完成write 但没有落盘，而client收到commit成功，这个时候主机掉电，启动的时候做崩溃恢复，没有commit标识和binglog，事务会回滚。我看文章说sync_binlog设置为大于1的值，会丢binlog日志,此时数据也会丢失**

**sync_binlog和binlog_group_commit_sync_no_delay_count的最大区别主要在于，数据的丢失与否吧？**

**sync_binlog = N：每个事务write后就响应客户端了。刷盘是N次事务后刷盘。N次事务之间宕机，数据丢失。**

binlog_group_commit_sync_no_delay_count=N： 必须等到N个后才能提交。换言之，会增加响应客户端的时间。但是一旦响应了，那么数据就一定持久化了。宕机的话，数据是不会丢失的。

---

**每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。老师好，这句话怎么理解呢？这不是服务器重启的情况下，会丢失1秒的数据吗**

: 不是，这意思就是，即使异常掉电，只要redo log的prepare 部分+binlog完整，就会保证不丢数据。

也就是说，最多会丢失1秒的“redo log commit信息”，但是这个commit信息丢失，并不会影响数据（就是崩溃恢复慢一点）

---

**sync_binlog和binlog_group_commit_sync_no_delay_count的最大区别**

sync_binlog和binlog_group_commit_sync_no_delay_count的最大区别主要在于，数据的丢失与否吧？

sync_binlog = N：每个事务write后就响应客户端了。刷盘是N次事务后刷盘。N次事务之间宕机，数据丢失。

binlog_group_commit_sync_no_delay_count=N： 必须等到N个后才能提交。换言之，会增加响应客户端的时间。但是一旦响应了，那么数据就一定持久化了。宕机的话，数据是不会丢失的。

**并发事务的redolog持久化，会把当前事务的redolog持久化，当前事务的redolog持久化后prepare状态么？redolog已经被持久化到磁盘了，那么当前事务提交时候，redolog变为prepare状态，这时候是从redologbuffer加载还是从磁盘加载？**

每个事务在提交过程的prepare阶段，会把redolog持久化； “当前事务的redolog持久化后prepare状态么”这个描述还是不清楚，你用事务A、事务B这样来描述吧😆 redolog已经被持久化到磁盘了，那么当前事务提交时候， （其实这里只是“部分”被持久化，因为这个事务自己在执行的过程中，还会产生新的日志），只需要继续持久化剩下的redo log

# 二十四、MySQL是怎么保证主备一致的？



```mysql

查看binlog_format:
show session variables like 'binlog_format';
修改日志格式：
set session binlog_format=statement;
set session binlog_format=row;
查看日志文件列表：
show binary logs;
根据查看到的日志文件使用显示日志事件的命令:
show binlog events in 'XXX';
```



在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。

毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。

在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。

今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。

## 24.1 MySQL 主备的基本原理

如图 1 所示就是基本的主备切换流程。

![图 1 MySQL 主备切换流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071621097.png)

在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。

当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。

在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：

1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
3. 可以用 readonly 状态，来判断节点的角色。

你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？

这个问题，你不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

接下来，我们再看看节**点 A 到 B 这条线的内部流程是什么样的**。图 2 中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。

![图 2 主备流程图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071624678.png)

图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log 的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。<!--从图2中可以看到，redologcommit成功后，才回复ack,binlog写成功后就可以同步至备库，为什么不需要等到redologcommit成功后呢，是因为binlog写盘成功，就算后续commit失败，数据库也是可以自己恢复重新commit的-->

备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：

1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。

这里需要说明，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。

分析完了这个长连接的逻辑，我们再来看一个问题：binlog 里面到底是什么内容，为什么备库拿过去可以直接执行。

## 24.2 binlog 的三种格式对比

**3种格式：**

1. statement 记录的就是SQL语句 对于delete limit，主备可能因为选择索引不同，导致执行结果不一致 
2. ow binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。 可以用来恢复数据 不会存在主备不一致 占用空间大
3.  3. mixed

我在第 15 篇答疑文章中，和你提到过 binlog 有两种格式，一种是 statement，一种是 row。可能你在其他资料上还会看到有第三种格式，叫作 mixed，其实它就是前两种格式的混合。

<!--statement：备库在执行主库的语句时执行结果可能不一致。原因：如果 where 条件中有多个索引，主备库在执行这条语句时，选择的索引可能不同，执行结果也就不同 row：由于记录的是修改的主键的 id，备库执行结果与主库一致-->

为了便于描述 binlog 的这三种格式间的区别，我创建了一个表，并初始化几行数据。

```mysql

mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  KEY `a` (`a`),
  KEY `t_modified`(`t_modified`)
) ENGINE=InnoDB;

insert into t values(1,1,'2018-11-13');
insert into t values(2,2,'2018-11-12');
insert into t values(3,3,'2018-11-11');
insert into t values(4,4,'2018-11-10');
insert into t values(5,5,'2018-11-09');
```

如果要在表中删除一行数据的话，我们来看看这个 delete 语句的 binlog 是怎么记录的。

注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。

```mysql

mysql> delete from t /*comment*/  where a>=4 and t_modified<='2018-11-10' limit 1;
```

当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。你可以用命令看 binlog 中的内容。

```mysql

mysql> show binlog events in 'master.000001';
```

![图 3 statement 格式 binlog 示例](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071632150.png)

现在，我们来看一下图 3 的输出结果。

* 第一行 SET @@SESSION.GTID_NEXT='ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；
* 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；
* 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。use 'test’命令之后的 delete 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。
* 最后一行是一个 COMMIT。你可以看到里面写着 xid=61。你还记得这个 XID 是做什么用的吗？如果记忆模糊了，可以再回顾一下第 15 篇文章中的相关内容。

<!--XID是用来联系bin log和redo log的。比如redo log里面有一个事务是prepare状态，但是不知道是不是commit状态，那就可以用XID去bin log里面查询该事务到底有没有提交。有提交则是commit状态，若没有提交则回滚该事务。-->

为了说明 statement 和 row 格式的区别，我们来看一下这条 delete 命令的执行效果图：

![图 4 delete 执行 warnings](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071652374.png)

可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。

为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：

1. 如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；
2. 但如果使用的是索引 t_modified，那么删除的就是 t_modified='2018-11-09’也就是 a=5 这一行。

由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险

那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。

![图 5 row 格式 binlog 示例](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071654825.png)

可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。

1. Table_map event，用于说明接下来要操作的表是 test 库的表 t;
2. Delete_rows event，用于定义删除的行为。

其实，我们通过图 5 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为图 5 中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析。

```mysql

mysqlbinlog  -vv data/master.000001 --start-position=8900;
```

<!--如果报mysqlbinlog: [ERROR] unknown variable 'default-character-set=utf8'错误，可在-vv前加上--no-defaults参数-->

![图 6 row 格式 binlog 示例的详细信息](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071658291.png)

从这个图中，我们可以看到以下几个信息：

* server id 1，表示这个事务是在 server_id=1 的这个库上执行的。
* 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。
* Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。
* 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。
* binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。
* 最后的 Xid event，用于表示事务被正确地提交了。

你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。

## 24.3 为什么会有 mixed 格式的 binlog？

基于上面的信息，我们来讨论一个问题：**为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：**

* 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
* 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。
* 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。

也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。

因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。

比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。

当然我要说的是，**现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row**。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。

接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。

通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。

如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。

如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了

其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。

虽然 mixed 格式的 binlog 现在已经用得不多了，但这里我还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：

```mysql
mysql> insert into t values(10,10, now());
```

如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？

先不要着急说结果，我们一起来看一下这条语句执行的效果。

![图 7 mixed 格式和 now()](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071710028.png)

可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？

接下来，我们再用 mysqlbinlog 工具来看看：

![图 8 TIMESTAMP 命令](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071711756.png)

从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。

<!--从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。-->

因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行，值都是固定的。也就是说，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性。	

我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。<!--使用binlog恢复数据时不能直接将binlog将其中的语句等拷贝出来直接执行，因为数据是基于上下文执行的。需要用到特定的解析工具，并将解析后的语句放入mysql执行-->

你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。

所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：

```mysql

mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;
```

这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。

## 24.4 循环复制问题

通过上面对 MySQL 中 binlog 基本内容的理解，你现在可以知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。

因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图 1 中 A、B 两个节点的内容是一致的。其实，图 1 中我画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是图 9 所示的主备切换流程。

![图 9 MySQL 主备切换流程 -- 双 M 结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203071715743.png)

对比图 9 和图 1，你可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。

但是，双 M 结构还有一个问题需要解决。

业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。

那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？

从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：

1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：

1. 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；
2. 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；
3. 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。

## 24.5 小结

今天这篇文章，我给你介绍了 MySQL binlog 的格式和一些基本机制，是后面我要介绍的读写分离等系列文章的背景知识，希望你可以认真消化理解。

binlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。

我也跟你介绍了 MySQL 不同格式 binlog 的优缺点，和设计者的思考。希望你在做系统开发时候，也能借鉴这些设计思想。

## 24.6 思考题

说到循环复制问题的时候，我们说 MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。

你能构造出一个这样的场景吗？又应该怎么解决呢？

一种场景是，在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。

另一种场景是，有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。

![](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081524714.png)

这种三节点复制的场景，做数据库迁移的时候会出现。

如果出现了循环复制，可以在 A 或者 A’上，执行如下命令：

```mysql

stop slave；
CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);
start slave;
```

这样这个节点收到日志后就不会再执行。过一段时间后，再执行下面的命令把这个值改回来。

```mysql

stop slave；
CHANGE MASTER TO IGNORE_SERVER_IDS=();
start slave;
```



## FAQ

**主库 A 从本地读取 binlog，发给从库 B；这里的本地是指文件系统的 page cache还是disk呢？**

是这样的，对于A的线程来说，就是“读文件”，

1. 如果这个文件现在还在 page cache中，那就最好了，直接读走；
2. 如果不在page cache里，就只好去磁盘读

这个行为是文件系统控制的，MySQL只是执行“读文件”这个操作

**双M架构下，主从复制，是不是一方判断自己的数据比对方少就从对方复制，判断依据是什么**

一开始创建主备关系的时候， 是由备库指定的。
比如基于位点的主备关系，备库说“我要从binlog文件A的位置P”开始同步， 主库就从这个指定的位置开始往后发。


而主备复制关系搭建完成以后，是主库来决定“要发数据给备库”的。所以主库有生成新的日志，就会发给备库。

**备库最开始是怎么确定位置的呢？**

备库启动同步的时候指定开始同步的binlog和binlog内部位移的参数，分别是MASTER_LOG_FILE和MASTER_LOG_POS参数

**事务所有产生的binlog 大于  max_binlog_size 值呢？ 那不是永久地rotate吗？ mysql是如何处理的？**

我之前理解是，mysql 每执行一条事务所产生的binlog准备写到 binlog file时，都会先判断当前文件写入这条binlog之后是否会超过设置的max_binlog_size值。 如果超过，则rotate 自动生成下个binlog flie 来记录这条binlog信息。

一个事务的binlog日志不会被拆到两个binlog文件，所以会等到这个事务的日志写完再rotate，所以你会看见超过配置大小上限的binlog 文件

**假如周日23点做了备份，周二20点需要恢复数据，那么在用binlog恢复时，如何恰好定位到周日23点的binlog,谢谢。**

Mysqlbinlog有个参数—stop-datetime 

**如果一张表并没有主键，插入的一条数据和这张表原有的一条数据所有字段都是一样的，然后对插入的这条数据做恢复，会不会把原有的那条数据删除？不知道在没有主键的情况下binlog会不会也记录数据库为其生成的主键id**

会删除一条，但确实可能删除到之前的那条。

主要就是因为，没有主键的时候，binlog里面就不会记录主键字段。

**请教一下，生产环境能不能使用正常使用表连接？要注意哪些地方？DBA总是说不建议用，还催促我将使用了表连接的地方改造，但也说不出个所以然。目前在两个百万级数据的表中有用到内连接，并没有觉得有什么问题**

索引使用正确，不要出现全表扫描，其实OK的

**文中说现在越来越多的使用row方式的binlog，那么只能选择接受写入慢和占用空间大的弊端么？**

是的，当然还有minimal可选，

**生产上用的是MySQL5.6的主从同步，主库用的是ssd硬盘，备库用的是机械硬盘，现在从库落后主库好几个小时，主库上数据的写入更新比较大，这个问题是由于两端硬件问题造成的吗？线上只有一个数据库，有什么好的同步加速方案吗？**

好是换硬件,把备库的磁盘能力提上来,

可以考虑一下备库设置 innodb_flush_log_at_trx_commit 和 sync_binlog 为非双1 试试

**主库挂了怎么办**

1. mysql主从+keepalived/heartbeat
        有脑裂，还是有前面丢数据问题

2. 用MMM或HMA之类
3. 用ZK之类

**主备复制关系搭建完成，主有数据写入的时候，发送给备的应该不是整个binlog log文件吧，是每次写入的binlog event么？**

 流式发送，一个事务提交就会发

**、在图 2 主备流程图对bg-thread->undolog(disk)->data(disk)不太理解，回滚段也是先记录到内存，再记录在磁盘么？undolog(disk)再到data(disk),看了下undo log的控制参数没有看到控制类似行为的，**

 “回滚段也是先记录到内存，再记录在磁盘么？” 是的。  undolog(disk)不需要到data(disk)，undo log的作用看一下08篇

**“update时，需要记录更新前后的数据，那这样的话，chage buffer不是用不上了么”**

不是的，binlog里面的内容用的是主键索引上的，主键索引确实用不上change buffer，但是普通索引可以

**查到主从状态中出现：Slave_SQL_Running_State: Waiting for Slave Workers to free pending events。不知道这个是否会引起延迟。查了些资料说得都不是很明白。老师是否可以简短解答下。以及这种延迟如何避免。**

这个的意思是， 现在工作线程里面等待的队列太多，都已经超过上限了，要等工作线程消化掉一些事务再分

简单说，就是备库的应用日志的队列太慢了。。

# 二十五、MYSQL是怎么保证高可用的

在上一篇文章中，我和你介绍了 binlog 的基本内容，在一个主备关系中，每个备库接收主库的 binlog 并执行。

正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。

但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重和你分析一下。

这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。

![图 1 MySQL 主备切换流程 -- 双 M 结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081355963.png)

## 25.1 主备延迟

主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。

接下来，我们先一起看看主动切换的场景。

在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：

1. 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;
2. 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;
3. 备库 B 执行完成这个事务，我们把这个时刻记为 T3。

所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。

你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒

> 'SHOW SLAVE STATUS' is deprecated and will be removed in a future release. Please use SHOW REPLICA STATUS instead

seconds_behind_master 的计算方法是这样的：

1. 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；
2. 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。

可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，我们可以用 seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。

你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？

其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。

需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。

所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。

## 25.2 主备延迟的来源

### 25.2.1 备库所在机器的性能要比主库所在的机器性能差

首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。

一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。

其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。

但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。

当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。

### 25.2.2 备库的压力大

追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？

这就是**第二种常见的可能了，即备库的压力大**。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。<!--一般用于读写分离；请求压力大时 可做一主多从 从库中又可分为冷热备份 热备份主要用于分担读请求 冷备份用于数据的完整性保障-->

我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。

<!--针对不同的情况选择不同的技术方案：针对从库的压力过大，可以选择一主多从，由从库来分担读的压力，这种策略在redis也存在，即：主从从架构，减少单个从库的压力。针对数据分析造成的压力，或者一些可以通过离线策略实现的方案，通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力，这一类主要是针对产品的数据分析需求。其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。-->

这种情况，我们一般可以这么处理：

1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。

其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。

> 备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。

追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？

### 25.2.3 大事务。

大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。

不知道你所在公司的 DBA 有没有跟你这么说过：**不要一次性地用 delete 语句删除太多数据**。其实，这就是一个典型的大事务场景。

比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。

结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。

**另一种典型的大事务场景，就是大表 DDL。**这个场景，我在前面的文章中介绍过。处理方案就是，计划内的 DDL，建议使用 gh-ost 方案（这里，你可以再回顾下第 13 篇文章《为什么表数据删掉一半，表文件大小不变？》中的相关内容）。

追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？

造成主备延迟还有一个大方向的原因，就是**	**。这个话题，我会留在下一篇文章再和你详细介绍。

由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。

## 25.3 可靠性优先策略

在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：

1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
2. 把主库 A 改成只读状态，即把 readonly 设置为 true；
3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止
4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
5. 把业务请求切到备库 B。

这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。

![2 MySQL 可靠性优先主备切换流程](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081442584.png)

备注：图中的 SBM，是 seconds_behind_master 参数的简写。

可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。

在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。

试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。

当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。

## 25.4 可用性优先策略

如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。

我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。

<!--其实这就是CAP中的C和A，MySQL主库在写完binlog后就给客户端响应了，没等binlog同步到一个或多个备库，这种策略是在C和A之间选择了A，牺牲了C，如果主库宕机了，但binlog的最后一个或几个事务没同步到备库，那备库成为主库后，数据就丢了。其它的NoSQL很多是给用户提供了选择，比如Mongo，用户可以设置日志同步到几个Slave后再给客户端响应，同步的Slave越多，C越强，A越弱，比如同步到X个Slave后再给客户端响应，那即使任何X个节点宕机，集群中仍然有1个节点有最新日志，它会成为主节点，数据没丢，集群还可以工作。-->

接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：

```mysql

mysql> CREATE TABLE `t` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `c` int(11) unsigned DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

insert into t(c) values(1),(2),(3);
```

这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：

```mysql

insert into t(c) values(4);
insert into t(c) values(5);
```

假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。

图 3 是**可用性优先策略，且 binlog_format=mixed** 时的切换流程和数据结果。

![图 3 可用性优先策略，且 binlog_format=mixed](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081458125.png)

现在，我们一起分析下这个切换流程

1. 步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据（4,4），之后开始进行主备切换。

2. 步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。

3. 步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。

   <!--就是在主键自增的表中，插入4和插入5这两条语句在备库上执行的时间不一样，导致备库上的ID和主库上的ID不一致。-->

4. 步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）

最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。

那么，如果我还是用可**用性优先策略，但设置 binlog_format=row**，情况又会怎样呢？

因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行

图 4 中我画出了详细过程，你可以自己再分析一下。

![图 4 可用性优先策略，且 binlog_format=row](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081503859.png)

从上面的分析中，你可以看到一些结论：

1. 使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。

<!--这里已经悄悄涉及到CAP理论了，一致性C，可用性A，分区容错性P，三者不可兼得，最多只能同时满足两个。主备产生了两个分区，所以P已经被占了，只剩下一个，所以要么只能选一致性C，要么只能选可用性A。如果既想要一致性C又想要可用性A，那只能放弃P，变回单点。-->

2. 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。

但事无绝对，**有没有哪种情况数据的可用性优先级更高呢？**

答案是，有的。我曾经碰到过这样的一个场景：

* 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。
* 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。

这时候，你可能就需要选择先强行切换，事后再补数据的策略。

当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。

这样的话，这种场景就又可以使用可靠性优先策略了。

接下来我们再看看，**按照可靠性优先的思路，异常切换会是什么效果？**

假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了

![图 5 可靠性优先策略，主库不可用](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081506602.png)

采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master=0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。

你可能会问，那能不能直接切换到备库 B，但是保持 B 只读呢？

这样也不行。

因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。

虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。

聊到这里你就知道了，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。

## 25.5 小结

今天这篇文章，我先和你介绍了 MySQL 高可用系统的基础，就是主备切换逻辑。紧接着，我又和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。

然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先和可用性优先策略的区别。

在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。

<!--AP和CP不可兼得，要CP，就要忍受延迟及其间不可用；要保证AP，就可能不一致。对于MySQL，一般优先保证一致性。 NoSQL以及分布式存储系统中，基本都是C和A的折中，数据同步给一个或多个节点后，再给客户端响应，同步节点越多，C越强，A越弱，但一般至少同步一个节点，以防主节点挂了后，新主与原主数据不一致。 Mysql主写完binlog不等备写就响应客户端，万一主挂了，新主（即原备库）会数据不一致，另外，人为进行主备切换也很麻烦，你要等主备延迟小于指定阈值时才可以切，要等到什么时候呢？你无法确定，你如果把阈值调大，那主备切换时，系统不可用时间会相应增大。后续Mysql应该也会做类似的优化吧-->

### 主从延迟的情况

1. 主库DML语句并发大,从库qps高

2. 从库服务器配置差或者一台服务器上几台从库(资源竞争激烈,特别是io)

3. 主库和从库的参数配置不一样

4. 大事务(DDL,我觉得DDL也相当于一个大事务)

<!--1、ddl先拿metadata锁，如果有备库的表被查询，需要等待 2、ddl需要扫描全表-->

5. 从库上在进行备份操作

6. 表上无主键的情况(主库利用索引更改数据,备库回放只能用全表扫描,这种情况可以调整slave_rows_search_algorithms参数适当优化下)

   <!--这个描述的场景是，在binlog_format=row，如果主库使用update更新很多条语句的话，同步到从库就是一行行的更新记录，每一个更新记录从库都需要全表扫面一遍，而主库的更新只需要一次全表扫描就更新完成了，即使主库使用索引更新，那么也是需要一次全表扫描-->

7. 设置的是延迟备库

8. 备库空间不足的情况下
9. 对myisam存储引擎的表做dml操作，从库会有延迟。
10. 利用pt工具对主库的大表做字段新增、修改和添加索引等操作，从库会有延迟。

semi-sync在网络故障超时的情况下会退化成async，这个时候如果刚好主库掉电了，有些binlog还没有传给从库，从库无法判断数据跟主库是否一致，如果强行切换可能会导致丢数据，在金融业务场景下只能＂人工智能＂来做切换，服务中断时间长。AliSQL采用双通道复制更容易判断主备数据是否一致，如果一致可以自动切换，如果不一致才需要人工恢复数据。

### 复制延迟排查思路

1. **查数据库在干什么**

```mysql
pager cat - | grep -v Sleep | sort -rn -k 12 | head -n 20
show full processlist;
select * from information_schema.processlist where 1=1 order by TIME desc limit 10;
```

2. **查看sql_thread在干什么**

```mysql
slave上查看状态：show slave status\G;
查看relay_master_log_file以及exec_master_log_pos
master上解析binglog日志：mysqlbinlog -v --base64-output=decode-rows --start-position=exec_master_log_pos relay_master_log_file
```

3. **如果发现卡在操作某表上：**

* 检查表结构
  * 没有索引：stop slave 可能会卡主，建议关闭mysql，启动后先加索引，然后start slave
  * 有索引：只能等，大事务需要做拆分，不要操作太多数据
* 大事务：M上session回话使用statement格式，使用语句级别的复制 

4. **查看MySQL状态**

   机器性能（CPU、IO等）：从库配置适当高一点，使用新硬件PCI-E或SSD设备
   表结构:  设计要合理，必须有主键，主键要短小，为查询字段建索引
   业务程序：适当使用缓存，减少数据库压力
   分析MySQL进程并结合源码：perf top `pidof mysqld` 

5. **参数临时优化**

   主库开启group commit
   从库开启writeset
   从库设置sync_binlog=0 &&  innodb_flush_log_at_trx_commit=2

6. **检查锁情况**

   show engine innodb status\G;

## 26.6 思考题

一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。

假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？

![图 6 备库延迟](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081521090.png)

* 一种是大事务（包括大表 DDL、一个事务操作很多行）
* ；还有一种情况比较隐蔽，就是备库起了一个长事务，比如

```mysql
begin; select * from t limit 1;
```

然后就不动了。

这时候主库对表 t 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也会被堵住，也不能看到这个现象。

## FAQ

**如果备库连接主库之后，主库的系统时间修改了，备库同步的时候是否会自动修正？**

不会

**假设主库的binlog刚写成功还未来得及把binlog同步到从库，主库就掉电了，这时候从库的数据会不完整吗？**
**第二个问题，原主库重启加入集群后，那条没有传出去的binlog会如何处理？**

1.可能会丢
 		2. 要看重启之后的拓扑结构了，如果还有节点是这个库的从库，还是会拿走的

**发生主从切换的时候，主有的最新数据没同步到从，会出现这种情况吗，出现了会怎么样**

异常切换有可能的

要根据你的处理策略了，如果不能丢，有几个可选的

1. 不切换（等这个库自己恢复起来）

2. 使用semi-sync策略
3. 启动后业务做数据对账（这个一般用得少，成本高

**一般主从延时多少算是合理的？是秒级别吗？**

一般大于1就不好 ^_^

**生产环境有一张表需要清理，该表大小140G。要保留最近一个月的数据，又不能按时间直接用detele删（全表扫描），本来想通过清空分区表删，但是分区表又是哈希的。。有没好的办法呢？**

估计下一个月占多少比例，如果比较小就建新表，把数据导过去吧 如果一个月占比高的话，只能一点点删了。 时间字段有索引的话，每个分区按时间过滤出来删除

使用中是通过时间分别查询出开始和结束的主键ID,然后根据主键ID范围进行轮询删除

**备库做逻辑备份时，有产生MDL锁。然后复制线程刚好被堵塞。。kill掉备份线程，一切都畅快了。。我遇到过，但是感觉那备份期间产生的非共享锁不是短时间就释放的吗？为什么堵的时间那么长，感觉像是遇到死锁**

备库逻辑备份，首先要拿MDL写锁，如果这时备库有个慢查询就会导致备份堵在了拿锁阶段，后续队列的所有SQL都会hang住，表象就是主从延迟不断升高。

**主库断电了，怎么把binlog传给从库同步数据，怎么使的SBM为0主从切换呢**

主库断电了，但是在从库io上仍然还有binlog日志、或者说从库本地仍然还有binlog日志没处理完。所以即使主库不存在了，从库仍然要通过现存的binlog做好同步处理。直到从库同步的binlog日志时间和自己本地时间差小于5即SBM<=5，表示从库具备了可以变为主库的条件，等到SBM=0了，那么此时从库就可以变为主库进行读写了。所以也就是后面说的那句话：“高可用是依赖主备延时的（更详细的说是依赖备库在同步binlog的延时的）“。同步的binlog延时越小，从库在遇到极端情况下切为主库的动作就越及时～

# 二十六、备库为什么会延迟好几个小时？

在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。

但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。

这就涉及到今天我要给你介绍的话题：备库并行复制能力。

为了便于你理解，我们再一起看一下第 24 篇文章《MySQL 是怎么保证主备一致的？》的主备流程图。

![图 1 主备流程图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081624029.png)

谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。

在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。

而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。

在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。

从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说 MySQL 多线程复制的演进过程。

其实说到底，所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：

![图 2 多线程模型](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081643254.png)

图 2 中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。

<!--coordinator（sql_thread）：负责读取中转日志和分发事务，真正更新日志的变成了worker线程，worker线程的个数由slave_parallel_workers决定，为物理机核数的四分之一到二分之一。-->

接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？

其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。

接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？

答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。

所以，coordinator 在分发的时候，需要满足以下这两个基本要求：

1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。
2. 同一个事务不能被拆开，必须放到同一个 worker 中。

各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策略。

## 26.1 MySQL 5.5 版本的并行复制策略

官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，我自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。

这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解 MySQL 官方版本并行复制策略的迭代。

## 26.2 按表分发策略

按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。

当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图 3 所示，就是按表分发的规则。

![图 3 按表并行复制程模型](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081710389.png)

可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。

在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。

图 3 中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。

假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。

现在我们用事务 T 的分配流程，来看一下分配规则。

1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。
2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。
3. 事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。
4. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。
5. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。
6. coordinator 继续读下一个中转日志，继续分配事务。

也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：

1. 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;
2. 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；
3. 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。

这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。

## 26.2 按行分发策略

要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。

这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。

按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。

但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：

```mysql

CREATE TABLE `t1` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `a` (`a`)
) ENGINE=InnoDB;

insert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);
```

假设，接下来我们要在主库执行这两个事务：

![图 4 唯一键冲突示例](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081718359.png)

可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。

因此，基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”

比如，在上面这个例子中，我要在表 t1 上执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。

因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:

1. key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。
2. key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。
3. key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。

可见，**相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源**。你可能也发现了，这两个方案其实都有一些约束条件：

1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
2. 表必须有主键；
3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。

但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。

对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：

1. 耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。
2. 耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。

所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：

1. coordinator 暂时先 hold 住这个事务；
2. 等待所有 worker 都执行完成，变成空队列；
3. coordinator 直接执行这个事务；
4. 恢复并行模式。

读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。

## 26.3 MySQL 5.6 版本的并行复制策略

官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。

这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。

相比于按表和按行分发，这个策略有两个优势：

1. 构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。
2. 不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。



但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。

理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。

## 26.4 MariaDB 的并行复制策略

在第 23 篇文章中，我给你介绍了 redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：

1. 能够在同一组里提交的事务，一定不会修改同一行；

<!--原因：事务是在需要的时候加锁，但是必须是事务提交了之后才会释放锁，如果两个事务修改的是同一行，那么这两个事务需要获取相同的行锁，由于两个事务都没有提交，由于锁的互斥性，是不可能让两个事务同时拥有的，故能够在同一个组提交的事务，一定不会修改同一行。-->

1. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。

在实现上，MariaDB 是这么做的：

1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
2. commit_id 直接写到 binlog 里面；
3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
4. 这一组全部执行完成后，coordinator 再去取下一批。

当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。

但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。

如图 5 所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。

![图 5 主库并行事务](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081737428.png)

而按照 MariaDB 的并行复制策略，备库上的执行效果如图 6 所示。

![图 6 MariaDB 并行复制，备库并行效果](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081737641.png)

可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。

另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。<!--因为设计是一组一组事务的完成，所以同一时间只能有一组事务在多个worker工作，即使只剩一个worker在工作，其它worker空闲也不能继续其它工作。-->

不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。

## 26.5 MySQL 5.7 的并行复制策略

在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：

1. 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；
2. 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。

你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？

答案是，不能。

因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。

而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。

这时候，你可以再回顾一下两阶段提交，我把前面第 23 篇文章中介绍过的两阶段提交过程图贴过来。

![图 7 两阶段提交细化过程图](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202203081740337.png)

其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。

因此，MySQL 5.7 并行复制策略的思想是：

1. 同时处于 prepare 状态的事务，在备库执行时是可以并行的；
2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。

我在第 23 篇文章，讲 binlog 的组提交的时候，介绍过两个参数

1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。

<!--redolog-prepare之后要写binlog，如果控制binlog的日志落盘时间多延后一下，那么就能保证主库dump线程向备库提供的binlog数据的数量，保证一次性给到备库的数据同个commitID下可以有更多redolog-prepare的数据（因为23章已经说过，redolog 处于prepare阶段的时候，就已经基本上说明数据操作是有效的了）所以备库得到的一个commid组的数据就越多，那么并行度也就越高-->

也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。

## 26.6 MySQL 5.7.22 的并行复制策略

在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。

相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。

1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。

你可能看出来了，这跟我们前面介绍的基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：

1. writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
2. 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；
3. 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。

因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。

当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。

## 26.7 小结

在今天这篇文章中，我和你介绍了 MySQL 的各种多线程复制策略。

为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。

<!--主库更新操作时并非是单线程的, 而是并行的执行的, 因此, 如果备库只能支持单线程的复制显然可能导致主备延迟越来越大.-->

在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：

* 如果你是 DBA，就需要根据不同的业务场景，选择不同的策略；
* 如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。

从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。

官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。

## 26.8 思考题

假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。

这时候，你为了更快地让备库追上主库，要开并行复制。在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？

你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？
