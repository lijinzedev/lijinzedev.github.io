---
title: Mysql45讲个人笔记与总结
top: false
cover: false
toc: true
mathjax: true
categories:
  - mysql
tags:
  - mysql
date: 2021-11-13 19:43:52
password:
summary:
---

# Mysql45

# 一、基础架构，SQL语句如何执行

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111131946742.png)

## 1.1 Server层

Server层：查询缓存、分析器、优化器、执行器等 以及所有内置的函数（eg:日期、时间、数学和加密函数等）所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

### 1.1.1 连接器

​			客户端连接到服务端，获取到==权限==等信息，然后在连接的有效时长内(==interactive_timeout==和==wait_timeout==参数控制， 5.7版本会断开可以自动重连)对sql进行处理。

* connect-timeout：连接过程中的等待时间
* wait-timeout：连接完成后，使用过程中的等待时间
* interactive-timeout：交换式……

`show processlist`

```mysql
# 通过命令可以去查看连接状态
show processlist
show variables like 'wait_timeout';
```

**注意：**

> 连接器会到权限表中查询拥有的权限，之后这个连接练得权限判断逻辑，都依赖于读到的权限，并且，连接在建立之后如果修改权限也不影响已经存在的连接，只有连接新建的时候，才会生效

**长链接与短连接**

> **长链接与短连接**是一种“行为”，比如连接完，执行一个查询，就断开，这是短连接；执行一个查询，不断开，下次查询还用这个连接，持续使用，就是长链接
>
> 换句话说，在不用连接池的时候，每次查询都要获取连接，查询完成之后调用close方法，这就是短链接，使用连接池之后，因为连接都被放入容器中，每次用完就放进去，而不是close，这种就是长连接

**mysql_reset_connection** 影响的会话状态相关的信息

> mysql_reset_connection()影响以下与会话状态相关的信息： ·回滚活跃事务并重新设置自动提交模式 ·释放所有的表锁 ·关闭或删除所有的临时表 ·重新初始化会话的系统变量值 ·丢失用户定义的变量设置 ·释放prepared语句 ·关闭handler变量 ·将last_insert_id()的值设置为0 ·释放get_lock()获取的锁 ·清空通过mysql_bind_param()调用定义的当前查询属性 返回值： 0表示成功，非0表示发生了错误。

#### FQA

**如何解决长链接所导致的内存占用过大MySQL异常重启问题（OOM）？**

1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

2. 首先会判断查询缓存是否开启，如果已经开启，会判断sql是select还是update/insert/delete，对于select，尝试去查询缓存，如果命中缓存直接返回数据给客户端， 如果缓存没有命中，或者没有开启缓存， 会进入到下一步分析器。

### 1.1.2 查询缓存

> 查询缓存：mysql拿到一个查询后，先查询缓存，（缓存保存形式KV（K为查询的语句，V为查询的结果））

#### FQA

**为什么建议关闭缓存？**

> 失效频繁，而且对于更新压力大的数据库，命中率非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。==mysql8.0版本取消了查询缓存的整个功能模块。==

```mysql
# 关闭查询缓存
show variables like '%query_cache_type%';
set GLOBAL query_cache_type='OFF';
```

### 1.1.3 分析器

> 分析器进行语法分析(根据词法分析的结果和语法规则，判断是否满足Mysql语法)、词法分析，检查sql的语法顺序等得到==解析树==， 然后预处理器对解析树进一步分析，==验证数据表、字段是否存在==，通关之后sql进入下一步优化器，

### 1.1.4 优化器

> 优化器对sql执行计划分析，决定使用哪个索引；在一个语句有多表关联（join）时，决定各个表的连接顺序，得到最终执行计划，得到优化后的执行计划之后交给执行器。

执行器调用存储引擎api执行sql，得到响应结果， 将结果返回给客户端，如果缓存是开启状态， 会更新缓存。

### 1.1.5 执行器

> 执行器在执行的时候会先判断对于表T有没有查询权限，如果没有返回没有权限的错误(在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。

**precheck验证权限**

> 权限验证不仅仅在执行器这部分会做，在分析器之后，也就是知道了该语句要“干什么”之后，也会先做一次权限验证。叫做precheck。而precheck是无法对运行时涉及到的表进行权限验证的，比如使用了触发器的情况。因此在执行器这里也要做一次执行时的权限验证。

**执行流程**

> 1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
> 2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
> 3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

FAQ

## 1.2 存储引擎层

负责数据的存储和提取，架构模式位==插件式==的支持InnoDB（默认）、MyISAM（不支持事务）、Memory（针对具体表，而非数据库）

InnoDB、MyISAM、Memory比较：：
InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（银行），
要求实现并发控制（售票），选择InnoDB。如果需要频繁更新、删除操作的数据库也选择InnoDB。因为支持
事务的提交和回滚
MyISAM：插入数据块、空间和内存使用比较低。如果表主要用于插入新记录和读出记录，选择MyISAM能实现处理高效率。
如果应用的完整性、并发性要求比较低，也可使用。
Memory：所有数据存在内存中，数据处理速度快，但不安全。如果需要很快的读写速度，对数据的安全性要求低，可选择Memory
它对表的大小有要求，不能建立太大的表。

# 二、日志系统，更新语句如何执行

**关于缓存**

​		对于MySQL8.0之前的版本，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这就是一般不建议使用查询缓存的原因。

## 2.1 redo log 重做日志

> 客户端执行DDL语句（create）/DML语句（insert，update，delete）/DCL语句（grant，revoke），数据库服务端执行的时候会涉及到 redo log（重做日志） 和 binlog（归档日志） 两个日志文件的更新。

**问题引出：**

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 ==IO 成本==、查找成本都很高。

**关于IO成本**

> IO成本就是寻址时间和上下文切换所需要的时间，最主要是用户态和内核态的上下文切换。我们知道用户态是无法直接访问磁盘等硬件上的数据的，只能通过操作系统去调内核态的接口，用内核态的线程去访问。 这里的上下文切换指的是同进程的线程上下文切换，所谓上下文就是线程运行需要的环境信息。 首先，用户态线程需要一些中间计算结果保存CPU寄存器，保存CPU指令的地址到程序计数器（执行顺序保证），还要保存栈的信息等一些线程私有的信息。 然后切换到内核态的线程执行，就需要把线程的私有信息从寄存器，程序计数器里读出来，然后执行读磁盘上的数据。读完后返回，又要把线程的信息写进寄存器和程序计数器。 切换到用户态后，用户态线程又要读之前保存的线程执行的环境信息出来，恢复执行。这个过程主要是消耗时间资源。 --来自《Linux性能优化实战》里的知识 SQL执行前优化器对SQL进行优化，这个过程还需要占用CPU资源

**关于随机IO**

> 随机 IO。 避免每次更新都要通过磁盘随机 IO 定位到记录位置。 将改动以顺序 IO 写到 redo log。可以使用组提交来批量更新。 类比，其实很多组件都是这么做的。 比如 Redis 的 Pipeline。以减少网络 IO。批量请求。

### 2.1.1 WAL技术

> MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。
>
> 详细的说：先写redo log到log buffer，具体内容就是针对哪个表空间的哪些页面做了哪些修改，然后log buffer中的日志内容会在某些时候写到redo日志文件中，比如事务提交时。至于为什么写redo日志会比刷新内存中的数据页到磁盘快，是因为服务器在启动时就已经给redo日志文件分配好了一块物理上连续的磁盘空间，每次写redo日志都是往文件中追加写，并没有寻址的过程。而修改过的数据页要刷新到磁盘的话，可能对应的磁盘空间并不是物理连续的，找起来费劲

​			当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并==更新内存==，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲（根据innodb_flush_log_at_trx_commit来决定）的时候做

**什么是更新内存**

> 更新内存的意思是先要把这一行记录从磁盘加载到内存中(buffer_pool),然后在内存中更新这个值。不会立即把最新值刷新到磁盘。
>
> 当需要更新的数据页在内存中时，就会直接更新内存中的数据页；不在内存中时，在可以使用 change buffer 的情况下，就会将更新操作记录到 change buffer 中，并将这些操作记录到 redo log 中；

---

### 2.1.3 redo log 图

> redo log 是循环写的，空间固定会用完，之后就去写磁盘，有刷页机制；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
>
> redo log实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111210009122.png)

write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

**落盘机制**

innodb_flush_log_at_trx_commit 变量控制日志缓冲区的内容如何写入和刷新到磁盘。innodb_flush_log_at_timeout 变量控制日志刷新频率(1s由log buffer刷盘一次）

> 落盘机制可以通过innodb_flush_log_at_trx_commit参数来控制：
>    当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
>    当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
>    当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。

1. 后台线程定期会刷脏页
2. 清理LRU链表时会顺带刷脏页
3. redoLog写满会强制刷
4. 数据库关闭时会将所有脏页刷回磁盘
5. 脏页数量过多（默认占缓冲池75%）时，会强制刷

### 2.1.3 crash-safe

> redo log 是 InnoDB引擎所特有的，所以我们如果再使用InnoDB引擎创建表时，如果数据库发生异常重启，之前提交的记录都不会丢失。 InnoDB正因为有了 redo log(重做日志)，才有了 crash-safe 的能力（即使mysql服务宕机，也不会丢失数据的能力）。

数据库重启了，内存中的数据页没有同步到磁盘中，可以通过redo log日志恢复

## 2.2 binlog 归档日志

binlog（归档日志）是Server 层自己的日志。

 如何查看 binlog： https://zhuanlan.zhihu.com/p/33504555 

1. 搜索 log 名称：show variables like '%log_bin%'; 
2.  查看 log 内容：show binlog events in 'binlog.000009’ 或 使用命令行工具：mysqlbinlog binlog.000009

**关于binlog**

> binlog日志格式binlog日志有两种格式，分别为STATMENT、ROW，运行模式有三种，分别为STATMENT、ROW和MIXED。 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。 STATMENT 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。 * 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能； * 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。 ROW 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。 * 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题； * 缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨 MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlogredo log

**为什么会有两份日志？**

> 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。
>
> binlog还不能去掉。 一个原因是，redolog只有InnoDB有，别的引擎没有。 另一个原因是，redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。 只有两份日记才有crash-safe功能 为什么binlog不能做到crash-safe？ 假如只有binlog，有可能先提交事务再写binlog，有可能事务提交数据更新之后数据库崩了，还没来得及写binlog。我们都知道binlog一般用来做数据库的主从复制或恢复数据库，这样就导致主从数据库不一致或者无法恢复数据库了。同样即使先写binlog再提交事务更新数据库，还是有可能写binlog成功之后数据库崩掉而导致数据库更新失败，这样也会导致主从数据库不一致或者无法恢复数据库。所以只有binlog做不到crash-safe。为了支持crash-safe，需要redolog，而且为了保证逻辑一致，事务提交需要两个阶段：prepare阶段和commit阶段。写redolog并落入磁盘(prepare状态)-->写binlog-->commit。commit的时候是不会落盘的。

**binlog为什么没有crash_safe的能力呢？**

> 不考虑mysql现有的实现，假如现在重新设计mysql，只用一个binlog是否可以实现cash_safe能力呢？答案是可以的，只不过binlog中也要加入checkpoint，数据库故障重启后，binlog checkpoint之后的sql都重放一遍。但是这样做让binlog耦合的功能太多。
>
> 并且写入方式的问题，binlog是追加写，crash时不能判定binlog中哪些内容是已经写入到磁盘，哪些还没被写入。而redolog是循环写，从check point到write pos间的内容都是未写入到磁盘的。

**binlog 与redolog的不同**

> 1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
> 2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
> 3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
> 4. 两者在更新方面也不一样redo log 分为 redo log buffer 和 redo log file，buffer 到 file 是通过 os buffer 写入，写入机制分别为【延迟写】: 每秒从 redo log buffer 写入到 os buffer 和 redo log file， 【实时写，实时刷】: 即无延时实时写入，【实时写，延迟刷】: 每次写入到 os buffer 后每秒刷到 redo log file， binlog是在事务提交后一次性写入

REDO的写盘时间会直接影响系统吞吐，显而易见，REDO的数据量要尽量少。其次，系统崩溃总是发生在始料未及的时候，当重启重放REDO时，系统并不知道哪些REDO对应的Page已经落盘，因此REDO的重放必须可重入，即REDO操作要保证幂等。最后，为了便于通过并发重放的方式加快重启恢复速度，REDO应该是基于Page的，即一个REDO只涉及一个Page的修改。 熟悉的读者会发现，数据量小是Logical Logging的优点，而幂等以及基于Page正是Physical Logging的优点，因此InnoDB采取了一种称为Physiological Logging的方式，来兼得二者的优势。所谓Physiological Logging，就是以Page为单位，但在Page内以逻辑的方式记录。举个例子，MLOG_REC_UPDATE_IN_PLACE类型的REDO中记录了对Page中一个Record的修改，方法如下： （Page ID，Record Offset，(Filed 1, Value 1) ... (Filed i, Value i) ... ) 其中，PageID指定要操作的Page页，Record Offset记录了Record在Page内的偏移位置，后面的Field数组，记录了需要修改的Field以及修改后的Value。

---

**执行器与InnoDB引擎执行update语句内部流程**

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的==数据页==本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。<!--操作系统层面读取磁盘的最小单位本来就是页，内存页、cache页和磁盘页都是一样大小，一般是4KB，但是Innodb使用B+树存储数据时，一个树节点即一次磁盘IO到内存是16KB，4倍关系。-->
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行==新数据==。<!--写在了内存中，innodb中的内存模型中有一个buffer pool的结构。innodb的存储结构，它分为内存结构和磁盘结构。-->
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。<!--1.binlog只有在commit的时候才会写入； 2.当prepare log 写入成功且binglog写入成功后发生crash，在mysql启动时候，会自动commit这个事物； 3.当prepare log写入成功，binlog写入失败，此时发生crash，mysql启动会自动回滚掉这个事物。即Binlog如果已经写入磁盘，那么redo log是prepare, 且binlog已经完整了，这时候崩溃恢复过程会认可这个事务，提交掉。 达到了“用binlog恢复的库跟原库逻辑相同” 这个要求-->

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111211530363.png)

**数据恢复步骤**

> 恢复的时候的大致步骤可能如下，摘取下来仅供做设计思想的参考：
>
>  **Step1.** 按顺序扫描redolog，如果redolog中的事务既有prepare标识，又有commit标识，就直接提交（先将磁盘页读入内存，再用 redo更新形成 dirty page，然后再刷盘） **Step2** . 如果redolog事务只有prepare标识，没有commit标识，则说明当前事务在commit阶段crash了，binlog中当前事务是否完整未可知，此时拿着redolog中当前事务的XID（redolog和binlog中事务落盘的标识），去查看binlog中是否存在此XID a. 如果binlog中有当前事务的XID，则提交事务（复制redolog disk中的数据页到磁盘数据页） b. 如果binlog中没有当前事务的XID，则回滚事务（使用undolog来删除redolog中的对应事务）

### 2.2.1 两阶段提交

> 将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。

**怎样让数据库恢复到半个月内任意一秒的状态？**

通过定期的整库备份加上binlog的操作回放可以保证数据的安全性。因为binlog记录的是数据的逻辑操作（原始sql语句），而redolog是数据的物理操作日志，并且非innodb的引擎没有redolog。因此回放的时候回使用binlog进行回放

例如：某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

* 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
* 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

**注：**在重放binlog之前，需要将binlog中误删除的那个位置前的操作给删除掉，不然还是会执行误删除操作。等于前面的所有操作都白费了，也可以指定重放的位置，重放到误删除操作之前的position。

---

**为什么要两阶段提交？**

> 因为从 “两阶段提交”的执行流程看，“ binlog 成功，redo log prepare 失败”的场景， redo log 和 binlog 还是不一致的。 真正的“两阶段提交” 是指对 redo log 进行“两阶段提交”：先 prepare，再commit。 数据库 crash-重启后，会对记录对redo log 进行check
>
> 1. 如果 redo log 已经commit，则视为有效。
>
> 2. 如果 redo log prepare 但未commit，则check对应的bin log记录是否记录成功。 
>    1. bin log记录成功则将该prepare状态的redo log视为有效 
>    2. bin log记录不成功则将该prepare状态的redo log视为无效

本质上是因为 redo log 负责事务； binlog负责归档恢复； 各司其职，相互配合，才提供(保证)了现有功能的完整性； 现在 你非要破坏 其中一个log，完了，还妄想保证上述的功能，怎么可能呢？ 除非你从根本上 改写binlog，合并redo log 和 binlog 的 职责和功能！

redolog和binlog具有关联行，在恢复数据时，redolog用于恢复主机故障时的未更新的物理数据，binlog用于备份操作。每个阶段的log操作都是记录在磁盘的，在恢复数据时，redolog 状态为commit则说明binlog也成功，直接恢复数据；如果redolog是prepare，则需要查询对应的binlog事务是否成功，决定是回滚还是执行。

简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### 2.2.2 小结

> redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。<!--innodb_flush_log_at_trx_commit={0|1|2} # 指定何时将事务日志刷到磁盘，默认为1。 0表示每秒将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中。 1表示每事务提交都将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中。 2表示每事务提交都将"log buffer"同步到"os buffer"但每秒才从"os buffer"刷到磁盘日志文件中。-->

> sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

## 2.3 FAQ

**全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？**

一天一备和一周一备： - 好处：最长恢复时间更短。 一天一备——全备+这一天0点到当前时间的binlog (如果每次0点全备) 一周一备——全备+周一到当前时间的binlog (如果每周周一0点全备) - 代价：一天一备，频繁全量备份，需要消耗大量存储空间

在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。

一周一备最坏情况就要应用一周的 binlog 了。

系统的对应指标就是  RTO（恢复目标时间）。

当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间增加磁盘压力，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。

---

**数据库备份策略**

备份就是救命药加后悔药，灾难发生的时候备份能救命，出现错误的时候备份能后悔。事情都有两面性，没有谁比谁好，只有谁比谁合适，完全看业务情况和需求而定。一天一备恢复时间更短，binlog更少，救命时候更快，但是后悔时间更短，而一周一备正好相反。我自己的备份策略是设置一个16小时延迟复制的从库，充当后悔药，恢复时间也较快。再两天一个全备库和binlog，作为救命药,最后时刻用。这样就比较兼顾了。

---

**为什么先写日志后写磁盘还可以查到数据呢？**

因为数据已经在内存中了，不会去查找磁盘了

如果update到内存后，redolog/binlog写入之前，这个时刻【如果】有其他客户端B能读到的话（比如 10 更新为20了），从客户端来的角度来看的话，这个20是已经更新完成的了。然而如果redolog/binlog写入之前崩溃了，恢复时，这个更新肯定是要丢弃的（因为日志还没commit）；这时候之前的读就是有问题的。所以个人认为在commit之前，哪怕是更新到内存了，其他读取理应是看不到这个尚未commit的数据的（和事务隔离级别有关？）

---

**由于脏页导致的普通select超过30s**

所谓刷脏就是由于内存页和磁盘数据不一致导致了该内存页是“脏页”，将内存页数据刷到磁盘的操作称为“刷脏”。刷脏是为了避免产生“脏页”，主要是因为MySQL更新先写redo log再定期批量刷到磁盘的，这就导致内存页的数据和磁盘数据不一致，为了搞清楚为什么“刷脏”会导致慢查，我们先分析下redo log再哪些场景会刷到磁盘。
场景1：redo log写满了，此时MySQL会停止所有更新操作，把脏页刷到磁盘
场景2：系统内存不足，需要将脏页淘汰，此时会把脏页刷到磁盘
场景3：系统空闲时，MySQL定期将脏页刷到磁盘

可以想到，在场景1和2都会导致慢查的产生，根据文章提到的，redo log是可以循环写的，那么即使写满了应该也不会停止所有更新操作吧，其实是会的，文中有句话“粉板写满了，掌柜只能停下手中的活，把粉板的一部分赊账记录更新到账本中，把这些记录从粉板删除，为粉板腾出新的空间”，这就意味着写满后是会阻塞一段时间的。

那么问题来了，innodb存储引擎的刷脏策略是怎么样的呢？通常而言会有两种策略：全量（sharp checkpoint）和部分（fuzzy checkpoint）。全量刷脏发生在关闭数据库时，部分刷脏发生在运行时。部分刷脏又分为定期刷脏、最近最少使用刷脏、异步/同步刷脏、脏页过多刷脏。

---

**关于数据页**

MySQL的记录是以“页”为单位存取的，默认大小16K。也就是说，你要访问磁盘中一个记录，不会只读这个记录，而会把它所在的16K数据一起读入内

---

**如果两种log都写完成了，但是redolog没有写磁盘，物理机挂了，redolog在内存中就丢失了吧，再启动跟磁盘中的binlog就不一致，后期恢复数据的时候会有问题吗**

需要讲trx_commit设置成1

---

**redo log为什么要设计成环形的？环形缓冲区的设计又有什么好？**

可以避免新建、删除文件带来的抖动

# 三、事物隔离

## 3.1 隔离性与隔离级别 

## 3.2 事物的ACID属性

* **Atomicity（原子性）：**

    一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。 

* **Consistency（一致性）：**

  在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。

*  **Isolation（隔离性）：**

  数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。 

* **Durability（持久性）：**

  事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

> 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

* **脏读:** 读到其他事务未提交的数据； 

* **不可重复读：**前后读取的记录内容不一致；

* **幻读：**前后读取的记录数量不一致。幻读也成幻行，指的是第一次查询和第二次查询返回的行集不一致。所以删除了一行数据也会导致幻读

## 3.3 事物的隔离级别

1. **读未提交RU：**一个事务还没提交时，它做的变更就能被别的事务看到。会造成“脏读”，“幻读”，“不可重复读取”。 
2. **读提交RC：**一个事务提交之后，它做的变更才会被其他事务看到。避免了“脏读”，“但不能避免""幻读“和”不可重复读取”。(是大多主流数据库默认的事务等级)
3. **可重复读RR：**一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。避免了“脏读“和”不可重复读取“的情况，但不能避免“幻读”。（带来了更多的性能损失）
4. **串行化Seria：**顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。（最严格级别，事务串行执行，资源消耗最大）

**注意：**

> 在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，要记得将 MySQL 的隔离级别设置为“读提交”
>
> 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。
>
> 5.7版本就是@@tx_isolation，8.0以上是transaction_isolation

## 3.4 视图

数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

1. **RC级别:**   MVCC视图会在每一个语句前创建一个，所以在RC级别下，一个事务是可以看到另外一个事务已经提交的内容、因为它在每一次查询之前都会重新给予最新的数据创建一个新的MVCC视图。 

2. **RR级别:** MVCC视图在，视图是在第一个Select语句执行时创建的吧？，这个视图会一直使用，直到该事务结束。 这里要注意不同的隔离级别他们的一致性事务视图创建的时间点是不同的。 

   事务最开始是update语句时，这个时候还没创建视图，当事务询查到第一条查询语句才开始创建视图

3. **RU：**没有视图的概念，直接返回记录上的最新值

4. **串行化：** 直接用加锁的方式来避免并行访问。

## 3.5 事物隔离的实现

> 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。<!--意思就是除了记录变更记录，还会记录一条变更相反的回滚操作记录，前者记录在redo log，后者记录在undo log-->

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![img](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111231403770.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小

## 3.7 事务的启动方式

1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。一致性视图是在执行第一个快照读语句时创建的；
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
3.  start transaction with consistent snapshot; 如果你想要马上启动一个事务，可以使用 `start transaction with consistent snapshot `这个命令。  一致性视图是在执行 start transaction with consistent snapshot 时创建的。
4. commit work and chain 将提交和开启事务用一条语句完成可以弥补，减少交互，来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

> 很多语言的第三方库都是使用连接池维持可复用的长连接来保持与mysql的链接，需注意，长连接并不意味着长事务，需要判断是否将autocommit设置成了0.

建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。

如果纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。

## 3.8 长事务查询

information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```mysql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

## FAQ

**回滚日志何时删除?**

> 在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。
>
> 回归日志生命周期 在开始时创建 提交后不一定删除 只有在提交后且没有比当前更早的事务时 回滚日志才会被删除 所以尽量不要使用长事务

**为什么不要使用长事务?**

 长事务意味着系统里面会存在很老的事务视图。 由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。

**如何避免长事务**

首先，从应用开发端来看：

1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。

   ```bash
   一、查询日志开启 
   方法一： 　　
   #设置路径
   mysql>set global general_log_file='/tmp/general.lg';  　
   # 开启general log模式 
   mysql>set global general_log=on; 　　
   # 关闭general log模式 命令行设置即可,无需重启 在general log模式开启过程中，所有对数据库的操作都将被记录 general.log 文件 
   mysql>set global general_log=off; 
   方法二： 也可以将日志记录在表中 
   set global log_output='table' 运行后,可以在mysql数据库下查找 general_log表 
   二、查询日志关闭 查看是否是开启状态： 
   mysql> show global variables like '%general%'; 
   #  关闭查询日志
   mysql> set global general_log = off; 
   ```

   

2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。

3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）

其次，从数据库端来看：

1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；
2. Percona 的 pt-kill 这个工具不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；
4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

# 四、深入浅出索引一

> 索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。

## 4.1 B+树

哈希表能快速找到数据，但是不支持范围查找，有序数组支持范围查找，但是不支持随机插入，B+树俩者都支持。

### 4.1.1 MySQL的存储结构

#### 4.1.1.1 表存储结构

单位：表>段>区>页>行

在数据库中， 不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说存储空间的基本单位是页。

一个页就是一棵树B+树的节点，数据库I/O操作的最小单位是页，与数据库相关的内容都会存储在页的结构里。

#### 4.1.1.2 B+树索引结构

在一棵B+树中，每个节点为都是一个页，每次新建节点的时候，就会申请一个页空间

同一层的节点为之间，通过页的结构构成了一个双向链表

非叶子节点为，包括了多个索引行，每个索引行里存储索引键和指向下一层页面的指针

叶子节点为，存储了关键字和行记录，在节点内部(也就是页结构的内部)记录之间是一个单向的表

#### 4.1.1.3 B+树页节点结构

有以下几个特点

将所有的记录分成几个组， 每组会存储多条记录，

页目录存储的是槽(slot)，槽相当于分组记录的索引，每个槽指针指向了不同组的最后一个记录

我们通过槽定位到组，再查看组中的记录

页的主要作用是存储记录，在页中记录以单链表的形式进行存储。

单链表优点是插入、删除方便，缺点是检索效率不高，最坏的情况要遍历链表所有的节点。因此页目录中提供了二分查找的方式，来提高记录的检索效率。

#### 4.1.1.4 B+树的检索过程

我们再来看下B+树的检索过程

从B+树的根开始，逐层找到叶子节点。

找到叶子节点为对应的数据页，将数据叶加载到内存中，通过页目录的槽采用二分查找的方式先找到一个粗略的记录分组。

在分组中通过链表遍历的方式进行记录的查找。

#### 4.1.1.5 为什么要用B+树索引

数据库访问数据要通过页，一个页就是一个B+树节点，访问一个节点相当于一次I/O操作，所以越快能找到节点，查找性能越好。

B+树的特点就是够矮够胖，能有效地减少访问节点次数从而提高性能。

下面，我们来对比一个二叉树、多叉树、B树和B+树。

### 4.1.2 二叉树

二叉树是一种二分查找树，有很好的查找性能，相当于二分查找。

但是当N比较大的时候，树的深度比较高。数据查询的时间主要依赖于磁盘IO的次数，二叉树深度越大，查找的次数越多，性能越差。

最坏的情况是退化成了链表，如下图

为了让二叉树不至于退化成链表，人们发明了AVL树(平衡二叉搜索树)：任何结点的左子树和右子树高度最多相差1

### 4.1.3 多叉树

多叉树就是节点可以是M个，能有效地减少高度，高度变小后，节点变少I/O自然少，性能比二叉树好了

### 4.1.4 B树

B树简单地说就是多叉树，每个叶子会存储数据，和指向下一个节点的指针。

例如要查找9，步骤如下

我们与根节点的关键字 (17，35)进行比较，9 小于 17 那么得到指针 P1；

按照指针 P1 找到磁盘块 2，关键字为(8，12)，因为 9 在 8 和 12 之间，所以我们得到指针 P2；

按照指针 P2 找到磁盘块 6，关键字为(9，10)，然后我们找到了关键字 9。

### 4.1.5 B+树

B+树是B树的改进，简单地说是：只有叶子节点才存数据，非叶子节点是存储的指针；所有叶子节点构成一个有序链表

例如要查找关键字16，步骤如下

与根节点的关键字 (1，18，35) 进行比较，16 在 1 和 18 之间，得到指针 P1(指向磁盘块 2)

找到磁盘块 2，关键字为(1，8，14)，因为 16 大于 14，所以得到指针 P3(指向磁盘块 7)

找到磁盘块 7，关键字为(14，16，17)，然后我们找到了关键字 16，所以可以找到关键字 16 所对应的数据。

### 4.1.6 B+树与B树的不同：

B+树非叶子节点不存在数据只存索引，B树非叶子节点存储数据

B+树使用双向链表串连所有叶子节点，区间查询效率更高，因为所有数据都在B+树的叶子节点，但是B树则需要通过中序遍历才能完成查询范围的查找。

B+树每次都必须查询到叶子节点才能找到数据，而B树查询的数据可能不在叶子节点，也可能在，这样就会造成查询的效率的不稳定

B+树查询效率更高，因为B+树矮更胖，高度小，查询产生的I/O最少。

这就是MySQL使用B+树的原因，就是这么简单！

## 4.2 InnoDB 的索引模型

在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。

对于Innodb对应的N叉树大小，以InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

MySql默认一个节点的长度为16K，一个整数（bigint）字段索引的长度为 8B,另外每个索引还跟着6B的指向其子树的指针；所以16K/14B ≈ 1170 参见https://blog.csdn.net/weixin_35871519/article/details/113303881

https://github.com/jeremycole/innodb_diagrams/blob/master/images/InnoDB_Structures.pdf

**关于 InnoDB 的表结构：**

1. 在 InnoDB 中，每一张表其实就是多个 B+ 树，即一个主键索引树和多个非主键索引树。

2. 执行查询的效率，使用主键索引 > 使用非主键索引 > 不使用索引。 

3. 如果不使用索引进行查询，则从主索引 B+ 树的叶子节点进行遍历。

**每一个索引在 InnoDB 里面对应一棵 B+ 树。**

**例如：**

```mysql
create table T(
id int primary key, 
k int not null, 
name varchar(16),
index (k))engine=InnoDB;
insert into t(id,k) values(100,1),(200,2),(300,3),(500,5),(600,6);
```

![InnoDB 的索引组织结构](https://raw.githubusercontent.com/lijinzedev/picture/main/img/202111231611454.png)

> 二级索引的叶子节点存的就是主键的值，不是引用！根据这个值进行回表，再在聚簇索引里面直接从叶子节点里面拿到值，不需要进行一次IO去磁盘找。为啥存值不存引用（数据在磁盘的地址指针）？因为一旦发生页分裂或者页合并，就得去维护这个地址指针，更麻烦。

---

**基于主键索引和普通索引的查询有什么区别？**

主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

---

## 4.3 索引维护

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

数据页参见https://www.cnblogs.com/zhuchangwu/p/14041410.html

由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。

显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。

**适合业务字段做主键的场景**

1. 只有一个索引；

2. 该索引必须是唯一索引。  

这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。

这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。

## FAQ

**重建索引问题**

如果你要重建索引 k，你的两个 SQL 语句可以这么写：

`alter table T drop index k;`

`alter table T add index(k);`

如果你要重建主键索引，也可以这么写：

`alter table T drop primary key;`

`alter table T add primary key(id);`

对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

1. 直接删掉主键索引是不好的，它会使得所有的二级索引都失效，并且会用ROWID来作主键索引；
2. 看到mysql官方文档写了三种措施，第一个是整个数据库迁移，先dump出来再重建表（这个一般只适合离线的业务来做）；第二个是用空的alter操作，比如ALTER TABLE t1 ENGINE = InnoDB;这样子就会原地重建表结构（真的吗？）；第三个是用repaire table，不过这个是由存储引擎决定支不支持的（innodb就不行）。

---

**“N叉树”的N值在MySQL中是可以被人工调整的么？**

1， 通过改变key值来调整
N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。我们通过改变Key的大小，就可以改变N的值
2， 改变页的大小
页越大，一页存放的索引就越多，N就越大。

数据页调整后，如果数据页太小层数会太深，数据页太大，加载到内存的时间和单个数据页查询时间会提高，需要达到平衡才行。

**没有主键的表，有一个普通索引。怎么回表？**

https://dev.mysql.com/doc/refman/5.6/en/innodb-index-types.html
5.6 文档
先找非空唯一索引；
如果没有，再用rowid ？

**innodb B+树主键索引的叶子节点存的是什么?**

B+树的叶子节点是page （页），一个页里面可以存多个行

 因为存的不可能是“页” 这一逻辑概念 只能说这个叶结点大小等于innoDB里设置的页大小 或者说这个叶结点其实就是“页” 但存的是什么 那当然是数据 什么数据 当然是表中的行数据

**普通索引，为什么要用回表，直接指向数据行，数据页不行吗？**

第一、主键索引和普通索引，实际指向的都是一个页地址，在每个页中，主键索引页每行的value存的是实际数据，普通索引页每行的value是主键id。
第二、如果普通索引页每行的value是主键索引页地址，那么在发生页分裂、页合并、主键索引重建的时候，需要遍历所有的普通索引，查找涉及到的普通索引key进行更新。
第三、可以理解为：使用id值，相当于对主键索引与普通索引进行了解耦，主键索引页的变更不会影响到其他的普通索引。
第四、关于解耦带来的好处，与查询上带来的性能损失之间的定量分析，希望有其他同学补充
第五、可能还有其他的原因，欢迎其他同学补充

**1、如果插入的数据是在主键树叶子结点的中间，后面的所有页如果都是满的状态，是不是会造成后面的每一页都会去进行页分裂操作，直到最后一个页申请新页移过去最后一个值**

只会分裂它要写入的那个页面。每个页面之间是用指针串的，改指针就好了，不需要“后面的全部挪动

在Page 数据结构中，记录 Page 的头信息的File Header 字段中有 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，通过这两个字段，来确定该页的上一页和下一页，实际上所有页通过两个字段可以形成一条双向链表的

**2、还有之前看到过说是插入数据如果是在某个数据满了页的首尾，为了减少数据移动和页分裂，会先去前后两个页看看是否满了，如果没满会先将数据放到前后两个页上，不知道是不是有这种情况**

对，减为了增加空间利用率
